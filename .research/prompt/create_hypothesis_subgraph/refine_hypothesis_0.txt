
LLM Name: o3-2025-04-16
Input:
You are an accomplished researcher in the field of machine learning. Based on the instructions below, please refine the research hypothesis provided in "Hypothesis Info" to make it more novel and academically as well as socially valuable.

# Instructions
- Carefully read the research theme described in "Research Topic" and understand the problems this research should address, as well as the broader impact it aims to achieve.
- "Hypothesis Info" contains a newly proposed research hypothesis related to the "Research Topic." Read the hypothesis thoroughly and refine it so that it becomes a research contribution with stronger novelty and significance.
- The reasoning behind the evaluation of novelty is provided in "Novelty," and the reasoning for significance is provided in "Significance." Use these evaluations as references to improve the research hypothesis.
- "Research Study List" provides a set of related prior studies. Each entry includes a summary of its title, main contributions, methodologies, results, and limitations. Read through these summaries to understand the direction and focus of research in this domain.
- "Hypothesis Info History" contains past research hypotheses and their evaluation reasoning. If provided, use it as a reference for refining the current hypothesis.
- Pay close attention to how each prior study builds upon earlier work and which limitations remain unresolved. Organize this information to form a clear understanding of the current research landscape.
- Identify the key gaps, challenges, or unmet needs that persist across these studies. Also, consider whether methods or concepts from other domains could help address these limitations.
- Reflect on unexplored aspects or areas for improvement (e.g., new techniques, new evaluation metrics, novel datasets, or methods for generalizing findings). Ensure that the refined hypothesis is broadly applicable and not overly dependent on a specific dataset or model.
- Please limit research hypotheses to those that can be validated with a Python script.
- Please also consider ways to enhance the feasibility of validation and improve accordingly.

# Research Topic
Improving fine-tuning performance of language models.

# Current Hypothesis
{
    "Open Problems": "Spectral AdapterR/A currently updates only the top-r singular directions of every weight matrix. This ignores information in lower singular vectors and can lead to under-fitting on tasks that need a broader sub-space, while increasing r linearly enlarges parameter count. A minimal way to use a wider spectrum without adding many trainable matrices is missing.",
    "Methods": "Gated Spectral Adapter (GSA). Keep the SVD‐based formulation of Spectral AdapterR but add a trainable, element-wise gating vector g∈R^k (k≥r, typically 2r) that scales the first k singular values: \n   Ŝ_i = S_i·(1+g_i)  for i≤k,  Ŝ_i = S_i  otherwise.\nThe gate is initialised to 0, regularised with λ·||g||₁ to keep most gates near zero and stay parameter-efficient. No extra matrices (AU, AV) are introduced; only one small vector per adapted layer.\nMotivation: allows the optimiser to selectively amplify or attenuate additional singular directions when beneficial while keeping parameter overhead negligible (k parameters vs O(rd)). L1 regularisation encourages sparsity so the effective rank grows only when needed.",
    "Experimental Setup": "Backbone: DeBERTaV3-base (185M).\nTasks: GLUE benchmark (train on each task with default splits).\nBaselines: (1) Full fine-tuning, (2) LoRA (rank 8), (3) Spectral AdapterR (rank 8).\nProposed: GSA with k=16 (still <0.02% params). Same optimiser & training schedule as Spectral Adapter paper (5 epochs, lr 2e-4).\nEvaluate development set; report averaged GLUE score (mean of task metrics).",
    "Primary Metric": "glue_avg",
    "Experimental Code": "import torch, torch.nn as nn\nclass GatedSpectralLayer(nn.Module):\n    def __init__(self, orig_lin, r=8, k=16, l1_lambda=1e-4):\n        super().__init__()\n        W = orig_lin.weight.data\n        U,S,V = torch.linalg.svd(W, full_matrices=False)\n        self.register_buffer('U', U)\n        self.register_buffer('V', V)\n        self.register_buffer('S_base', S)\n        self.k = k\n        self.gate = nn.Parameter(torch.zeros(k))\n        self.l1_lambda = l1_lambda\n        orig_lin.forward = self.forward  # monkey-patch\n    def forward(self, x):\n        S = self.S_base.clone()\n        S[:self.k] = S[:self.k] * (1+self.gate)\n        W_hat = (self.U * S.unsqueeze(0)) @ self.V\n        return torch.nn.functional.linear(x, W_hat)\n    def l1_reg(self):\n        return self.l1_lambda * self.gate.abs().sum()\n# usage during model construction\nfor name, module in model.named_modules():\n    if isinstance(module, nn.Linear) and module.weight.dim()==2:\n        GatedSpectralLayer(module, r=8, k=16)\n# add l1 losses in training loop\nloss = loss_ce + sum(m.l1_reg() for m in model.modules() if hasattr(m,'l1_reg'))",
    "Expected Result": "Expect GSA to raise glue_avg by ~1-1.5 points over Spectral AdapterR (e.g., from 86.0→87.2) while adding <0.002% extra trainable params. On tasks needing richer subspaces (STS-B, RTE) larger gains (≈2 points) are anticipated. L1 term keeps effective activated gates ≤r on most layers.",
    "Expected Conclusion": "A single gating vector per layer lets the optimiser exploit additional spectral directions when beneficial, overcoming the rigidity of top-r selection. Because it reuses the SVD basis and adds only O(k) parameters, it preserves parameter-efficiency and computational cost, yet yields consistent accuracy gains, showing that fine-grained control over the singular spectrum is a cheap but effective improvement to Spectral Adapters."
}

# Novelty
Most prior spectral-space PEFT methods (Spectral AdapterR, AdapterA, AdaLoRA) already (i) decouple rank from parameter budget, (ii) learn per-direction scaling of singular values (Spectral AdapterR’s C vector) and (iii) allow the effective rank to change during training (AdaLoRA’s rank scheduling).  The proposed Gated Spectral Adapter differs only in allowing the scaling vector to cover additional (r< i ≤k) singular directions and in adding an L1 penalty to keep most gates at zero.  This is a modest architectural tweak that re-uses the existing SVD basis and does not introduce new trainable matrices, but the underlying idea—selectively re-weighting or expanding the set of singular directions with sparse regularisation—has close antecedents in AdaLoRA’s adaptive rank growth, in Spectral AdapterR’s trainable C vector, and in DoRA’s element-wise scaling. Hence the methodological novelty is limited and incremental.

# Significance
Because it needs only one O(k) gating vector per layer, the method could be adopted easily in settings where parameter budget is extremely tight (e.g., on-device fine-tuning).  If it reliably improves GLUE by ~1 pt with <0.002 % extra parameters, it provides a practical, low-cost refinement to Spectral Adapters and may stimulate further study of fine-grained spectral control.  However, the expected gains are small, the experiments are limited to one 185 M-parameter backbone and standard GLUE tasks, and the approach does not address broader challenges such as robustness, multilinguality or privacy.  Academic impact is therefore moderate and societal impact minor.

# Hypothesis History
No previous hypotheses.

# Research Study List
{
    "Title": "Parameter-Efficient Fine-Tuning Design Spaces",
    "Main Contributions": "The paper addresses the lack of systematic design patterns in parameter-efficient fine-tuning (PEFT) strategies, which are typically hand-crafted and applied separately. It introduces PEFT design spaces, characterized by layer grouping, trainable parameter allocation, tunable groups, and strategy assignment. Through a progressive refinement process, the research discovers key design patterns: grouping layers in a spindle pattern, allocating trainable parameters uniformly, tuning all groups, and assigning proper strategies to different groups. These discovered patterns lead to new PEFT methods (S4-model and S4-3b-model) that consistently and significantly outperform existing PEFT strategies across various backbone models (T5, RoBERTa, BART, XLNet) and NLP tasks (GLUE, XSum, WMT, SuperGLUE), often surpassing full fine-tuning performance with significantly fewer trainable parameters (0.5%).",
    "Methodology": "The methodology involves defining parameter-efficient fine-tuning (PEFT) design spaces using four components: layer grouping, trainable parameter allocation, tunable groups, and strategy assignment. Starting with an unconstrained design space (S0), the research progressively refines it by adding constraints based on the overall model quality. This quality is quantified by randomly sampling 100 models from a design space, fine-tuning them for 3 epochs on the GLUE benchmark, and averaging their performances. A greedy selection process is applied at each stage for each component. Specific design patterns explored include: (i) five layer grouping patterns (Increasing, Uniform, Decreasing, Spindle, Bottleneck), (ii) three trainable parameter allocation patterns (Increasing, Uniform, Decreasing), (iii) various combinations of tunable groups, and (iv) assigning individual or combinations of PEFT strategies (Adapter, Prefix, BitFit, LoRA) to different layer groups.",
    "Experimental Setup": "The design patterns were discovered using T5-base and T5-3b pretrained backbone models on the GLUE benchmark, measuring Matthews correlation for CoLA, Spearman correlation for STS-B, and accuracy for other tasks. Final evaluation of the new PEFT methods (S4-model, S4-3b-model) was conducted on GLUE, XSum (abstractive summarization, using ROUGE scores), WMT 2016 en-ro (machine translation, using BLEU scores), and SuperGLUE. These evaluations utilized T5-base/3b, RoBERTa-base/large, BART-base/large, and XLNet-base/large backbone models. Implementations used Hugging Face. The total number of trainable parameters was set to 0.5% (0.1% for BitFit) of the backbone model's parameters. Training used a linear decay scheduler with a warmup ratio of 0.06, a batch size of 128 for base models and 64 for large models, a maximum learning rate of 5e-5, and 5 or 10 training epochs. All experiments were performed using 8 A100 GPUs. Results were averaged over 20 random runs (10 for SuperGLUE), with statistical significance tested at p < 0.05 or p < 0.01.",
    "Limitations": "The study explicitly states that for computational efficiency, it was beyond its scope to enumerate all possible constraints related to the design space components. This implies that the progressive and greedy discovery process might not have explored the entire optimal design space, potentially settling on locally optimal patterns rather than globally optimal ones. The goal was to demonstrate the utility of design spaces, not necessarily to find the absolute \"best\" design.",
    "Future Research Directions": "Not mentioned",
    "Experiment Code": "# Adapters\nif is_torch_available():\n    _import_structure[\"adapters\"] = [\n        \"ADAPTER_CACHE\",\n        \"ADAPTER_CONFIG_MAP\",\n        \"ADAPTERFUSION_CONFIG_MAP\",\n        \"ADAPTER_MODEL_MAPPING\",\n        \"DEFAULT_ADAPTER_CONFIG\",\n        \"DEFAULT_ADAPTERFUSION_CONFIG\",\n        \"MODEL_WITH_HEADS_MAPPING\",\n        \"AdapterArguments\",\n        \"AdapterConfig\",\n        \"AdapterConfigBase\",\n        \"AdapterFusionConfig\",\n        \"AdapterInfo\",\n        \"AdapterLayer\",\n        \"AdapterLayerBase\",\n        \"AdapterSetup\",\n        \"AdapterTrainer\",\n        \"AdapterType\",\n        \"AutoAdapterModel\",\n        \"AutoModelWithHeads\",\n        \"BartAdapterModel\",\n        \"BartModelWithHeads\",\n        \"BeitAdapterModel\",\n        \"BertAdapterModel\",\n        \"BertModelWithHeads\",\n        \"CompacterConfig\",\n        \"CompacterPlusPlusConfig\",\n        \"ConfigUnion\",\n        \"DebertaAdapterModel\",\n        \"DebertaV2AdapterModel\",\n        \"DistilBertAdapterModel\",\n        \"DistilBertModelWithHeads\",\n        \"DynamicAdapterFusionConfig\",\n        \"EmbeddingAdaptersMixin\",\n        \"ForwardContext\",\n        \"GPT2AdapterModel\",\n        \"GPT2ModelWithHeads\",\n        \"GPTJAdapterModel\",\n        \"HoulsbyConfig\",\n        \"HoulsbyInvConfig\",\n        \"IA3Config\",\n        \"InvertibleAdaptersMixin\",\n        \"LoRAConfig\",\n        \"MAMConfig\",\n        \"MBartAdapterModel\",\n        \"MBartModelWithHeads\",\n        \"ModelAdaptersConfig\",\n        \"ModelAdaptersMixin\",\n        \"ModelWithFlexibleHeadsAdaptersMixin\",\n        \"ModelWithHeadsAdaptersMixin\",\n        \"MultiLingAdapterArguments\",\n        \"ParallelConfig\",\n        \"PfeifferConfig\",\n        \"PfeifferInvConfig\",\n        \"PrefixTuningConfig\",\n        \"RobertaAdapterModel\",\n        \"RobertaModelWithHeads\",\n        \"Seq2SeqAdapterTrainer\",\n        \"StaticAdapterFusionConfig\",\n        \"T5AdapterModel\",\n        \"T5ModelWithHeads\",\n        \"PEFTConfig\",\n        \"ViTAdapterModel\",\n        \"XLMRobertaAdapterModel\",\n        \"XLMRobertaModelWithHeads\",\n        \"get_adapter_config_hash\",\n        \"get_adapter_info\",\n        \"list_adapters\",\n    ]",
    "Experiment Result": "The package `adapter-transformers` is described as \"A friendly fork of HuggingFace's Transformers, adding Adapters to PyTorch language models\". The `transformers` library includes components for data processing and metrics for tasks such as GLUE, evidenced by imports like `glue_compute_metrics`, `glue_convert_examples_to_features`, `glue_output_modes`, `glue_processors`, and `glue_tasks_num_labels`. It also provides `AdapterTrainer` and `Seq2SeqAdapterTrainer` for fine-tuning models with adapters. However, specific experimental settings described in the method, such as randomly sampling 100 models, fine-tuning for 3 epochs, or averaging their performances, are not explicitly detailed in the provided repository content."
}{
    "Title": "Spectral Adapter: Fine-Tuning in Spectral Space",
    "Main Contributions": "The paper introduces the \"Spectral Adapter\" framework to enhance Parameter-Efficient Fine-Tuning (PEFT) methods by incorporating the spectral information of pretrained weight matrices. It proposes two spectral adaptation mechanisms: additive tuning (Spectral AdapterA) and orthogonal rotation (Spectral AdapterR) of the top singular vectors, performed after Singular Value Decomposition (SVD) of pretrained weights. Key findings include a theoretical demonstration that Spectral AdapterA offers twice the rank capacity of LoRA for an equal parameter budget and that tuning top singular vectors is robust due to better neuron alignment. Empirically, the proposed method achieves superior parameter efficiency and tuning performance compared to various PEFT baselines in language models (DeBERTaV3-base, Mistral 7B, Llama3 8B) and diffusion models (Chilloutmix). Additionally, Spectral AdapterA provides a natural solution for multi-adapter fusion, improving identity preservation and concept binding, while Spectral AdapterR offers finer-grained parameter budgets.",
    "Methodology": "The core methodology involves applying Singular Value Decomposition (SVD) to pretrained weight matrices (W = USV^T) and then fine-tuning only the top-r columns of the singular vector matrices (U and V). Two specific spectral fine-tuning mechanisms are introduced: 1. Spectral AdapterA: Additively tunes the top-r columns, represented as [U1 + AU U2]S[V1 + AV V2], where AU and AV are trainable matrices. This is initialized with AU and AV set to zero. 2. Spectral AdapterR: Orthogonally rotates the top-r columns, represented as [U1 RU U2]S[V1 RV V2], where RU and RV are trainable r x r orthogonal matrices. Orthogonality is maintained using Cayley parameterization (R = (I+Q)(I-Q)^-1, with Q being a skew-symmetric matrix derived from a trainable parameter). This ensures exact rotation and preserves SVD structure for sequential fine-tuning. For multi-adapter fusion, different concepts are distributed along distinct columns of the singular vector matrices, and adapters are merged in a FedAvg-like manner by averaging the updated singular vector components.",
    "Experimental Setup": "Experiments were conducted on large language models and diffusion models. For language models, DeBERTaV3-base (185M) was fine-tuned on GLUE benchmarks (MNLI, SST-2, MRPC, CoLA, QNLI, QQP, RTE, STS-B), Mistral 7B was fine-tuned on the GSM8K task, and Llama3 8B was fine-tuned on the Orca Math dataset (for training loss) and evaluated on GSM8K. Baselines included LoRA, DoRA, OFT, AdaLoRA, and SVDiff (for DeBERTaV3-base). For diffusion models, the Chilloutmix model was used for multi-adapter fusion tasks involving custom animal and toy concepts, and multi-character generation (Yoshua Bengio, Yann LeCun, Geoffrey Hinton), compared against Gradient Fusion, Orthogonal Adaptation, and FedAvg. For parameter efficiency analysis, Chilloutmix was fine-tuned on custom vase, chair, and table concepts, compared against LoRA, SVDiff, LiDB, OFT, and VeRA. T2I-Adapter with sketch/keypose conditions was used for spatial alignment in diffusion model experiments. Evaluation included accuracy scores for LLMs (GLUE, GSM8K), visual quality of generated images, and CLIP-based alignment scores (cosine similarity with reference images and prompt texts) for diffusion models. All experiments were performed using NVIDIA RTX A6000 GPUs. Hyperparameters for baselines followed their official implementations, while Spectral Adapter parameters were tuned.",
    "Limitations": "One limitation is the current work's choice of exclusively tuning the top spectral space. Although its effectiveness has been theoretically verified under simple settings, further comprehensive investigation into tuning different columns of singular vector matrices is crucial to fully understand the role of spectral information in the fine-tuning procedure. Additionally, the time consumption of the Singular Value Decomposition (SVD) process can increase significantly as models grow larger, necessitating the development or adoption of faster SVD methods to maintain practicality.",
    "Future Research Directions": "Future research could explore fine-tuning the spectral representation of specific components within large models, such as only the attention layers. Another promising direction is to dynamically combine spectral adaptation with other existing PEFT methods, like AdaLoRA, to potentially achieve even greater efficiency or performance. Further in-depth investigation into tuning different columns of singular vector matrices, beyond just the top ones, is also critical for a more complete understanding of how spectral information influences the fine-tuning process. Lastly, developing or integrating faster Singular Value Decomposition (SVD) methods will be important to mitigate the increasing computational cost as models continue to scale in size.",
    "Experiment Code": "import math\n\nimport torch\nimport torch.nn as nn\nfrom diffusers.models.attention_processor import AttnProcessor\nfrom diffusers.utils.import_utils import is_xformers_available\nimport torch.nn.functional as F\nimport numpy as np\n\nif is_xformers_available():\n    import xformers\n    \n\ndef remove_edlora_unet_attention_forward(unet):\n    def change_forward(unet):  # omit proceesor in new diffusers\n        for name, layer in unet.named_children():\n            if layer.__class__.__name__ == 'Attention' and name == 'attn2':\n                layer.set_processor(AttnProcessor())\n            else:\n                change_forward(layer)\n    change_forward(unet)\n\n\nclass EDLoRA_Control_AttnProcessor:\n    r\"\"\"\n    Default processor for performing attention-related computations.\n    \"\"\"\n    def __init__(self, cross_attention_idx, place_in_unet, controller, attention_op=None):\n        self.cross_attention_idx = cross_attention_idx\n        self.place_in_unet = place_in_unet\n        self.controller = controller\n        self.attention_op = attention_op\n\n    def __call__(\n        self,\n        attn,\n        hidden_states,\n        encoder_hidden_states=None,\n        attention_mask=None,\n        temb=None,\n    ):\n        residual = hidden_states\n\n        if attn.spatial_norm is not None:\n            hidden_states = attn.spatial_norm(hidden_states, temb)\n\n        input_ndim = hidden_states.ndim\n\n        if input_ndim == 4:\n            batch_size, channel, height, width = hidden_states.shape\n            hidden_states = hidden_states.view(batch_size, channel, height * width).transpose(1, 2)\n\n        if encoder_hidden_states is None:\n            is_cross = False\n            encoder_hidden_states = hidden_states\n        else:\n            is_cross = True\n            if len(encoder_hidden_states.shape) == 4:  # multi-layer embedding\n                encoder_hidden_states = encoder_hidden_states[:, self.cross_attention_idx, ...]\n            else:  # single layer embedding\n                encoder_hidden_states = encoder_hidden_states\n\n        assert not attn.norm_cross\n\n        batch_size, sequence_length, _ = encoder_hidden_states.shape\n        attention_mask = attn.prepare_attention_mask(attention_mask, sequence_length, batch_size)\n\n        if attn.group_norm is not None:\n            hidden_states = attn.group_norm(hidden_states.transpose(1, 2)).transpose(1, 2)\n\n        query = attn.to_q(hidden_states)\n        key = attn.to_k(encoder_hidden_states)\n        value = attn.to_v(encoder_hidden_states)\n\n        query = attn.head_to_batch_dim(query).contiguous()\n        key = attn.head_to_batch_dim(key).contiguous()\n        value = attn.head_to_batch_dim(value).contiguous()\n\n        if is_xformers_available() and not is_cross:\n            hidden_states = xformers.ops.memory_efficient_attention(query, key, value, attn_bias=attention_mask)\n            hidden_states = hidden_states.to(query.dtype)\n        else:\n            attention_probs = attn.get_attention_scores(query, key, attention_mask)\n            attention_probs = self.controller(attention_probs, is_cross, self.place_in_unet)\n            hidden_states = torch.bmm(attention_probs, value)\n\n        hidden_states = attn.batch_to_head_dim(hidden_states)\n\n        # linear proj\n        hidden_states = attn.to_out[0](hidden_states)\n        # dropout\n        hidden_states = attn.to_out[1](hidden_states)\n\n        if input_ndim == 4:\n            hidden_states = hidden_states.transpose(-1, -2).reshape(batch_size, channel, height, width)\n\n        if attn.residual_connection:\n            hidden_states = hidden_states + residual\n\n        hidden_states = hidden_states / attn.rescale_output_factor\n\n        return hidden_states\n\n\nclass EDLoRA_AttnProcessor:\n    def __init__(self, cross_attention_idx, attention_op=None):\n        self.attention_op = attention_op\n        self.cross_attention_idx = cross_attention_idx\n\n    def __call__(\n        self,\n        attn,\n        hidden_states,\n        encoder_hidden_states=None,\n        attention_mask=None,\n        temb=None,\n    ):\n        residual = hidden_states\n\n        if attn.spatial_norm is not None:\n            hidden_states = attn.spatial_norm(hidden_states, temb)\n\n        input_ndim = hidden_states.ndim\n\n        if input_ndim == 4:\n            batch_size, channel, height, width = hidden_states.shape\n            hidden_states = hidden_states.view(batch_size, channel, height * width).transpose(1, 2)\n\n        if encoder_hidden_states is None:\n            encoder_hidden_states = hidden_states\n        else:\n            if len(encoder_hidden_states.shape) == 4:  # multi-layer embedding\n                encoder_hidden_states = encoder_hidden_states[:, self.cross_attention_idx, ...]\n            else:  # single layer embedding\n                encoder_hidden_states = encoder_hidden_states\n\n        assert not attn.norm_cross\n\n        batch_size, sequence_length, _ = encoder_hidden_states.shape\n        attention_mask = attn.prepare_attention_mask(attention_mask, sequence_length, batch_size)\n\n        if attn.group_norm is not None:\n            hidden_states = attn.group_norm(hidden_states.transpose(1, 2)).transpose(1, 2)\n\n        query = attn.to_q(hidden_states)\n        key = attn.to_k(encoder_hidden_states)\n        value = attn.to_v(encoder_hidden_states)\n\n        query = attn.head_to_batch_dim(query).contiguous()\n        key = attn.head_to_batch_dim(key).contiguous()\n        value = attn.head_to_batch_dim(value).contiguous()\n\n        if is_xformers_available():\n            hidden_states = xformers.ops.memory_efficient_attention(query, key, value, attn_bias=attention_mask)\n            hidden_states = hidden_states.to(query.dtype)\n        else:\n            attention_probs = attn.get_attention_scores(query, key, attention_mask)\n            hidden_states = torch.bmm(attention_probs, value)\n\n        hidden_states = attn.batch_to_head_dim(hidden_states)\n\n        # linear proj\n        hidden_states = attn.to_out[0](hidden_states)\n        # dropout\n        hidden_states = attn.to_out[1](hidden_states)\n\n        if input_ndim == 4:\n            hidden_states = hidden_states.transpose(-1, -2).reshape(batch_size, channel, height, width)\n\n        if attn.residual_connection:\n            hidden_states = hidden_states + residual\n\n        hidden_states = hidden_states / attn.rescale_output_factor\n\n        return hidden_states\n\n\ndef revise_edlora_unet_attention_forward(unet):\n    def change_forward(unet, count):\n        for name, layer in unet.named_children():\n            if layer.__class__.__name__ == 'Attention' and 'attn2' in name:\n                layer.set_processor(EDLoRA_AttnProcessor(count))\n                count += 1\n            else:\n                count = change_forward(layer, count)\n        return count\n\n    # use this to ensure the order\n    cross_attention_idx = change_forward(unet.down_blocks, 0)\n    cross_attention_idx = change_forward(unet.mid_block, cross_attention_idx)\n    cross_attention_idx = change_forward(unet.up_blocks, cross_attention_idx)\n    print(f'Number of attention layer registered {cross_attention_idx}')\n\n\ndef revise_edlora_unet_attention_controller_forward(unet, controller):\n    class DummyController:\n        def __call__(self, *args):\n            return args[0]\n\n        def __init__(self):\n            self.num_att_layers = 0\n\n    if controller is None:\n        controller = DummyController()\n\n    def change_forward(unet, count, place_in_unet):\n        for name, layer in unet.named_children():\n            if layer.__class__.__name__ == 'Attention' and 'attn2' in name:  # only register controller for cross-attention\n                layer.set_processor(EDLoRA_Control_AttnProcessor(count, place_in_unet, controller))\n                count += 1\n            else:\n                count = change_forward(layer, count, place_in_unet)\n        return count\n\n    # use this to ensure the order\n    cross_attention_idx = change_forward(unet.down_blocks, 0, 'down')\n    cross_attention_idx = change_forward(unet.mid_block, cross_attention_idx, 'mid')\n    cross_attention_idx = change_forward(unet.up_blocks, cross_attention_idx, 'up')\n    print(f'Number of attention layer registered {cross_attention_idx}')\n    controller.num_att_layers = cross_attention_idx\n\nclass SpectralLinearLayer_OFT(nn.Module):\n    def __init__(self, name, original_module, rank=4, alpha=1, top=True, idx=0, revised_r=-1):\n        rank = 8\n        super().__init__()\n        self.name = name\n        if original_module.__class__.__name__ == 'Conv2d':\n            self.conv = True\n            in_channels, out_channels = original_module.in_channels, original_module.out_channels\n        else:\n            self.conv = False\n            in_channels, out_channels = original_module.in_features, original_module.out_features\n        W = original_module.weight.data.view(out_channels, in_channels)\n        U, S, V = torch.svd(W)\n        self.U = torch.nn.Parameter(U, requires_grad=False)\n        self.S = torch.nn.Parameter(S, requires_grad=False)\n        self.V = torch.nn.Parameter(V, requires_grad=False)\n        self.spectral_A = torch.nn.Parameter(torch.zeros(revised_r,revised_r), requires_grad=True)\n        self.spectral_B = torch.nn.Parameter(torch.zeros(revised_r,revised_r), requires_grad=True)\n        self.spectral_C = torch.nn.Parameter(torch.ones(revised_r), requires_grad=True)\n        original_module.forward = self.forward\n        self.original_module = original_module\n        self.top = top\n        self.idx = idx\n        assert revised_r>0\n        self.rank = revised_r\n\n    def cayley(self, data: torch.Tensor) -> torch.Tensor:\n        r, _ = data.shape\n        skew = 0.5 * (data - data.T)\n        I = torch.eye(r, device=data.device)\n        Q = torch.mm(I - skew, torch.inverse(I + skew))\n        return Q\n\n    def forward(self, hidden_states):\n        if self.top:\n            pad_U = self.U.clone()\n            pad_U[:,self.idx*self.rank:(self.idx+1)*self.rank] = self.U[:,self.idx*self.rank:(self.idx+1)*self.rank]@self.cayley(self.spectral_A)\n            pad_S = self.S.clone()\n            pad_S[self.idx*self.rank:(self.idx+1)*self.rank] = self.S[self.idx*self.rank:(self.idx+1)*self.rank]*self.spectral_C\n            pad_V = self.V.clone()\n            pad_V[:,self.idx*self.rank:(self.idx+1)*self.rank] = self.V[:,self.idx*self.rank:(self.idx+1)*self.rank]@self.cayley(self.spectral_B)\n        else:\n            raise Exception('')\n        pad_W = pad_U@pad_S.diag()@pad_V.T\n        if self.conv :\n            raise Exception('')\n        else:\n            return F.linear(hidden_states, pad_W, bias=self.original_module.bias)",
    "Experiment Result": "The implementation `SpectralLinearLayer_OFT` (found in `adapter_efficiency/mix_spectral/Mix-of-Show/mixofshow/models/edlora.py`) corresponds to 'Spectral AdapterR'.\n\n**Spectral AdapterR Details:**\n- **SVD application:** During initialization (`__init__`), Singular Value Decomposition (`torch.svd(W)`) is applied to the original weight matrix `W` of a linear layer (or flattened convolution). The resulting `U`, `S`, and `V` matrices are stored as non-trainable `torch.nn.Parameter`.\n- **Fine-tuning mechanism:** Orthogonal rotation is applied to specific 'top-r' columns of the singular vector matrices `U` and `V`, and scalar scaling is applied to the corresponding singular values in `S`.\n- **Trainable parameters:**\n    - `self.spectral_A`: `r x r` matrix, initialized with zeros. Used to derive the orthogonal rotation matrix for `U` via Cayley parameterization.\n    - `self.spectral_B`: `r x r` matrix, initialized with zeros. Used to derive the orthogonal rotation matrix for `V` via Cayley parameterization.\n    - `self.spectral_C`: `r`-dimensional vector, initialized with ones. Used to scale the `r` singular values in `S`.\n- **Orthogonality enforcement:** Cayley parameterization `Q = torch.mm(I - skew, torch.inverse(I + skew))` (where `skew = 0.5 * (data - data.T)`) is used to ensure `self.spectral_A` and `self.spectral_B` represent orthogonal rotation matrices `RU` and `RV`.\n- **Rank parameter (`r`):** The rank for fine-tuning (`revised_r` in the code) is configurable and passed via `lora_cfg['rank']` during instantiation in `train_edlora.py`. This determines the size of `spectral_A`, `spectral_B`, and `spectral_C`.\n- **Weight reconstruction:** In the `forward` pass, `pad_U`, `pad_S`, `pad_V` are computed by applying the learned transformations. The adapted weight matrix `pad_W` is then reconstructed as `pad_U @ pad_S.diag() @ pad_V.T`.\n\n**Spectral AdapterA:**\n- The provided repository content does not contain a direct implementation of 'Spectral AdapterA' as described (additive tuning of `top-r` columns of `U` and `V` with `[U1 + AU U2]S[V1 + AV V2]`). Other LoRA-like implementations (`LiLoRALinearLayer` in `mix_lidb`, `LoRALinearLayer` in `mix_lora`) are present but do not explicitly operate on the singular vectors `U` and `V` additively in an SVD-decomposed manner.\n\n**Multi-adapter fusion (FedAvg-like):**\n- The fusion mechanism is implemented in `adapter_fusion/fedavg_gradient/fedavg_fusion.py` through the `merge_kv_in_cross_attention` and `merge_spatial_attention` functions.\n- For each concept, the individual spectral adapters (like `SpectralLinearLayer_OFT`) are applied to the base model's weights to obtain `merge_params` (the full adapted weight matrix for that concept and layer).\n- These `merge_params` from all concepts are collected for each layer into `concept_weights_dict`.\n- Fusion occurs by stacking these adapted weight matrices (`torch.stack`) and then calculating their mean (`torch.mean`) to produce `Wnew`.\n- This indicates that the fusion is performed by averaging the *reconstructed adapted weight matrices* from individual concepts, rather than averaging the updated singular vector components (`U`, `S`, `V`) directly."
}{
    "Title": "Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone",
    "Main Contributions": "The paper introduces Res-Tuning, a novel tuning paradigm that unbinds tuners from the backbone of large-scale foundation models, addressing the limitations of existing parameter-efficient tuning (PETL) methods that are deeply coupled with the base model architecture. Key contributions include a unified formulation that seamlessly encompasses popular tuning approaches (prefix-tuning, prompt-tuning, adapters) and allows for flexible combination of various tuning strategies to discover stronger performers. A memory-efficient variant, Res-Tuning-Bypass, is proposed, which detaches tuners from the main branch to avoid back-propagation through the backbone and enables one-time backbone forward for multi-task inference. Extensive experiments demonstrate superior efficacy and efficiency on both discriminative (e.g., VTAB-1K) and generative tasks (text-to-image generation), outperforming existing alternatives with significant reductions in memory consumption and inference time while maintaining competitive performance.",
    "Methodology": "Res-Tuning operates on a unified formulation where the output is a sum of the frozen pre-trained operation (OP) and a learnable Res-Tuner connected in parallel: x' = OP(x) + Res-Tuner(x). Existing PETL methods like prefix tuning, prompt tuning, and adapter tuning are theoretically and empirically re-formulated into this unbinding structure, often by expressing them as a weighted parallel combination of original and tuner-specific operations. The memory-efficient Res-Tuning-Bypass explicitly detaches the Res-Tuner bypass network from the main backbone, forming a sequence of tuners (`xbypass_l = λRes-Tuner(xl) + (1− λ)Res-Tuner(xbypass_l−1)`). This ensures gradients are only back-propagated to the tuners. The tuners within the bypass are categorized as horizontal (processing backbone output) and vertical (processing previous bypass output). The framework allows for flexible instantiation of Res-Tuners (e.g., prompt tuning for FFNs, adapters for MHA) and combinations (Single-, Dual-, Tri-Res-Tuner configurations).",
    "Experimental Setup": "The framework was evaluated across discriminative (transfer learning, few-shot learning, domain generalization) and generative (text-to-image generation) tasks. Backbone models include ViT-B/16 (ImageNet-21K), ViT-L/14 (CLIP), ConvNeXt, and ResNet-101 for discriminative tasks, and Stable Diffusion v1.5 (U-Net architecture) for generative tasks. Datasets for discriminative tasks include CIFAR-100, VTAB-1K (19 diverse visual classification tasks), FGVC-Aircraft, Food-101, Oxford Flowers, Oxford Pets, Stanford Cars (for few-shot), and ImageNet variants (ImageNet-1K, -V2, -Sketch, -A, -R for domain generalization). Generative tasks used COCO2017 for text-to-image and fine-grained datasets (Oxford Flowers, Food-101, NABirds, Stanford Dogs, Stanford Cars, SUN397) for instance-level fine-tuning. NLP tasks (SST2, MNLI) were included in ablations. Evaluation metrics were top-1 accuracy for discriminative tasks and FID score along with qualitative results for generative tasks. Baselines included traditional methods (full fine-tuning, linear probing), parameter-efficient methods (Adapter, LoRA, VPT, SSF, NOAH, AdaptFormer, MAM-Adapter), and memory-efficient methods (Side-Tuning, LST). Training used AdamW optimizer with cosine decay learning rate schedule, random cropping, and horizontal flipping augmentations. Experiments were conducted on A100 GPUs.",
    "Limitations": "The transfer ability of the proposed tuning paradigm is largely dependent on the performance and characteristics of the upstream pre-trained foundation model. A significant societal concern is the potential for illegal content within the upstream pre-training model to lead to the illegal use of the tuning methods developed.",
    "Future Research Directions": "The authors express hope that their discoveries will facilitate further research in the flexible and efficient tuning of large foundation models. The inherent flexibility of the Res-Tuning framework suggests future work could involve exploring new tuner designs, more complex combinations of existing and novel tuners (as explicitly mentioned by the potential for 'New-Tuning' and 'Mix-Tuning'), and applying the unbinding and bypass mechanisms to a wider array of model architectures and downstream tasks beyond those explored in the paper.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "ReFT: Representation Finetuning for Language Models",
    "Main Contributions": "The paper introduces Representation Finetuning (ReFT), a novel family of parameter-efficient finetuning (PEFT) methods that adapt large language models by learning task-specific interventions on frozen hidden representations instead of modifying model weights. The authors define a strong instance, Low-rank Linear Subspace ReFT (LoReFT), and an ablation, DiReFT, which are significantly more parameter-efficient (15x–65x fewer parameters than LoRA) while achieving competitive or state-of-the-art performance across commonsense reasoning, arithmetic reasoning, instruction-following, and natural language understanding benchmarks. A generic ReFT training library is also publicly released.",
    "Methodology": "ReFT methods intervene on hidden representations during the model's forward pass. An intervention is defined by a function (Φ), a set of input positions (P), and a layer (l). LoReFT, a specific instance of ReFT, builds on distributed alignment search (DAS) and defines its intervention function as ΦLoReFT(h) = h + R⊺(Wh + b − Rh), where R is a low-rank projection matrix with orthonormal rows spanning an r-dimensional subspace, and W, b are learned linear projection parameters. The base LM's weights are frozen. DiReFT is an ablation of LoReFT, ΦDiReFT(h) = h + W⊺2 (W1h + b), which removes the orthogonality constraint and difference operation. Training objectives include cross-entropy loss for generation tasks and a classification head with cross-entropy loss for single-label classification tasks.",
    "Experimental Setup": "Experiments were conducted on LLaMA-family models (LLaMA-1 7B/13B, Llama-2 7B, Llama-3 8B) and smaller LMs (RoBERTa-base 125M, RoBERTa-large 350M). Benchmarks included eight commonsense reasoning datasets (COMMONSENSE 170K), four arithmetic reasoning datasets (MATH10K), instruction-following with Ultrafeedback evaluated via Alpaca-Eval v1.0 (win-rate against text-davinci-003 using GPT-4), and the GLUE benchmark for natural language understanding. Hyperparameters were tuned on dedicated development sets (e.g., GSM8K training subset, Alpaca-52K) to prevent test-set overfitting. Performance was compared against state-of-the-art PEFTs such as LoRA, DoRA, prefix-tuning, adapter-tuning, BitFit, and RED. All experiments were run on single NVIDIA A100 40G/80G or RTX 6000 GPUs, with models loaded in torch.bfloat16.",
    "Limitations": "The research primarily explored LLaMA-family models, suggesting a need to investigate ReFT's effectiveness on other model families and vision-language models (e.g., LLaVA). The large hyperparameter search space means ReFT's full capabilities have not yet been explored, indicating a need for automated search. There's a call for deeper exploration into the underlying reasons why ReFT works, specifically how interventions create new causal pathways or modify existing ones. The authors also highlight a general limitation in PEFT research regarding test-set 'hill-climbing' during hyperparameter tuning, advocating for new benchmarks that disallow this practice.",
    "Future Research Directions": "Future work includes exploring ReFT's effectiveness on a wider range of model families (beyond LLaMA) and vision-language models (e.g., LLaVA). Automating the hyperparameter search for ReFT is also a key direction. Deeper investigation into the causal mechanisms and pathways modified by ReFT interventions is suggested. The potential for more structured ReFTs to modify complex causal pathways, and the compositionality of learned orthogonal subspaces without adaptation, are areas for further study. Additionally, exploring LM personalization with ReFT in few-shot settings and introducing new benchmarks for PEFTs/ReFTs that prevent test-set tuning are proposed.",
    "Experiment Code": "class LoreftIntervention(\n    SourcelessIntervention,\n    TrainableIntervention,\n    DistributedRepresentationIntervention\n):\n    \"\"\"\n    LoReFT(h) = h + R^T(Wh + b \n\n\n    - Rh)\n    \"\"\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs, keep_last_dim=True)\n        rotate_layer = LowRankRotateLayer(\n            self.embed_dim, kwargs[\"low_rank_dimension\"], init_orth=True)\n        self.rotate_layer = torch.nn.utils.parametrizations.orthogonal(rotate_layer)\n        self.learned_source = torch.nn.Linear(\n            self.embed_dim, kwargs[\"low_rank_dimension\"]).to(\n            kwargs[\"dtype\"] if \"dtype\" in kwargs else torch.bfloat16)\n        self.dropout = torch.nn.Dropout(kwargs[\"dropout\"] if \"dropout\" in kwargs else 0.0)\n        self.act_fn = ACT2FN[\"linear\"] if \"act_fn\" not in kwargs or kwargs[\"act_fn\"] is None else ACT2FN[kwargs[\"act_fn\"]]\n        \n    def forward(\n        self, base, source=None, subspaces=None\n    ):\n        rotated_base = self.rotate_layer(base)\n        output = base + torch.matmul(\n            (self.act_fn(self.learned_source(base)) - rotated_base), self.rotate_layer.weight.T\n        )\n        return self.dropout(output.to(base.dtype))\n\n    def state_dict(self, *args, **kwargs):\n        \"\"\"\n        Overwrite for data-efficiency.\n        \"\"\"\n        state_dict = OrderedDict()\n        for k, v in self.learned_source.state_dict().items():\n            state_dict[k] = v\n        state_dict[\"rotate_layer\"] = self.rotate_layer.weight.data\n        return state_dict\n\n    def load_state_dict(self, state_dict, *args, **kwargs):\n        \"\"\"\n        Overwrite for data-efficiency.\n        \"\"\"\n        self.learned_source.load_state_dict(state_dict, strict=False)\n\n        # Caveat: without creating a new layer, it might not work (still not sure why)\n        # We have to recreate a layer, and load back the columns.\n        overload_w = state_dict[\"rotate_layer\"].to(\n            self.learned_source.weight.device)\n        overload_w_width = overload_w.shape[-1]\n        rotate_layer = LowRankRotateLayer(\n            self.embed_dim, overload_w_width, init_orth=True).to(\n            self.learned_source.weight.device)\n        self.rotate_layer = torch.nn.utils.parametrizations.orthogonal(rotate_layer)\n        self.rotate_layer.parametrizations.weight[0].base[:,:overload_w_width] = overload_w\n        assert torch.allclose(self.rotate_layer.weight.data, overload_w.data) == True # we must match!\n        \n        return",
    "Experiment Result": "The training is configured via the `finetune` function in `examples/loreft/train.py` which takes command-line arguments. Key experimental settings include:\n\n-   **Base Model:** `model` argument, defaults to `yahma/llama-7b-hf`.\n-   **Intervention Type:** `intervention_type` argument. For LoReFT, it is set to `LoreftIntervention`. For DiReFT, it corresponds to `NodireftIntervention` (defined as `h + W2^T(W1h + b)` which removes the orthogonality constraint and difference operation as described for DiReFT).\n-   **Intervention Layers:** `layers` argument, defaults to `2;10;18;26`. Can be 'all' for all hidden layers. If `position` indicates multiple positions (e.g., `f1+l1`) and `share_weights` is false, the number of layers is effectively doubled to allow separate interventions.\n-   **Low-Rank Dimension (r):** `rank` argument, defaults to `8`.\n-   **Intervention Position:** `position` argument, defaults to `f1+l1` (first token and last token). Also supports `fn` (first N tokens) or `ln` (last N tokens).\n-   **Epochs:** `epochs` argument, defaults to `1`.\n-   **Learning Rate:** `lr` argument, defaults to `5e-3`.\n-   **Learning Rate Scheduler:** `schedule` argument, defaults to `linear`.\n-   **Training Batch Size:** `batch_size` argument, defaults to `4` (`per_device_train_batch_size`).\n-   **Gradient Accumulation Steps:** `gradient_accumulation_steps` argument, defaults to `4`.\n-   **Weight Decay:** `weight_decay` argument, defaults to `0.00`.\n-   **Warmup Ratio:** `warmup_ratio` argument, defaults to `0.00`.\n-   **Dropout:** `dropout` argument, defaults to `0.00` for the intervention layers.\n-   **Activation Function:** `act_fn` argument, defaults to `None` (which implies a linear activation for the learned source in `LoreftIntervention` and `NodireftIntervention`).\n-   **Add Bias:** `add_bias` argument, defaults to `False` for intervention linear layers.\n-   **Maximum Sequence Length:** `max_length` argument, defaults to `512`.\n-   **Share Weights:** `share_weights` argument, defaults to `False`, controlling if intervention weights are shared across different intervention positions.\n-   **Data Type:** `dtype` argument, defaults to `bfloat16` on CUDA devices and `float32` otherwise.\n-   **Training Objective:**\n    -   For generation tasks (e.g., `alpaca`, `math`), `ReftTrainerForCausalLM` uses standard cross-entropy loss for language modeling on `shift_logits` and `shift_labels`.\n    -   For single-label classification tasks (e.g., `glue`), `ReftTrainerForSequenceClassification` uses cross-entropy loss. It can also use MSE loss for regression or BCEWithLogitsLoss for multi-label classification based on the problem type.\n-   **Base LM Weights:** Base LM weights are frozen by calling `reft_model.disable_model_gradients()`. For GLUE tasks, gradients can be optionally re-enabled for the classification head if `allow_cls_grad` is true."
}{
    "Title": "LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning",
    "Main Contributions": "The paper addresses the challenge of high memory requirements for fine-tuning large pre-trained models, a limitation not fully resolved by existing parameter-efficient transfer learning (PETL) methods. It proposes Ladder Side-Tuning (LST), a novel PETL technique that substantially reduces training memory by not requiring backpropagation through the large backbone network. LST trains a small, separate ladder side network that takes intermediate activations from the frozen backbone via shortcut \"ladders\" and makes predictions. Key findings show LST saves 69% of memory compared to full fine-tuning (2.7x more than Adapter and LoRA) while achieving competitive or superior accuracy on GLUE NLP tasks and various vision-and-language tasks (VQA, GQA, NLVR2, MSCOCO) using T5 and CLIP-T5 models, especially in low-memory regimes. It also demonstrates scalability to larger T5 models (T5-large, T5-3B) and improved efficiency through layer dropping and structural weight initialization.",
    "Methodology": "LST employs a separate, lightweight \"ladder side network\" which is a scaled-down version of the backbone transformer (with a reduction factor 'r'). This side network reuses frozen word embeddings and the language model head from the backbone. It incorporates \"gated ladder connections,\" which are shortcut connections that feed intermediate activations from the frozen backbone network into the side network. These activations are linearly projected to match the side network's lower dimensions, and a learned gating mechanism (\"\b5i*hf_i +(1 \b2 \b5i)*hg_i-1\") combines backbone information with the side network's internal representations. For initialization, LST uses \"structural weight initialization\" where side network weights are derived from a pruned version of the backbone network's weights, based on importance scores (e.g., Fisher Information or weight magnitude). Additionally, \"layer dropping\" is applied to the side network to further enhance parameter and memory efficiency by removing intermediate transformer layers.",
    "Experimental Setup": "LST was evaluated on Natural Language Processing (NLP) tasks using the GLUE benchmark (CoLA, SST-2, MRPC, QQP, MNLI, QNLI, RTE, STS-B) and Vision-and-Language (VL) tasks including Visual Question Answering (VQA, GQA), Visual Reasoning (NLVR2), and Image Captioning (MSCOCO). The backbone models used were T5 (T5-base, T5-large, T5-3B) for NLP and CLIP-T5 for VL tasks (with CLIP frozen). Baselines included Full fine-tuning, Adapters, LoRA, BitFit, and Prompt-tuning, as well as comparisons to the concurrent Y-tuning and the related Side-Tuning method. Evaluation metrics varied by task: accuracy for SST-2, MNLI, QNLI, RTE, VQA, GQA, NLVR2; Matthew's Correlation for CoLA; Pearson-Spearman Correlation for STS-B; and average F1/Accuracy for MRPC, QQP; and CIDEr for MSCOCO. Training involved 10 or 20 epochs, with learning rates searched and a reduction factor 'r' of 8 for NLP and 4 for VL. Layer dropping was applied to LST for larger T5 models to match memory usage of baselines. Ablation studies were conducted on initialization strategies (Random, Weight Magnitude, Fisher Information), side network layer designs (Transformer blocks with gates/cross-attention, Adapter blocks with gates), and the utility of intermediate shortcut connections.",
    "Limitations": "The paper extensively focuses on demonstrating LST's advantages and how it overcomes the limitations of previous PETL methods, rather than explicitly stating its own weaknesses or constraints. The closest to a limitation mentioned is that during inference, LST involves forward propagation through two distinct networks (backbone and side network), but the authors immediately mitigate this by stating it \"does not necessarily use more inference time because the same level of the backbone network and the side network can be computed in parallel.\" No other explicit limitations, weaknesses, or assumptions of LST are detailed within the paper.",
    "Future Research Directions": "A key future research direction explicitly mentioned is the potential to combine LST with other memory-efficient training methods, such as reversible neural networks and gradient checkpointing. The authors state that these methods are \"agnostic to memory saving from LST,\" suggesting that combining them could lead to \"a higher level of memory efficiency.\" The paper also expresses a general hope that LST will help users with limited computational resources tune larger models across diverse domains.",
    "Experiment Code": "def construct_side_network(self, config, side_config, num_layers, LAYER_TYPE, gate_name):\n        side_transformers_config = copy.deepcopy(config)\n\n        side_transformers_config.intermediate_size = side_transformers_config.intermediate_size // side_config.reduction_factor\n        side_transformers_config.hidden_size = side_transformers_config.hidden_size // side_config.reduction_factor\n\n        side_layers = side_config.encoder_side_layers\n\n        if side_config.add_side_visual_projection:\n            self.side_visn_fc = VisualFeatEncoder(config)\n        else:\n            self.side_visn_fc = None\n\n        if side_layers is None:\n            # add every layer\n            side_layers = list(range(num_layers))\n        else:\n            side_layers = eval(side_layers)\n\n        side_block = nn.ModuleList(\n            [LAYER_TYPE(side_transformers_config)\n                    if i in side_layers else None\n                    for i in range(num_layers)]\n        )\n\n        self.add_residual_after = side_config.add_residual_after\n        \n        side_first_downsample = nn.Linear(config.hidden_size, side_transformers_config.hidden_size, bias=False)\n\n        if side_config.side_downsample_pool:\n            side_downsamples = nn.ModuleList(\n                [nn.AdaptiveAvgPool1d(side_transformers_config.hidden_size)\n                if i in side_layers else None\n                for i in range(num_layers)]\n            )\n        else:\n            side_downsamples = nn.ModuleList(\n                [nn.Linear(config.hidden_size, side_transformers_config.hidden_size, bias=False) \n                if i in side_layers else None\n                for i in range(num_layers)]\n            )\n\n        side_final_upsample = nn.Linear(side_transformers_config.hidden_size, config.hidden_size, bias=False)\n\n        self.use_gate = side_config.use_gate\n        side_gate_params = None\n        if self.use_gate == \"learnable\":\n            # Parameter list cannot contain None\n            side_gate_params = nn.ParameterList(\n                [nn.Parameter(torch.ones(1) * side_config.gate_alpha) \n                for i in range(num_layers)]\n            )\n\n            self.gate_T = side_config.gate_T\n        elif \"schedule\" in self.use_gate or self.use_gate == \"one\":\n            for i in range(num_layers):\n                self.register_buffer(f'side_gate_{gate_name}' + str(i), torch.ones(1))\n        elif self.use_gate == \"none\":\n            pass\n        else:\n            raise NotImplementedError\n\n        return side_block, side_first_downsample, side_final_upsample, side_downsamples, side_gate_params\n\n    def merge_backbone_to_side(self, side_hidden_states, backbone_hidden_states, gate_name, idx):\n        if self.use_gate == \"learnable\":\n            side_gate_param = getattr(self, f\"side_gate_params_{gate_name}\")[idx]\n            gate = torch.sigmoid(side_gate_param / self.gate_T)\n            side_hidden_states = gate * side_hidden_states + (1 - gate) * backbone_hidden_states # add the information from the backbone network\n        elif \"schedule\" in self.use_gate or self.use_gate == \"one\":\n            gate = getattr(self, f\"side_gate_{gate_name}{idx}\")\n            side_hidden_states = gate * side_hidden_states + (1 - gate) * backbone_hidden_states\n        else:\n            side_hidden_states = side_hidden_states + backbone_hidden_states\n\n        return side_hidden_states\n\n    def forward(self, lang_feats, lang_attention_mask,\n                visn_feats, visn_attention_mask=None, task=None):\n        if VISUAL_CONFIG.vilt_style:\n            assert(not VISUAL_CONFIG.freeze_clip)\n            if VISUAL_CONFIG.use_clip:\n                images, boxes = visn_feats\n                lang_attention_mask = lang_attention_mask.squeeze(1).squeeze(1)\n                lang_attention_mask[lang_attention_mask!=0] = float(\"-inf\")\n\n                joint_feats = self.visual_model.visual(images.type(self.visual_model.dtype), skip_last_layer=True, text_embedding = lang_feats, text_mask=lang_attention_mask)\n                return _split_with_none(lang_feats, images, joint_feats)\n            elif VISUAL_CONFIG.use_vit:\n                images, boxes = visn_feats\n                joint_feats = self.visual_model(\n                    images,\n                    return_features=True,\n                    text_embedding=lang_feats,\n                    text_mask=lang_attention_mask)\n                return _split_with_none(lang_feats, images, joint_feats)\n\n        if VISUAL_CONFIG.use_clip:\n            images, boxes = visn_feats\n            visn_feats = self.visual_model.visual(images.type(self.visual_model.dtype), skip_last_layer=True)\n\n            if \"RN\" in VISUAL_CONFIG.clip_model_name:\n                if VISUAL_CONFIG.use_max_pooling:\n                    visn_feats = self.max_pooling(visn_feats)\n\n                if VISUAL_CONFIG.use_positional_embedding:\n                    visn_feats = self.visual_pos(visn_feats)\n                else:\n                    visn_feats = visn_feats.permute(0, 2, 3, 1).view(visn_feats.size(0), -1, visn_feats.size(1))\n                \n            # Cast back to fp32\n            visn_feats = visn_feats.to(dtype=next(self.visn_fc.parameters()).dtype)\n        elif VISUAL_CONFIG.use_vit:\n            images, boxes = visn_feats\n            visn_feats = self.visual_model(images, return_features=True)\n            visn_feats = visn_feats.to(dtype=next(self.visn_fc.parameters()).dtype)\n        elif VISUAL_CONFIG.drop_boxes:\n            visn_feats, boxes = visn_feats\n        \n        if VISUAL_CONFIG.sub_sampling:\n            # visn_feats: batch x seq_len x 768\n\n            sub_feat_num = VISUAL_CONFIG.sub_feat_num\n            sampled_index = []\n            for i in range(visn_feats.size(0)):\n                sampled_index.append(torch.from_numpy(np.random.choice(visn_feats.size(1), sub_feat_num, replace=False)))\n            sampled_index = torch.stack(sampled_index, dim=0).unsqueeze(-1).expand(visn_feats.size(0), sub_feat_num, visn_feats.size(2)).long().to(visn_feats.device)  # batch x sub_feat_num x 768?\n            visn_feats = torch.gather(visn_feats, 1, sampled_index)\n            \n        # Run visual embedding layer\n        # Note: Word embedding layer was executed outside this module.\n        #       Keep this design to allow loading BERT weights.\n\n        pre_visn_feats = visn_feats\n        visn_feats = self.visn_fc(visn_feats)\n\n        if visn_attention_mask is None:\n            visn_attention_mask = torch.zeros(visn_feats.size(0), visn_feats.size(1)).to(dtype=next(self.visn_fc.parameters()).dtype).to(next(self.visn_fc.parameters()).device)\n            visn_attention_mask = visn_attention_mask.unsqueeze(1).unsqueeze(2)\n\n        if VISUAL_CONFIG.visualbert_style:\n            joint_feats = _cat_with_none(lang_feats, visn_feats, dim=1) #torch.cat((lang_feats, visn_feats), dim=1)\n            joint_mask = _cat_with_none(lang_attention_mask, visn_attention_mask, dim=-1)  #torch.cat((lang_attention_mask, visn_attention_mask), dim=-1)\n            all_attention_weights = []\n\n            if self.train_side_transformer and self.side_visn_fc is not None:\n                side_visn_feats = self.side_visn_fc(pre_visn_feats)\n                side_joint_feats = _cat_with_none(lang_feats, side_visn_feats, dim=1)\n            else:\n                side_joint_feats = joint_feats\n\n            side_hidden_states = self.side_first_downsample_l(side_joint_feats) if self.train_side_transformer else None\n\n            if self.detach_visual_projection:\n                joint_feats = joint_feats.detach()\n            for idx, layer_module in enumerate(self.layer):\n                #if args.get(\"output_attention\", False):\n                #    joint_feats, attention_weights = layer_module(joint_feats, joint_mask)\n                #    all_attention_weights.append(attention_weights)\n                #else:\n                joint_feats = layer_module(joint_feats, joint_mask, task)\n\n                if self.train_side_transformer:\n                    side_layer_module = self.side_block_l[idx]\n\n                    if side_layer_module is not None:\n                        if not self.add_residual_after:\n                            backbone_hidden_states = self.side_downsamples_l[idx](joint_feats)\n                            side_hidden_states = self.merge_backbone_to_side(side_hidden_states, backbone_hidden_states, \"l\", idx)\n                        \n                        side_hidden_states = side_layer_module(side_hidden_states, joint_mask, task)\n\n                        if self.add_residual_after:\n                            backbone_hidden_states = self.side_downsamples_l[idx](joint_feats)\n                            side_hidden_states = self.merge_backbone_to_side(side_hidden_states, backbone_hidden_states, \"l\", idx)\n\n            if self.train_side_transformer:\n                joint_feats = self.side_final_upsample_l(side_hidden_states)\n            #if args.get(\"output_attention\", False):\n            #    return _split_with_none(lang_feats, visn_feats, joint_feats), all_attention_weights\n            return _split_with_none(lang_feats, visn_feats, joint_feats)\n        else:\n            # Run language layers\n\n            side_lang_feats = self.side_first_downsample_l(lang_feats) if self.train_side_transformer else None\n\n            for idx, layer_module in enumerate(self.layer):\n                lang_feats = layer_module(lang_feats, lang_attention_mask, task)\n\n                if self.train_side_transformer:\n                    side_layer_module = self.side_block_l[idx]\n\n                    if side_layer_module is not None:\n                        if not self.add_residual_after:\n                            backbone_hidden_states = self.side_downsamples_l[idx](lang_feats)\n                            side_lang_feats = self.merge_backbone_to_side(side_lang_feats, backbone_hidden_states, \"l\", idx)\n\n                        side_lang_feats = side_layer_module(side_lang_feats, joint_mask, task)\n\n                        if self.add_residual_after:\n                            backbone_hidden_states = self.side_downsamples_l[idx](lang_feats)\n                            side_lang_feats = self.merge_backbone_to_side(side_lang_feats, backbone_hidden_states, \"l\", idx)\n\n            side_visn_feats = self.side_first_downsample_r(visn_feats) if self.train_side_transformer else None\n\n            # Run relational layers\n            for idx, layer_module in enumerate(self.r_layers):\n                visn_feats = layer_module(visn_feats, visn_attention_mask, task)\n\n                if self.train_side_transformer:\n                    side_layer_module = self.side_block_r[idx]\n                    if side_layer_module is not None:\n                        if not self.add_residual_after:\n                            backbone_hidden_states = self.side_downsamples_r[idx](visn_feats)\n                            side_visn_feats = self.merge_backbone_to_side(side_visn_feats, backbone_hidden_states, \"r\", idx)  \n\n                        side_visn_feats = side_layer_module(side_visn_feats, joint_mask, task)\n\n                        if self.add_residual_after:\n                            backbone_hidden_states = self.side_downsamples_r[idx](visn_feats)\n                            side_visn_feats = self.merge_backbone_to_side(side_visn_feats, backbone_hidden_states, \"r\", idx)\n\n            # Run cross-modality layers\n            for idx, layer_module in enumerate(self.x_layers):\n                lang_feats, visn_feats = layer_module(lang_feats, lang_attention_mask,\n                                                    visn_feats, visn_attention_mask, task)\n\n                if self.train_side_transformer:\n                    side_layer_module = self.side_block_x[idx]\n                    if side_layer_module is not None:\n                        if not self.add_residual_after:\n                            side_lang_feats = self.merge_backbone_to_side(side_lang_feats, self.side_downsamples_x[idx](lang_feats), \"x\", idx)\n                            side_visn_feats = self.merge_backbone_to_side(side_visn_feats, self.side_downsamples_x[idx](visn_feats), \"x\", idx)\n                        \n                        side_lang_feats, side_visn_feats = side_layer_module(side_lang_feats, lang_attention_mask,\n                                                                            side_visn_feats, visn_attention_mask, task)\n\n                        if self.add_residual_after:\n                            side_lang_feats = self.merge_backbone_to_side(side_lang_feats, self.side_downsamples_x[idx](lang_feats), \"x\", idx)\n                            side_visn_feats = self.merge_backbone_to_side(side_visn_feats, self.side_downsamples_x[idx](visn_feats), \"x\", idx)\n\n            if self.train_side_transformer:\n                lang_feats = self.side_final_upsample_l(side_lang_feats)\n                visn_feats = self.side_final_upsample_r(side_visn_feats)\n\n        return lang_feats, visn_feats",
    "Experiment Result": "The Ladder Side Network (LST) employs a scaled-down version of the backbone transformer, integrating 'gated ladder connections' and 'structural weight initialization' with optional 'layer dropping'.\n\n**Network Structure & Integration (from `CLIP-ViL/src/lxrt/modeling.py`):**\n- `LXRTEncoder.construct_side_network` method builds the side network components:\n    - `side_transformers_config`: A deep copy of the main model's config, with `intermediate_size` and `hidden_size` reduced by `side_config.reduction_factor`.\n    - `side_block`: An `nn.ModuleList` containing `LAYER_TYPE` (e.g., `BertLayer`, `LXRTXLayer`) instances for specified `encoder_side_layers`. If `encoder_side_layers` is None, all layers are added.\n    - `side_first_downsample`: A linear layer to project the backbone's initial hidden state to the side network's reduced dimension.\n    - `side_downsamples`: A list of linear layers or `nn.AdaptiveAvgPool1d` (if `side_config.side_downsample_pool` is True) to project intermediate backbone hidden states to the side network's dimension.\n    - `side_final_upsample`: A linear layer to project the side network's final hidden state back to the backbone's dimension.\n    - `side_gate_params`: If `use_gate` is 'learnable', an `nn.ParameterList` of learnable gate parameters, initialized with `side_config.gate_alpha`.\n- `LXRTEncoder.merge_backbone_to_side` method implements the gated ladder connections:\n    - Combines `side_hidden_states` and `backbone_hidden_states` using a learned gate `gate * side_hidden_states + (1 - gate) * backbone_hidden_states`.\n    - The `gate` can be 'learnable' (sigmoid of `side_gate_param / gate_T`), 'schedule', 'one', or 'none'.\n- The `LXRTEncoder.forward` method integrates the side network's computation within the main transformer layers (language, relational, and cross-modality layers) by conditionally updating `side_lang_feats`, `side_visn_feats`, or `side_hidden_states` and merging them with backbone features at each step.\n\n**Structural Weight Initialization (from `CLIP-ViL/src/pruning/`):**\n- `pruning_without_residual` function (from `pruning_methods_bert.py`) performs the actual pruning of backbone weights to initialize the side network.\n    - It takes a `model`, `reduction_factor`, `importance_measure` (optional, for score-based pruning), `version`, `num_heads`, and `iterations`.\n    - It uses `L1Strategy` or `AttnL1Strategy` (depending on `version`) to select pruning indices.\n    - The function iterates through ordered layers, applying `select_weights` to prune parameters based on calculated importance scores and `prune_val` (derived from `reduction_factor`).\n- `compute_fisher` function (from `fisher.py`) calculates importance scores (Fisher Information) for structural weight initialization.\n    - It takes a `model`, `task`, `train_dataset`, `data_collator`, `num_samples`, `cuda_device`, and `grad_type` ('square' or 'absolute').\n    - It computes gradients for a subset of samples and accumulates `grad_method(param.grad).data` in `gradients_dict`.\n\n**Configuration & Experimental Settings:**\n\n**`CLIP-ViL/src/lxrt/side_transformers/config.py` (SideConfig defaults):**\n- `task_reduction_factor`: 8 (reduction factor 'r').\n- `encoder_side_layers`: `None` (all layers are considered).\n- `add_residual_after`: `False`.\n- `use_gate`: `\"learnable\"`.\n- `gate_alpha`: `0`.\n- `gate_T`: `0.1`.\n- `side_downsample_pool`: `False`.\n\n**`CLIP-ViL/src/param.py` (Command-line arguments from `parse_args`):**\n- `--use_side_transformers`: `action='store_true'` to enable the side network.\n- `--reduction_factor`: `type=int, default=16` (used for `task_reduction_factor`).\n- `--encoder_side_layers`: `type=str, default=None` (e.g., `'[0, 2, 4]'` for layer dropping).\n- `--use_gate`: `action='store_true'` (enables a learnable gate by default) or can be other values like 'one', 'schedule', 'none'.\n- `--load_side_pretrained_weights`: `default=''` (path to load pruned weights, e.g., containing 'fisher' or 'bert' keyword for importance-based initialization).\n- `--samples_for_fisher`: `type=int, default=1024` (number of samples to use for Fisher Information calculation).\n- `--detach_visual_projection`: `action='store_true'`.\n- `--add_side_visual_projection`: `action='store_true'`.\n- `--add_residual_after`: `action='store_true'`.\n- `--gate_alpha`: `type=float, default=0`.\n- `--gate_T`: `type=float, default=0.1`.\n- `--side_downsample_pool`: `action='store_true'`.\n\n**Initialization and Training Flow (e.g., from `src/tasks/gqa.py` `Trainer` class):**\n- `Trainer.create_side_network_initial_weights` method:\n    - Temporarily sets `self.args.use_side_transformers = False` to instantiate a base model (without the side network) for importance calculation.\n    - If `\"fisher\"` is in `self.args.load_side_pretrained_weights`, it calls `compute_fisher` to calculate importance measures.\n    - Calls `pruning_without_residual` (or similar method) on the base model with the specified `reduction_factor` and `importance_measure` to obtain `pruned_state_dict`.\n    - Deletes the temporary base model to save memory.\n- `Trainer.initialize_side_network` method (from `src/tasks/trainer_base.py`):\n    - Copies pruned weights from `pruned_state_dict` to the newly initialized side network modules (`side_visn_fc`, `side_block_l`, `side_block_r`, `side_block_x`) in the main model.\n- `Trainer.unfreeze_parameters` method (from `src/tasks/trainer_base.py`):\n    - Unfreezes all parameters with \"side\" in their name, making them trainable. Other components like `logit_fc` and biases are also made trainable under certain conditions.\n- `Trainer.print_trainable_params_percentage` (from `src/tasks/trainer_base.py`): Reports the percentage of trainable parameters after freezing/unfreezing, providing an efficiency metric for LST."
}{
    "Title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data",
    "Main Contributions": "The paper proposes Conditionally Adaptive Multi-Task Learning (CA-MTL) to address challenges in Multi-Task Learning (MTL) such as overfitting to low-resource tasks, catastrophic forgetting, and negative task transfer. The main contributions include a novel Transformer-based Adapter with a new conditional attention mechanism and task-conditioned modules that facilitate weight sharing and mitigate forgetting by fixing half of the pretrained model weights. Additionally, a new uncertainty-based multi-task data sampling strategy is introduced to mitigate the negative effects of data imbalance across tasks. CA-MTL is shown to surpass single-task fine-tuning and other adapter methods while being parameter and data efficient, achieving state-of-the-art results on several NLP tasks and demonstrating superior performance across up to 26 tasks.",
    "Methodology": "CA-MTL's methodology comprises two main components: a Task Conditioned Transformer and Multi-Task Uncertainty Sampling. The Task Conditioned Transformer adapts and modulates pretrained weights using task-specific embeddings through Conditional Weight Transformations. This includes a Conditional Attention module with a block-diagonal conditional matrix to account for task-specific biases, a Conditional Alignment layer inserted between the input embedding and the first Transformer layer to align data of diverse tasks, a Conditional Layer Normalization module to adapt layer normalization statistics, and a Conditional Bottleneck (two-layer feed-forward) to facilitate weight sharing and task-specific information flow. The Multi-Task Uncertainty Sampling algorithm, inspired by Active Learning, uses Shannon Entropy to prioritize tasks. It evaluates model uncertainty to select training examples, normalizing uncertainty measures to account for differing numbers of prediction classes and favoring tasks with higher uncertainty, thereby helping balance task sampling and prevent catastrophic forgetting.",
    "Experimental Setup": "The experiments were conducted using a CA-MTL implementation based on HuggingFace, utilizing BERTBASE, BERTLARGE, and RoBERTaLARGE models. The bottom half of the Transformer layers were frozen to preserve pretrained knowledge, with ablation studies performed on different freezing configurations. Evaluation datasets included GLUE (8 tasks), Super-GLUE (8 tasks), MRQA (6 tasks), WNUT2017 (NER), SciTail, and SNLI, totaling up to 26 NLP tasks. The models were trained with a batch size of 32, Adam optimizer (learning rate 2e-5, warm-up over first 10% steps), 5-8 epochs, sequence length of 128-256, and a dropout rate of 0.1, without parameter search, model ensembles, or task-specific tricks. Performance was validated by comparing average GLUE scores, Task sigma (standard deviation across tasks), covariance similarity scores, and specific task metrics (F1, accuracy, Spearman/Matthew's correlation) against single-task fine-tuning, vanilla MTL baselines, and other adapter networks. Domain adaptation was tested in low-resource settings (0.1% to 100% of data) on SciTail and SNLI with new linear decoder heads and various task embedding initializations.",
    "Limitations": "One limitation is that CA-MTL's performance during zero-shot transfer to new tasks is sensitive to the initialization of the new task's embedding. While freezing half of the pretrained layers was a design choice to preserve knowledge for a large number of tasks, this configuration slightly lowered performance on a subset of 9 GLUE tasks compared to fully unfrozen models. Additionally, for the NER task (WNUT2017), CA-MTL did not fully close the performance gap with single-task baselines, with the authors noting that it 'had not yet overfit on this particular task and could have closed the gap with the ST baselines with more training cycles,' implying potential for further optimization or longer training. The Evolutionary Data Measures (EDM) used to estimate task difficulty were also noted to lack precision for regression-like values, being more effective at assigning a class of difficulty.",
    "Future Research Directions": "The paper concludes by stating that 'Extending such ideas will be an objective for future work.' This broadly suggests further exploration and development of task-conditioned adaptive learning approaches for dynamically adapting and modularizing knowledge embedded in large monolithic pretrained models. Specific directions are not explicitly detailed beyond this general statement.",
    "Experiment Code": "File Path: src/model/ca_mtl.py\nContent:\nimport re\nimport logging\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional\n\nimport torch\nimport torch.nn as nn\nfrom transformers import BertPreTrainedModel\n\nfrom src.model.decoder import Decoder\nfrom src.model.encoders.bert import _BertEncoder\nfrom src.model.encoders.ca_mtl_base import CaMtlBaseEncoder\nfrom src.model.encoders.ca_mtl_large import CaMtlLargeEncoder\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass CaMtlArguments:\n    \"\"\"\n    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n    \"\"\"\n\n    model_name_or_path: str = field(\n        metadata={\n            \"help\": \"Path to pretrained model or model identifier from: CA-MTL-base, CA-MTL-large, bert-base-cased \"\n                    \"bert-base-uncased, bert-large-cased, bert-large-uncased\"\n        }\n    )\n    freeze_encoder_layers: str = field(\n        default=None,\n        metadata={\"help\": \"Freeze encoder layers. format: <start_layer>-<end_layer>\"},\n    )\n\n\nclass CaMtl(BertPreTrainedModel):\n    def __init__(\n        self,\n        config,\n        model_args,\n        data_args,\n    ):\n        super().__init__(config)\n\n        self.data_args = data_args\n        self.bert = self._create_encoder(model_args.model_name_or_path)\n        self.decoders = nn.ModuleList()\n        for task in data_args.tasks:\n            self.decoders.append(Decoder(config.hidden_size, task))\n\n        self.init_weights()\n\n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None,\n        labels=None,\n        task_id=None,\n        span_locs=None,\n        sample_id=None,\n    ):\n\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=inputs_embeds,\n            task_id=task_id,\n        )\n\n        sequence_output, pooled_output = outputs[:2]\n\n        loss_list = []\n        unique_task_ids = torch.unique(task_id)\n        unique_task_ids_list = (\n            unique_task_ids.cpu().numpy()\n            if unique_task_ids.is_cuda\n            else unique_task_ids.numpy()\n        )\n        loss_grouped_per_task = (\n            torch.zeros_like(task_id[0]).repeat(len(self.data_args.tasks)).float()\n        )\n        batch_entropy_per_task = torch.zeros(input_ids.shape[0])\n        batch_entropy_mean_per_task = torch.zeros(input_ids.shape[0])\n        max_mean_batch_entropy = None\n        logits = None\n        for unique_task_id in unique_task_ids_list:\n            task_id_filter = task_id == unique_task_id\n            decoder_id = unique_task_id\n            logits, current_loss, batch_entropy = self.decoders[decoder_id].forward(\n                sequence_output[task_id_filter],\n                pooled_output[task_id_filter],\n                labels=None if labels is None else labels[task_id_filter],\n                attention_mask=attention_mask[task_id_filter],\n            )\n\n            batch_entropy_mean = batch_entropy.mean().item()\n            batch_entropy_per_task[task_id_filter] = batch_entropy\n            batch_entropy_mean_per_task[task_id_filter] = torch.full_like(\n                batch_entropy, batch_entropy_mean\n            )\n            if (\n                max_mean_batch_entropy is None\n                or batch_entropy_mean > max_mean_batch_entropy\n            ):\n                max_mean_batch_entropy = batch_entropy_mean\n\n            if labels is not None:\n                loss_grouped_per_task[unique_task_id] = current_loss\n                loss_list.append(current_loss)\n\n        outputs = (\n            (logits)\n            + outputs[2:]\n            +\n            (\n                batch_entropy_per_task,\n                batch_entropy_mean_per_task,\n                max_mean_batch_entropy,\n            )\n        )\n\n        if loss_list:\n            loss = torch.stack(loss_list)\n            outputs = (loss.mean(),) + outputs + (loss_grouped_per_task.view(1, -1),)\n\n        return outputs\n\n    def _create_encoder(self, model_name_or_path):\n        if model_name_or_path == \"CA-MTL-large\":\n            return CaMtlLargeEncoder(self.config, data_args=self.data_args)\n        elif model_name_or_path == \"CA-MTL-base\":\n            return CaMtlBaseEncoder(self.config, data_args=self.data_args)\n        else:\n            return _BertEncoder(self.config)\n\n    @staticmethod\n    def get_base_model(model_name_or_path):\n        if model_name_or_path == \"CA-MTL-large\":\n            return \"bert-large-cased\"\n        elif model_name_or_path == \"CA-MTL-base\":\n            return \"bert-base-cased\"\n        else:\n            return model_name_or_path\n\n    def freeze_encoder_layers(\n        self,\n        model_args,\n        unfrozen_modules=[\n            \"random_weight_matrix\",\n            \"film.gb_weights\",\n            \"ln_weight_modulation.gb_weights\",\n            \"adapter\",\n        ],\n    ):\n        if model_args.freeze_encoder_layers is not None:\n            start_layer, end_layer = model_args.freeze_encoder_layers.split(\"-\")\n\n            for name, param in self.bert.named_parameters():\n                requires_grad = True\n                match = re.match(self.bert.get_layer_regexp(), name)\n                if match:\n                    layer_number = int(match.groups()[0])\n                    requires_grad = not int(start_layer) <= layer_number <= int(\n                        end_layer\n                    ) or any([module in match.string for module in unfrozen_modules])\n                elif name.startswith(\"embedding\"):\n                    requires_grad = False\n                param.requires_grad = requires_grad\n\n        for name, param in self.bert.named_parameters():\n            logger.info(\n                \"%s - %s\", name, (\"Unfrozen\" if param.requires_grad else \"FROZEN\")\n            )\n\nFile Path: src/model/decoder.py\nContent:\nimport torch\nimport numpy\nfrom scipy.stats import entropy\nfrom transformers import glue_tasks_num_labels\nfrom torch.nn import MSELoss, CrossEntropyLoss, Softmax, Dropout, Linear, Softmax\n\n\nclass Decoder(torch.nn.Module):\n    def __init__(self, hidden_size, task_name):\n        super().__init__()\n        self.num_labels = glue_tasks_num_labels[task_name]\n        self.dropout = Dropout(0.1)\n        self.model = Linear(hidden_size, self.num_labels)\n\n    def forward(self, sequence_output, pooled_output, labels=None, **kwargs):\n        loss = None\n        pooled_output = self.dropout(pooled_output)\n        logits = self.model(pooled_output)\n\n        batch_entropy = self.calculate_entropy(logits)\n\n        if labels is not None:\n            if self.num_labels == 1:\n                #  We are doing regression\n                loss_fct = MSELoss()\n                loss = loss_fct(logits.view(-1), labels.float().view(-1))\n            else:\n                loss_fct = CrossEntropyLoss()\n                loss = loss_fct(logits.view(-1, self.num_labels), labels.long().view(-1))\n\n        return logits, loss, batch_entropy\n\n    def calculate_entropy(self, logits):\n        probas = Softmax(dim=1)(logits.detach())\n        samples_entropy = entropy(probas.transpose(0, 1).cpu())\n        even_preds = numpy.array(\n            [[1 / self.num_labels for _ in range(self.num_labels)]]\n        )\n        max_entropy = entropy(even_preds.T)\n        epsilon = 1e-5\n        samples_entropy = samples_entropy / (max_entropy.item() + epsilon)\n        return torch.tensor(samples_entropy)\n\nFile Path: src/model/encoders/ca_mtl_base.py\nContent:\nimport math\nimport torch\nimport torch.nn as nn\nfrom transformers.modeling_bert import (\n    BertEmbeddings,\n    BertPooler,\n    BertPreTrainedModel,\n    BertAttention,\n    BertIntermediate,\n    BertLayer,\n    BertSelfOutput,\n)\n\nfrom src.model.encoders.conditional_modules import FiLM, CBDA, ConditionalBottleNeck, ConditionalLayerNorm\n\n\nclass MyBertSelfAttention9(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(\n            config, \"embedding_size\"\n        ):\n            raise ValueError(\n                \"The hidden size (%d) is not a multiple of the number of attention \"\n                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n            )\n        self.output_attentions = config.output_attentions\n\n        self.num_attention_heads = config.num_attention_heads\n        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n        self.all_head_size = self.num_attention_heads * self.attention_head_size\n\n        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n\n        self.max_seq_length = config.max_seq_length\n        assert config.hidden_size % self.max_seq_length == 0, \\\n            \"Block decomposed attention will only work if this condition is met.\"\n        self.num_blocks = config.hidden_size//self.max_seq_length\n        self.cond_block_diag_attn = CBDA(\n            config.hidden_size, math.ceil(self.max_seq_length/self.num_blocks), self.num_blocks\n        )  # d x L/N\n\n        self.random_weight_matrix = nn.Parameter(\n            torch.zeros(\n                [config.max_seq_length, math.ceil(self.max_seq_length/self.num_blocks)]\n            ),\n            requires_grad=True,\n        )\n\n    def transpose_for_scores(self, x):\n        new_x_shape = x.size()[:-1] + (\n            self.num_attention_heads,\n            self.attention_head_size,\n        )\n        x = x.view(*new_x_shape)\n        return x.permute(0, 2, 1, 3)\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n    ):\n\n        # If this is instantiated as a cross-attention module, the keys\n        # and values come from an encoder; the attention mask needs to be\n        # such that the encoder's padding tokens are not attended to.\n        if encoder_hidden_states is not None:\n            mixed_value_layer = self.value(encoder_hidden_states)\n            attention_mask = encoder_attention_mask\n        else:\n            mixed_value_layer = self.value(hidden_states)\n\n        value_layer = self.transpose_for_scores(mixed_value_layer)\n\n        mixed_key_layer = self.key(hidden_states)\n        mixed_query_layer = self.query(hidden_states)\n        key_layer = self.transpose_for_scores(mixed_key_layer)\n        query_layer = self.transpose_for_scores(mixed_query_layer)\n        attention_scores1 = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n        attention_scores1 = attention_scores1 / math.sqrt(self.attention_head_size)\n\n        attention_scores2 = self.cond_block_diag_attn(\n            x_cond=task_embedding,\n            x_to_film=self.random_weight_matrix,\n        )\n\n        attention_scores = attention_scores1 + attention_scores2.unsqueeze(1)\n\n        # b x seq len x hid dim\n\n        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n        if attention_mask is not None:\n            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n            attention_scores = attention_scores + attention_mask\n\n        # y = ax + b(task_emb)\n        # Normalize the attention scores to probabilities.\n        attention_probs = nn.Softmax(dim=-1)(\n            attention_scores\n        )  # b x num heads x seq length x head dim\n\n        # This is actually dropping out entire tokens to attend to, which might\n        # seem a bit unusual, but is taken from the original Transformer paper.\n        attention_probs = self.dropout(attention_probs)\n\n        # Mask heads if we want to\n        if head_mask is not None:\n            attention_probs = attention_probs * head_mask\n\n        context_layer = torch.matmul(attention_probs, value_layer)\n\n        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n        context_layer = context_layer.view(*new_context_layer_shape)\n\n        outputs = (\n            (context_layer, attention_probs)\n            if self.output_attentions\n            else (context_layer,)\n        )\n        return outputs\n\n\nclass MyBertSelfOutput9(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n        self.LayerNorm = ConditionalLayerNorm(config.hidden_size, config.hidden_size, eps=config.layer_norm_eps)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n\n    def forward(self, hidden_states, input_tensor, task_embedding, task_id):\n        hidden_states = self.dense(hidden_states)\n        hidden_states = self.dropout(hidden_states)\n        hidden_states = self.LayerNorm(hidden_states + input_tensor, task_embedding, task_id)\n        return hidden_states\n\n\nclass MyBertOutput9(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n        self.LayerNorm = ConditionalLayerNorm(config.hidden_size, config.hidden_size, eps=config.layer_norm_eps)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n\n    def forward(self, hidden_states, input_tensor, task_embedding, task_id):\n        hidden_states = self.dense(hidden_states)\n        hidden_states = self.dropout(hidden_states)\n        hidden_states = self.LayerNorm(hidden_states + input_tensor, task_embedding, task_id)\n        return hidden_states\n\n\nclass MyBertAttention9(BertAttention):\n    def __init__(self, config, add_conditional_layernorm=True):\n        super().__init__(config)\n        self.self = MyBertSelfAttention9(config)\n        self.add_conditional_layernorm = add_conditional_layernorm\n        if add_conditional_layernorm:\n            self.output = MyBertSelfOutput9(config)\n        else:\n            self.output = BertSelfOutput(config)\n        self.pruned_heads = set()\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n        task_id=None\n    ):\n        self_outputs = self.self(\n            hidden_states,\n            attention_mask,\n            head_mask,\n            encoder_hidden_states,\n            encoder_attention_mask,\n            task_embedding=task_embedding,\n        )\n        if self.add_conditional_layernorm:\n            attention_output = self.output(self_outputs[0], hidden_states, task_embedding, task_id)\n        else:\n            attention_output = self.output(self_outputs[0], hidden_states)\n        outputs = (attention_output,) + self_outputs[\n            1:\n        ]  # add attentions if we output them\n        return outputs\n\n\nclass BertAdapter9(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.bottleneck = ConditionalBottleNeck(config)\n        self.condlayernorm = ConditionalLayerNorm(config.hidden_size, config.hidden_size, eps=config.layer_norm_eps)\n\n    def forward(self, bert_layer_input, hidden_states, task_embedding, task_id):\n        hidden_states = self.bottleneck(task_embedding, hidden_states)\n        hidden_states = self.condlayernorm(hidden_states + bert_layer_input, task_embedding, task_id)\n        return hidden_states\n\n\nclass MyBertAdapterLayer9(nn.Module):\n    \"\"\"Adapter Layer trained from scratch (sub layer names are changed)\"\"\"\n    def __init__(self, config):\n        super(MyBertAdapterLayer9, self).__init__()\n        self.new_attention = MyBertAttention9(config)\n        self.new_intermediate = BertIntermediate(config)\n        self.new_output = MyBertOutput9(config)\n        self.adapter = BertAdapter9(config)\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n        task_id=None\n    ):\n        self_attention_outputs = self.new_attention(\n            hidden_states, attention_mask, head_mask, task_embedding=task_embedding, task_id=task_id\n        )\n        attention_output = self_attention_outputs[0]\n        outputs = self_attention_outputs[\n            1:\n        ]  # add self attentions if we output attention weights\n\n        intermediate_output = self.new_intermediate(attention_output)\n        layer_output = self.new_output(\n            intermediate_output, attention_output, task_embedding=task_embedding, task_id=task_id\n        )\n        adapted_layer_output = self.adapter(\n            attention_output, layer_output, task_embedding=task_embedding, task_id=task_id\n        )\n        outputs = (adapted_layer_output,) + outputs\n        return outputs\n\n\nclass MyBertLayer9(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.attention = MyBertAttention9(config)\n        self.is_decoder = config.is_decoder\n        if self.is_decoder:\n            self.crossattention = BertAttention(config)\n        self.intermediate = BertIntermediate(config)\n        self.output = MyBertOutput9(config)\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n        task_id=None\n    ):\n        self_attention_outputs = self.attention(\n            hidden_states, attention_mask, head_mask, task_embedding=task_embedding, task_id=task_id\n        )\n        attention_output = self_attention_outputs[0]\n        outputs = self_attention_outputs[\n            1:\n        ]  # add self attentions if we output attention weights\n\n        if self.is_decoder and encoder_hidden_states is not None:\n            cross_attention_outputs = self.crossattention(\n                attention_output,\n                attention_mask,\n                head_mask,\n                encoder_hidden_states,\n                encoder_attention_mask,\n            )\n            attention_output = cross_attention_outputs[0]\n            outputs = (\n                outputs + cross_attention_outputs[1:]\n            )  # add cross attentions if we output attention weights\n\n        intermediate_output = self.intermediate(attention_output)\n        layer_output = self.output(intermediate_output, attention_output, task_embedding, task_id)\n        outputs = (layer_output,) + outputs\n        return outputs\n\n\nclass BertLayer9(BertLayer):\n    \"\"\"Same as BertLayer but with different inputs\"\"\"\n    def __init__(self, config):\n        super().__init__(config)\n        self.attention = MyBertAttention9(config, add_conditional_layernorm=False)\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n        task_id=None\n    ):\n        self_attention_outputs = self.attention(\n            hidden_states, attention_mask, head_mask, task_embedding=task_embedding, task_id=task_id\n        )\n        attention_output = self_attention_outputs[0]\n        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n\n        intermediate_output = self.intermediate(attention_output)\n        layer_output = self.output(intermediate_output, attention_output)\n        outputs = (layer_output,) + outputs\n        return outputs\n\n\nclass MyBertEncoder9(nn.Module):\n    def __init__(self, config, tasks):\n        super().__init__()\n        self.output_attentions = config.output_attentions\n        self.output_hidden_states = config.output_hidden_states\n        self.task_transformation = nn.Linear(config.hidden_size, config.hidden_size)\n        num_bert_layers = config.num_hidden_layers//2\n        num_mybert_layers = config.num_hidden_layers//2-1\n        assert num_bert_layers+num_mybert_layers+1 == config.num_hidden_layers\n        self.layer = nn.ModuleList(\n            [BertLayer9(config) for _ in range(num_bert_layers)] +\n            [MyBertLayer9(config) for _ in range(num_mybert_layers)] +\n            [MyBertAdapterLayer9(config)]  # FiLM8\n        )\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_type=None,\n        task_embedding=None\n    ):\n        all_hidden_states = ()\n        all_attentions = ()\n        task_embedding = self.task_transformation(task_embedding)\n        for i, layer_module in enumerate(self.layer):\n            if self.output_hidden_states:\n                all_hidden_states = all_hidden_states + (hidden_states,)\n\n            layer_outputs = layer_module(\n                hidden_states,\n                attention_mask,\n                head_mask[i],\n                encoder_hidden_states,\n                encoder_attention_mask,\n                task_embedding,\n                task_type\n            )\n            hidden_states = layer_outputs[0]\n\n            if self.output_attentions:\n                all_attentions = all_attentions + (layer_outputs[1],)\n\n        # Add last layer\n        if self.output_hidden_states:\n            all_hidden_states = all_hidden_states + (hidden_states,)\n\n        outputs = (hidden_states,)\n        if self.output_hidden_states:\n            outputs = outputs + (all_hidden_states,)\n        if self.output_attentions:\n            outputs = outputs + (all_attentions,)\n        return outputs  # last-layer hidden state, (all hidden states), (all attentions)\n\n\nclass CaMtlBaseEncoder(BertPreTrainedModel):\n    r\"\"\"\n    # NOTE: Combination of: (might work best for base) and uses:\n        -- block diagonal attention\n        -- conditional layer norm for the top half layers base=6-10 and large=11-22, top layer excluded\n        -- conditional bias attention term to the original attention matrix\n        -- conditional adapter for the top layer only at layer=11 for base and layer=23 for large\n        -- conditional alignment after the embedding layer only\n    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n        **last_hidden_state**: ``torch.FloatTensor`` of shape ``(batch_size, sequence_length, hidden_size)``\n            Sequence of hidden-states at the output of the last layer of the model.\n        **pooler_output**: ``torch.FloatTensor`` of shape ``(batch_size, hidden_size)``\n            Last layer hidden-state of the first token of the sequence (classification token)\n            further processed by a Linear layer and a Tanh activation function. The Linear\n            layer weights are trained from the next sentence prediction (classification)\n            objective during Bert pretraining. This output is usually *not* a good summary\n            of the semantic content of the input, you're often better with averaging or pooling\n            the sequence of hidden-states for the whole input sequence.\n        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n            of shape ``(batch_size, sequence_length, hidden_size)``:\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n\n    Examples::\n\n        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        model = BertFiLMModel.from_pretrained('bert-base-uncased')\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids)\n        last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n\n    \"\"\"\n\n    def __init__(self, config, data_args=None, **kwargs):\n        super().__init__(config)\n        tasks = data_args.tasks\n        self.task_id_2_task_idx = {i: i for i, t in enumerate(tasks)}\n        self.config = config\n        self.config.num_tasks = len(tasks)\n        config.max_seq_length = data_args.max_seq_length\n        self.task_type_embeddings = nn.Embedding(len(tasks), config.hidden_size)\n        self.conditional_alignment = FiLM(\n            config.hidden_size, config.hidden_size\n        )  # FiLM5\n\n        self.embeddings = BertEmbeddings(config)\n        self.encoder = MyBertEncoder9(config, tasks)\n        self.pooler = BertPooler(config)\n\n        self.init_weights()\n\n    def get_input_embeddings(self):\n        return self.embeddings.word_embeddings\n\n    def set_input_embeddings(self, value):\n        self.embeddings.word_embeddings = value\n\n    def _prune_heads(self, heads_to_prune):\n        \"\"\"Prunes heads of the model.\n        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        See base class PreTrainedModel\n        \"\"\"\n        for layer, heads in heads_to_prune.items():\n            self.encoder.layer[layer].attention.prune_heads(heads)\n\n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        **kwargs,\n    ):\n        \"\"\"Forward pass on the Model.\n\n        The model can behave as an encoder (with only self-attention) as well\n        as a decoder, in which case a layer of cross-attention is added between\n        the self-attention layers, following the architecture described in:\n        .. _`Attention is all you need`:\n            https://arxiv.org/abs/1706.03762\n\n        \"\"\"\n        task_type = self._create_task_type(kwargs[\"task_id\"])\n        task_embedding = self.task_type_embeddings(task_type)\n\n        if input_ids is not None and inputs_embeds is not None:\n            raise ValueError(\n                \"You cannot specify both input_ids and inputs_embeds at the same time\"\n            )\n        elif input_ids is not None:\n            input_shape = input_ids.size()\n        elif inputs_embeds is not None:\n            input_shape = inputs_embeds.size()[:-1]\n        else:\n            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n\n        device = input_ids.device if input_ids is not None else inputs_embeds.device\n\n        if attention_mask is None:\n            attention_mask = torch.ones(input_shape, device=device)\n        if token_type_ids is None:\n            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\n        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n        # ourselves in which case we just need to make it broadcastable to all heads.\n        if attention_mask.dim() == 3:\n            extended_attention_mask = attention_mask[:, None, :, :]\n        elif attention_mask.dim() == 2:\n            # Provided a padding mask of dimensions [batch_size, seq_length]\n            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n            if self.config.is_decoder:\n                batch_size, seq_length = input_shape\n                seq_ids = torch.arange(seq_length, device=device)\n                causal_mask = (\n                    seq_ids[None, None, :].repeat(batch_size, seq_length, 1)\n                    <= seq_ids[None, :, None]\n                )\n                causal_mask = causal_mask.to(\n                    torch.long\n                )  # not converting to long will cause errors with pytorch version < 1.3\n                extended_attention_mask = (\n                    causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n                )\n            else:\n                extended_attention_mask = attention_mask[:, None, None, :]\n        else:\n            raise ValueError(\n                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n                    input_shape, attention_mask.shape\n                )\n            )\n\n        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n        # masked positions, this operation will create a tensor which is 0.0 for\n        # positions we want to attend and -10000.0 for masked positions.\n        # Since we are adding it to the raw scores before the softmax, this is\n        # effectively the same as removing these entirely.\n        extended_attention_mask = extended_attention_mask.to(\n            dtype=next(self.parameters()).dtype\n        )  # fp16 compatibility\n        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n\n        # If a 2D ou 3D attention mask is provided for the cross-attention\n        # we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]\n        if self.config.is_decoder and encoder_hidden_states is not None:\n            (\n                encoder_batch_size,\n                encoder_sequence_length,\n                _,\n            ) = encoder_hidden_states.size()\n            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n            if encoder_attention_mask is None:\n                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n\n            if encoder_attention_mask.dim() == 3:\n                encoder_extended_attention_mask = encoder_attention_mask[:, None, :, :]\n            elif encoder_attention_mask.dim() == 2:\n                encoder_extended_attention_mask = encoder_attention_mask[\n                    :, None, None, :\n                ]\n            else:\n                raise ValueError(\n                    \"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\".format(\n                        encoder_hidden_shape, encoder_attention_mask.shape\n                    )\n                )\n\n            encoder_extended_attention_mask = encoder_extended_attention_mask.to(\n                dtype=next(self.parameters()).dtype\n            )  # fp16 compatibility\n            encoder_extended_attention_mask = (\n                1.0 - encoder_extended_attention_mask\n            ) * -10000.0\n        else:\n            encoder_extended_attention_mask = None\n\n        # Prepare head mask if needed\n        # 1.0 in head_mask indicate we keep the head\n        # attention_probs has shape bsz x n_heads x N x N\n        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n        if head_mask is not None:\n            if head_mask.dim() == 1:\n                head_mask = (\n                    head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n                )\n                head_mask = head_mask.expand(\n                    self.config.num_hidden_layers, -1, -1, -1, -1\n                )\n            elif head_mask.dim() == 2:\n                head_mask = (\n                    head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)\n                )  # We can specify head_mask for each layer\n            head_mask = head_mask.to(\n                dtype=next(self.parameters()).dtype\n            )  # switch to fload if need + fp16 compatibility\n        else:\n            head_mask = [None] * self.config.num_hidden_layers\n\n        embedding_output = self.embeddings(\n            input_ids=input_ids,\n            position_ids=position_ids,\n            token_type_ids=token_type_ids,\n            inputs_embeds=inputs_embeds,\n        )\n        embedding_output = self.conditional_alignment(\n            x_cond=task_embedding,\n            x_to_film=embedding_output,\n        )\n        encoder_outputs = self.encoder(\n            embedding_output,\n            attention_mask=extended_attention_mask,\n            head_mask=head_mask,\n            encoder_hidden_states=encoder_hidden_states,\n            encoder_attention_mask=encoder_extended_attention_mask,\n            task_type=task_type,\n            task_embedding=task_embedding,\n        )\n        sequence_output = encoder_outputs[0]\n        pooled_output = self.pooler(sequence_output)\n\n        outputs = (sequence_output, pooled_output,) + encoder_outputs[\n            1:\n        ]  # add hidden_states and attentions if they are here\n        return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n\n    def _create_task_type(self, task_id):\n        task_type = task_id.clone()\n        unique_task_ids = torch.unique(task_type)\n        unique_task_ids_list = (\n            unique_task_ids.cpu().numpy()\n            if unique_task_ids.is_cuda\n            else unique_task_ids.numpy()\n        )\n        for unique_task_id in unique_task_ids_list:\n            task_type[task_type == unique_task_id] = self.task_id_2_task_idx[\n                unique_task_id\n            ]\n        return task_type\n\n    @classmethod\n    def get_layer_regexp(cls):\n        return r\"encoder.layer.*\\.([0-9]+)\\..*\"\nFile Path: src/model/encoders/ca_mtl_large.py\nContent:\nimport math\nimport torch\nimport torch.nn as nn\nfrom transformers.modeling_bert import (\n    BertEmbeddings,\n    BertPooler,\n    BertPreTrainedModel,\n    BertAttention,\n    BertIntermediate,\n    BertLayer,\n    BertSelfOutput,\n)\n\nfrom src.model.encoders.conditional_modules import FiLM, CBDA, ConditionalLayerNorm, ConditionalBottleNeck\n\n\nclass MyBertSelfAttention10(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(\n            config, \"embedding_size\"\n        ):\n            raise ValueError(\n                \"The hidden size (%d) is not a multiple of the number of attention \"\n                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n            )\n        self.output_attentions = config.output_attentions\n\n        self.num_attention_heads = config.num_attention_heads\n        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n        self.all_head_size = self.num_attention_heads * self.attention_head_size\n\n        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n\n        self.max_seq_length = config.max_seq_length\n        assert config.hidden_size % self.max_seq_length == 0, \\\n            \"Block decomposed attention will only work if this condition is met.\"\n        self.num_blocks = config.hidden_size // self.max_seq_length\n        self.cond_block_diag_attn = CBDA(\n            config.hidden_size, math.ceil(self.max_seq_length / self.num_blocks), self.num_blocks\n        )  # d x L/N\n\n        self.random_weight_matrix = nn.Parameter(\n            torch.zeros(\n                [config.max_seq_length, math.ceil(self.max_seq_length / self.num_blocks)]\n            ),\n            requires_grad=True,\n        )\n\n    def transpose_for_scores(self, x):\n        new_x_shape = x.size()[:-1] + (\n            self.num_attention_heads,\n            self.attention_head_size,\n        )\n        x = x.view(*new_x_shape)\n        return x.permute(0, 2, 1, 3)\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n    ):\n\n        # If this is instantiated as a cross-attention module, the keys\n        # and values come from an encoder; the attention mask needs to be\n        # such that the encoder's padding tokens are not attended to.\n        if encoder_hidden_states is not None:\n            mixed_value_layer = self.value(encoder_hidden_states)\n            attention_mask = encoder_attention_mask\n        else:\n            mixed_value_layer = self.value(hidden_states)\n\n        value_layer = self.transpose_for_scores(mixed_value_layer)\n\n        mixed_key_layer = self.key(hidden_states)\n        mixed_query_layer = self.query(hidden_states)\n        key_layer = self.transpose_for_scores(mixed_key_layer)\n        query_layer = self.transpose_for_scores(mixed_query_layer)\n        attention_scores1 = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n        attention_scores1 = attention_scores1 / math.sqrt(self.attention_head_size)\n\n        attention_scores2 = self.cond_block_diag_attn(\n            x_cond=task_embedding,\n            x_to_film=self.random_weight_matrix,\n        )\n\n        attention_scores = attention_scores1 + attention_scores2.unsqueeze(1)\n\n        # b x seq len x hid dim\n\n        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n        if attention_mask is not None:\n            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n            attention_scores = attention_scores + attention_mask\n\n        # y = ax + b(task_emb)\n        # Normalize the attention scores to probabilities.\n        attention_probs = nn.Softmax(dim=-1)(\n            attention_scores\n        )  # b x num heads x seq length x head dim\n\n        # This is actually dropping out entire tokens to attend to, which might\n        # seem a bit unusual, but is taken from the original Transformer paper.\n        attention_probs = self.dropout(attention_probs)\n\n        # Mask heads if we want to\n        if head_mask is not None:\n            attention_probs = attention_probs * head_mask\n\n        context_layer = torch.matmul(attention_probs, value_layer)\n\n        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n        context_layer = context_layer.view(*new_context_layer_shape)\n\n        outputs = (\n            (context_layer, attention_probs)\n            if self.output_attentions\n            else (context_layer,)\n        )\n        return outputs\n\n\nclass MyBertSelfOutput10(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n        self.LayerNorm = ConditionalLayerNorm(config.hidden_size, config.hidden_size, eps=config.layer_norm_eps)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n\n    def forward(self, hidden_states, input_tensor, task_embedding, task_id):\n        hidden_states = self.dense(hidden_states)\n        hidden_states = self.dropout(hidden_states)\n        hidden_states = self.LayerNorm(hidden_states + input_tensor, task_embedding, task_id)\n        return hidden_states\n\n\nclass MyBertOutput10(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n        self.LayerNorm = ConditionalLayerNorm(config.hidden_size, config.hidden_size, eps=config.layer_norm_eps)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n\n    def forward(self, hidden_states, input_tensor, task_embedding, task_id):\n        hidden_states = self.dense(hidden_states)\n        hidden_states = self.dropout(hidden_states)\n        hidden_states = self.LayerNorm(hidden_states + input_tensor, task_embedding, task_id)\n        return hidden_states\n\n\nclass MyBertAttention10(BertAttention):\n    def __init__(self, config, add_conditional_layernorm=True):\n        super().__init__(config)\n        self.self = MyBertSelfAttention10(config)\n        self.add_conditional_layernorm = add_conditional_layernorm\n        if add_conditional_layernorm:\n            self.output = MyBertSelfOutput10(config)\n        else:\n            self.output = BertSelfOutput(config)\n        self.pruned_heads = set()\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n        task_id=None\n    ):\n        self_outputs = self.self(\n            hidden_states,\n            attention_mask,\n            head_mask,\n            encoder_hidden_states,\n            encoder_attention_mask,\n            task_embedding=task_embedding,\n        )\n        if self.add_conditional_layernorm:\n            attention_output = self.output(self_outputs[0], hidden_states, task_embedding, task_id)\n        else:\n            attention_output = self.output(self_outputs[0], hidden_states)\n        outputs = (attention_output,) + self_outputs[\n            1:\n        ]  # add attentions if we output them\n        return outputs\n\n\nclass MyBertLayer10(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.attention = MyBertAttention10(config)\n        self.is_decoder = config.is_decoder\n        if self.is_decoder:\n            self.crossattention = BertAttention(config)\n        self.intermediate = BertIntermediate(config)\n        self.output = MyBertOutput10(config)\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n        task_id=None\n    ):\n        self_attention_outputs = self.attention(\n            hidden_states, attention_mask, head_mask, task_embedding=task_embedding, task_id=task_id\n        )\n        attention_output = self_attention_outputs[0]\n        outputs = self_attention_outputs[\n            1:\n        ]  # add self attentions if we output attention weights\n\n        if self.is_decoder and encoder_hidden_states is not None:\n            cross_attention_outputs = self.crossattention(\n                attention_output,\n                attention_mask,\n                head_mask,\n                encoder_hidden_states,\n                encoder_attention_mask,\n            )\n            attention_output = cross_attention_outputs[0]\n            outputs = (\n                outputs + cross_attention_outputs[1:]\n            )  # add cross attentions if we output attention weights\n\n        intermediate_output = self.intermediate(attention_output)\n        layer_output = self.output(intermediate_output, attention_output, task_embedding, task_id)\n        outputs = (layer_output,) + outputs\n        return outputs\n\n\nclass BertLayer10(BertLayer):\n    \"\"\"Same as BertLayer but with different inputs\"\"\"\n    def __init__(self, config):\n        super().__init__(config)\n        self.attention = MyBertAttention10(config, add_conditional_layernorm=False)\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_embedding=None,\n        task_id=None\n    ):\n        self_attention_outputs = self.attention(\n            hidden_states, attention_mask, head_mask, task_embedding=task_embedding, task_id=task_id\n        )\n        attention_output = self_attention_outputs[0]\n        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n\n        intermediate_output = self.intermediate(attention_output)\n        layer_output = self.output(intermediate_output, attention_output)\n        outputs = (layer_output,) + outputs\n        return outputs\n\n\nclass MyBertEncoder10(nn.Module):\n    def __init__(self, config, tasks):\n        super().__init__()\n        self.output_attentions = config.output_attentions\n        self.output_hidden_states = config.output_hidden_states\n        self.task_transformation = nn.Linear(config.hidden_size, config.hidden_size)\n        num_bert_layers = config.num_hidden_layers//2 + config.num_hidden_layers % 2\n        num_mybert_layers = config.num_hidden_layers//2\n        assert num_bert_layers+num_mybert_layers == config.num_hidden_layers\n        self.layer = nn.ModuleList(\n            [BertLayer10(config) for _ in range(num_bert_layers)] +\n            [MyBertLayer10(config) for _ in range(num_mybert_layers)]\n        )\n        assert len(self.layer) == config.num_hidden_layers\n        #FiLM6\n        self.adapter_layer = nn.ModuleList(\n            [\n                ConditionalBottleNeck(config)\n                for _ in range(config.num_hidden_layers)\n            ]\n        )\n\n    def forward(\n        self,\n        hidden_states,\n        attention_mask=None,\n        head_mask=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        task_type=None,\n        task_embedding=None\n    ):\n        all_hidden_states = ()\n        all_attentions = ()\n        task_embedding = self.task_transformation(task_embedding)\n        hidden_film = torch.zeros_like(hidden_states)\n        for i, (layer_module, adapter_module) in enumerate(zip(self.layer, self.adapter_layer)):\n            if self.output_hidden_states:\n                all_hidden_states = all_hidden_states + (hidden_states,)\n\n            layer_outputs = layer_module(\n                hidden_states,\n                attention_mask,\n                head_mask[i],\n                encoder_hidden_states,\n                encoder_attention_mask,\n                task_embedding,\n                task_type\n            )\n            hidden_states = layer_outputs[0]\n\n            if self.output_attentions:\n                all_attentions = all_attentions + (layer_outputs[1],)\n            # FiLM layer with a skip connection\n            hidden_film = adapter_module(\n                x_cond=task_embedding, hidden_states=hidden_states + hidden_film\n            )\n\n        # Add last layer\n        if self.output_hidden_states:\n            all_hidden_states = all_hidden_states + (hidden_states,)\n\n        outputs = (hidden_film,)\n        if self.output_hidden_states:\n            outputs = outputs + (all_hidden_states,)\n        if self.output_attentions:\n            outputs = outputs + (all_attentions,)\n        return outputs  # last-layer hidden state, (all hidden states), (all attentions)\n\n\nclass CaMtlLargeEncoder(BertPreTrainedModel):\n    r\"\"\"\n    # NOTE: Combination of: (might work best for large) and uses:\n        -- block diagonal attention\n        -- conditional layer norm for the top half layers base=6-10 and large=11-22, top layer excluded\n        -- conditional bias attention term to the original attention matrix\n        -- down/projection bottleneck for all layers\n        -- conditional alignment after the embedding layer only\n    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n        **last_hidden_state**: ``torch.FloatTensor`` of shape ``(batch_size, sequence_length, hidden_size)``\n            Sequence of hidden-states at the output of the last layer of the model.\n        **pooler_output**: ``torch.FloatTensor`` of shape ``(batch_size, hidden_size)``\n            Last layer hidden-state of the first token of the sequence (classification token)\n            further processed by a Linear layer and a Tanh activation function. The Linear\n            layer weights are trained from the next sentence prediction (classification)\n            objective during Bert pretraining. This output is usually *not* a good summary\n            of the semantic content of the input, you're often better with averaging or pooling\n            the sequence of hidden-states for the whole input sequence.\n        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n            of shape ``(batch_size, sequence_length, hidden_size)``:\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n\n    Examples::\n\n        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        model = BertFiLMModel.from_pretrained('bert-base-uncased')\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids)\n        last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n\n    \"\"\"\n\n    def __init__(self, config, data_args=None, **kwargs):\n        super().__init__(config)\n        tasks = data_args.tasks\n        self.task_id_2_task_idx = {i: i for i, t in enumerate(tasks)}\n        self.config = config\n        self.config.num_tasks = len(tasks)\n        config.max_seq_length = data_args.max_seq_length\n        self.task_type_embeddings = nn.Embedding(len(tasks), config.hidden_size)\n        self.conditional_alignment = FiLM(\n            config.hidden_size, config.hidden_size\n        )  # FiLM5\n\n        self.embeddings = BertEmbeddings(config)\n        self.encoder = MyBertEncoder10(config, tasks)\n        self.pooler = BertPooler(config)\n\n        self.init_weights()\n\n    def get_input_embeddings(self):\n        return self.embeddings.word_embeddings\n\n    def set_input_embeddings(self, value):\n        self.embeddings.word_embeddings = value\n\n    def _prune_heads(self, heads_to_prune):\n        \"\"\"Prunes heads of the model.\n        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        See base class PreTrainedModel\n        \"\"\"\n        for layer, heads in heads_to_prune.items():\n            self.encoder.layer[layer].attention.prune_heads(heads)\n\n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None,\n        encoder_hidden_states=None,\n        encoder_attention_mask=None,\n        **kwargs,\n    ):\n        \"\"\"Forward pass on the Model.\n\n        The model can behave as an encoder (with only self-attention) as well\n        as a decoder, in which case a layer of cross-attention is added between\n        the self-attention layers, following the architecture described in:\n        .. _`Attention is all you need`:\n            https://arxiv.org/abs/1706.03762\n\n        \"\"\"\n        task_type = self._create_task_type(kwargs[\"task_id\"])\n        task_embedding = self.task_type_embeddings(task_type)\n\n        if input_ids is not None and inputs_embeds is not None:\n            raise ValueError(\n                \"You cannot specify both input_ids and inputs_embeds at the same time\"\n            )\n        elif input_ids is not None:\n            input_shape = input_ids.size()\n        elif inputs_embeds is not None:\n            input_shape = inputs_embeds.size()[:-1]\n        else:\n            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n\n        device = input_ids.device if input_ids is not None else inputs_embeds.device\n\n        if attention_mask is None:\n            attention_mask = torch.ones(input_shape, device=device)\n        if token_type_ids is None:\n            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\n        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n        # ourselves in which case we just need to make it broadcastable to all heads.\n        if attention_mask.dim() == 3:\n            extended_attention_mask = attention_mask[:, None, :, :]\n        elif attention_mask.dim() == 2:\n            # Provided a padding mask of dimensions [batch_size, seq_length]\n            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n            if self.config.is_decoder:\n                batch_size, seq_length = input_shape\n                seq_ids = torch.arange(seq_length, device=device)\n                causal_mask = (\n                    seq_ids[None, None, :].repeat(batch_size, seq_length, 1)\n                    <= seq_ids[None, :, None]\n                )\n                causal_mask = causal_mask.to(\n                    torch.long\n                )  # not converting to long will cause errors with pytorch version < 1.3\n                extended_attention_mask = (\n                    causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n                )\n            else:\n                extended_attention_mask = attention_mask[:, None, None, :]\n        else:\n            raise ValueError(\n                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n                    input_shape, attention_mask.shape\n                )\n            )\n\n        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n        # masked positions, this operation will create a tensor which is 0.0 for\n        # positions we want to attend and -10000.0 for masked positions.\n        # Since we are adding it to the raw scores before the softmax, this is\n        # effectively the same as removing these entirely.\n        extended_attention_mask = extended_attention_mask.to(\n            dtype=next(self.parameters()).dtype\n        )  # fp16 compatibility\n        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n\n        # If a 2D ou 3D attention mask is provided for the cross-attention\n        # we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]\n        if self.config.is_decoder and encoder_hidden_states is not None:\n            (\n                encoder_batch_size,\n                encoder_sequence_length,\n                _,\n            ) = encoder_hidden_states.size()\n            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n            if encoder_attention_mask is None:\n                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n\n            if encoder_attention_mask.dim() == 3:\n                encoder_extended_attention_mask = encoder_attention_mask[:, None, :, :]\n            elif encoder_attention_mask.dim() == 2:\n                encoder_extended_attention_mask = encoder_attention_mask[\n                    :, None, None, :\n                ]\n            else:\n                raise ValueError(\n                    \"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\".format(\n                        encoder_hidden_shape, encoder_attention_mask.shape\n                    )\n                )\n\n            encoder_extended_attention_mask = encoder_extended_attention_mask.to(\n                dtype=next(self.parameters()).dtype\n            )  # fp16 compatibility\n            encoder_extended_attention_mask = (\n                1.0 - encoder_extended_attention_mask\n            ) * -10000.0\n        else:\n            encoder_extended_attention_mask = None\n\n        # Prepare head mask if needed\n        # 1.0 in head_mask indicate we keep the head\n        # attention_probs has shape bsz x n_heads x N x N\n        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n        if head_mask is not None:\n            if head_mask.dim() == 1:\n                head_mask = (\n                    head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n                )\n                head_mask = head_mask.expand(\n                    self.config.num_hidden_layers, -1, -1, -1, -1\n                )\n            elif head_mask.dim() == 2:\n                head_mask = (\n                    head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)\n                )  # We can specify head_mask for each layer\n            head_mask = head_mask.to(\n                dtype=next(self.parameters()).dtype\n            )  # switch to fload if need + fp16 compatibility\n        else:\n            head_mask = [None] * self.config.num_hidden_layers\n\n        embedding_output = self.embeddings(\n            input_ids=input_ids,\n            position_ids=position_ids,\n            token_type_ids=token_type_ids,\n            inputs_embeds=inputs_embeds,\n        )\n        embedding_output = self.conditional_alignment(\n            x_cond=task_embedding,\n            x_to_film=embedding_output,\n        )\n        encoder_outputs = self.encoder(\n            embedding_output,\n            attention_mask=extended_attention_mask,\n            head_mask=head_mask,\n            encoder_hidden_states=encoder_hidden_states,\n            encoder_attention_mask=encoder_extended_attention_mask,\n            task_type=task_type,\n            task_embedding=task_embedding,\n        )\n        sequence_output = encoder_outputs[0]\n        pooled_output = self.pooler(sequence_output)\n\n        outputs = (sequence_output, pooled_output,) + encoder_outputs[\n            1:\n        ]  # add hidden_states and attentions if they are here\n        return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n\n    def _create_task_type(self, task_id):\n        task_type = task_id.clone()\n        unique_task_ids = torch.unique(task_type)\n        unique_task_ids_list = (\n            unique_task_ids.cpu().numpy()\n            if unique_task_ids.is_cuda\n            else unique_task_ids.numpy()\n        )\n        for unique_task_id in unique_task_ids_list:\n            task_type[task_type == unique_task_id] = self.task_id_2_task_idx[\n                unique_task_id\n            ]\n        return task_type\n\n    @classmethod\n    def get_layer_regexp(cls):\n        return r\"encoder.layer.*\\.([0-9]+)\\..*\"\nFile Path: src/model/encoders/conditional_modules.py\nContent:\nimport torch\nimport numbers\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass FiLM(nn.Module):\n    \"\"\" Feature-wise Linear Modulation (FiLM) layer\"\"\"\n    def __init__(self, input_size, output_size, num_film_layers=1, layer_norm=False):\n        \"\"\"\n        :param input_size: feature size of x_cond\n        :param output_size: feature size of x_to_film\n        :param layer_norm: true or false\n        \"\"\"\n        super(FiLM, self).__init__()\n        self.input_size = input_size\n        self.output_size = output_size\n        self.num_film_layers = num_film_layers\n        self.layer_norm = nn.LayerNorm(output_size) if layer_norm else None\n        film_output_size = self.output_size * num_film_layers * 2\n        self.gb_weights = nn.Linear(self.input_size, film_output_size)\n        self.gb_weights.bias.data.fill_(0)\n\n    def forward(self, x_cond, x_to_film):\n        gb = self.gb_weights(x_cond).unsqueeze(1)\n        gamma, beta = torch.chunk(gb, 2, dim=-1)\n        out = (1 + gamma) * x_to_film + beta\n        if self.layer_norm is not None:\n            out = self.layer_norm(out)\n        return out\n\n\nclass CBDA(nn.Module):\n    \"\"\" Conditional Block Diagonal Attention (CBDA) layer\"\"\"\n    def __init__(self, input_size, output_size, blocks=1, num_film_layers=1, layer_norm=False):\n        \"\"\"\n        :param input_size: feature size of x_cond\n        :param output_size: feature size of x_to_film\n        :param layer_norm: true or false\n        \"\"\"\n        super(CBDA, self).__init__()\n        self.input_size = input_size\n        self.output_size = output_size\n        self.num_film_layers = num_film_layers\n        self.layer_norm = nn.LayerNorm(output_size) if layer_norm else None\n        self.blocks = blocks\n        film_output_size = self.output_size * num_film_layers * 2\n        self.gb_weights = nn.Linear(self.input_size, film_output_size)\n        self.gb_weights.bias.data.fill_(0)\n\n    def forward(self, x_cond, x_to_film):\n        gb = self.gb_weights(x_cond).unsqueeze(1)\n        gamma, beta = torch.chunk(gb, 2, dim=-1)\n        out = (1 + gamma) * x_to_film + beta\n        if self.layer_norm is not None:\n            out = self.layer_norm(out)\n        out = [torch.block_diag(*list(out_b.chunk(self.blocks, 0))) for out_b in out]\n        out = torch.stack(out)\n        return out[:, :, :out.size(1)]\n\n\nclass ConditionalLayerNorm(nn.Module):\n    r\"\"\"Applies Conditional Layer Normalization over a mini-batch of inputs.\n\n    .. math::\n        y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma(z) + \\beta(z)\n\n    The mean and standard-deviation are calculated separately over the last\n    certain number dimensions which have to be of the shape specified by\n    :attr:`normalized_shape`.\n    :math:`\\gamma` and :math:`\\beta` are learnable affine transform parameters of\n    :attr:`normalized_shape` if :attr:`elementwise_affine` is ``True``.\n\n    .. note::\n        Unlike Batch Normalization and Instance Normalization, which applies\n        scalar scale and bias for each entire channel/plane with the\n        :attr:`affine`, Layer Normalization applies per-element scale and\n        bias with :attr:`elementwise_affine`.\n\n    This layer uses statistics computed from input data in both training and\n    evaluation modes. The affine transformation is molulated by a conditional tensor.\n    In our case, we use task embeddings z.\n\n    Args:\n        normalized_shape (int or list or torch.Size): input shape from an expected input\n            of size\n\n            .. math::\n                [* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n                    \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n\n            If a single integer is used, it is treated as a singleton list, and this module will\n            normalize over the last dimension which is expected to be of that specific size.\n        eps: a value added to the denominator for numerical stability. Default: 1e-5\n        elementwise_affine: a boolean value that when set to ``True``, this module\n            has learnable per-element affine parameters initialized to ones (for weights)\n            and zeros (for biases). Default: ``True``.\n\n    Shape:  - Input: :math:`(N, *)`  - Output: :math:`(N, *)` (same shape as input)\n\n    Examples::\n\n        >>> input_ = torch.randn(20, 5, 10, 10)\n        >>> condition = torch.randn(20, 10)\n        >>> # With Learnable Parameters\n        >>> m = ConditionalLayerNorm([10, 10])\n        >>> # Normalize over last dimension of size 10\n        >>> m = nn.LayerNorm(10)\n        >>> # Activating the module\n        >>> output = m(input_, condition)\n\n    .. _`Layer Normalization`: https://arxiv.org/abs/1607.06450\n    .. _`Conditional Layer Normalization`: https://arxiv.org/\n    \"\"\"\n    __constants__ = ['normalized_shape', 'condition_size', 'weight', 'bias', 'eps']\n\n    def __init__(self, normalized_shape, condition_size, eps=1e-5):\n        super(ConditionalLayerNorm, self).__init__()\n        if isinstance(normalized_shape, numbers.Integral):\n            normalized_shape = (normalized_shape,)\n        self.normalized_shape = tuple(normalized_shape)\n\n        self.condition_size = condition_size\n        self.eps = eps\n\n        self.weight = nn.Parameter(torch.Tensor(*normalized_shape))\n        self.ln_weight_modulation = FiLM(condition_size, sum(normalized_shape))\n        self.bias = nn.Parameter(torch.Tensor(*normalized_shape))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.ones_(self.weight)\n        nn.init.zeros_(self.bias)\n\n    def forward(self, input_, condition, task_id):\n        unique_task_ids = torch.unique(task_id)\n        cln_output = torch.zeros_like(input_)\n        for unique_task_id in unique_task_ids:\n            task_id_filter = task_id == unique_task_id\n            task_emb = condition[task_id_filter][0].unsqueeze(0)\n            weight = self.ln_weight_modulation(task_emb, self.weight).view(-1)\n            cln_output[task_id_filter] = F.layer_norm(input_[task_id_filter], self.normalized_shape, weight, self.bias, self.eps)\n        return cln_output\n\n    def extra_repr(self):\n        return '{normalized_shape}, {condition_size}, eps={eps}'.format(**self.__dict__)\n\n\nclass ConditionalBottleNeck(nn.Module):\n    \"\"\"Down projection and up projection with FiLM layers within Transformer layer.\"\"\"\n    def __init__(self, config):\n        super(ConditionalBottleNeck, self).__init__()\n        self.emb_transf = nn.Linear(config.hidden_size, config.hidden_size)\n        self.hidden_modulation = FiLM(config.hidden_size, config.hidden_size)\n        self.down_proj_layer = nn.Linear(config.hidden_size, config.hidden_size//3)\n        self.up_proj_layer = nn.Linear(config.hidden_size//3, config.hidden_size)\n\n    def forward(self, x_cond, hidden_states):\n        x_cond = self.emb_transf(x_cond)\n        hidden_states = self.hidden_modulation(x_cond=x_cond, x_to_film=hidden_states)\n        hidden_states = self.down_proj_layer(hidden_states)\n        hidden_states = self.up_proj_layer(hidden_states)\n        return hidden_states\n\nFile Path: src/mtl_trainer.py\nContent:\nimport os\nimport logging\nfrom dataclasses import dataclass, field\nfrom typing import Dict, Optional, Callable, Tuple\n\nimport torch\nimport numpy as np\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.utils.data.sampler import RandomSampler\nfrom transformers import Trainer, TrainingArguments, EvalPrediction, glue_output_modes\nfrom transformers.optimization import AdamW, get_linear_schedule_with_warmup\n\nfrom src.data.glue_utils import compute_glue_metrics\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass MultiTaskTrainingArguments(TrainingArguments):\n    use_mt_uncertainty: bool = field(\n        default=False,\n        metadata={\"help\": \"Use MT-Uncertainty sampling method\"},\n    )\n    uniform_mt_sampling: bool = field(\n        default=False,\n        metadata={\"help\": \"Sample each task an equal amount to times per epoch.\"},\n    )\n    percent_of_max_data_size: float = field(\n        default=1.0,\n        metadata={\n            \"help\": \"If uniform_mt_sampling=True, specify the samples per task per \"\n            \"epoch based on the maximum dataset length. If below 0.0 or above 1.0,\"\n            \"it will be set to the closest of 0.0 or 1.0.\"\n        },\n    )\n    warmup_proportion: float = field(\n        default=0.1,\n        metadata={\"help\": \"0.0 to args.lr for warmup_proportion * num_training_steps\"},\n    )\n\n\nclass MultiTaskTrainer(Trainer):\n    def __init__(\n        self,\n        tokenizer,\n        data_args,\n        eval_datasets=None,\n        test_datasets=None,\n        *args,\n        **kwargs,\n    ):\n        super(MultiTaskTrainer, self).__init__(*args, **kwargs)\n        self.tokenizer = tokenizer\n        self.data_args = data_args\n        self.eval_datasets = eval_datasets\n        self.test_datasets = test_datasets\n        self.eval_results = {}\n\n    def get_optimizers(\n        self, num_training_steps: int\n    ) -> Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]:\n        \"\"\"\n        Setup the optimizer and the learning rate scheduler.\n\n        We provide a reasonable default that works well.\n        If you want to use something else, you can pass a tuple in the Trainer's init,\n        or override this method in a subclass.\n        \"\"\"\n        if self.optimizers is not None:\n            return self.optimizers\n        # Prepare optimizer and schedule (linear warmup and decay)\n        no_decay = [\"bias\", \"LayerNorm.weight\"]\n        optimizer_grouped_parameters = [\n            {\n                \"params\": [\n                    p\n                    for n, p in self.model.named_parameters()\n                    if not any(nd in n for nd in no_decay)\n                ],\n                \"weight_decay\": self.args.weight_decay,\n            },\n            {\n                \"params\": [\n                    p\n                    for n, p in self.model.named_parameters()\n                    if any(nd in n for nd in no_decay)\n                ],\n                \"weight_decay\": 0.0,\n            },\n        ]\n        num_warmup_steps = (\n            self.args.warmup_proportion * num_training_steps\n        )  # this is different from overridden function\n        optimizer = AdamW(\n            optimizer_grouped_parameters,\n            lr=self.args.learning_rate,\n            eps=self.args.adam_epsilon,\n        )\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=num_warmup_steps,\n            num_training_steps=num_training_steps,  # this is different from overridden function\n        )\n        return optimizer, scheduler\n\n    def get_train_dataloader(self) -> DataLoader:\n        if self.args.use_mt_uncertainty:\n            return self._create_custom_dataloader()\n        else:\n            return super().get_train_dataloader()\n\n    def _create_custom_dataloader(self):\n        class MtUcertaintyIterator:\n            \"\"\"Sample tasks using uncertainty measure.\"\"\"\n\n            def __init__(self, my_loader):\n                self.my_loader = my_loader\n                self.loader_iters = [iter(loader) for loader in self.my_loader.loaders]\n                self.loader_iter_sizes = [len(i) for i in self.loader_iters]\n                self.max_count = len(self.my_loader)\n                self.batch_count = 0\n\n            def __iter__(self):\n                return self\n\n            def __next__(self):\n                if self.batch_count == self.max_count:\n                    self.batch_count = 0\n                    raise StopIteration()\n\n                test_batch = {}\n                for idx, loader_iter in enumerate(self.loader_iters):\n                    try:\n                        batch = loader_iter.__next__()\n                    except StopIteration:\n                        new_loader_iter = iter(self.my_loader.loaders[idx])\n                        self.loader_iters[idx] = new_loader_iter\n                        batch = new_loader_iter.__next__()\n\n                    test_batch = self.batchify_data(batch, test_batch)\n\n                inputs = {}\n                for k, v in test_batch.items():\n                    if k not in [\"labels\"]:\n                        inputs[k] = v.detach().to(self.my_loader.args.device)\n\n                with torch.no_grad():\n                    model.select_batch_mode = True\n                    outputs = model(**inputs)\n                    model.select_batch_mode = False\n\n                (\n                    test_batch_entropy,\n                    test_batch_entropy_mean,\n                    max_mean_batch_entropy,\n                ) = outputs[-3:]\n\n                for _, v in inputs.items():\n                    del v  # free GPU mem\n                del inputs\n\n                test_batch_entropy_mean = (\n                    test_batch_entropy_mean / max_mean_batch_entropy\n                )\n                test_batch_entropy = test_batch_entropy * test_batch_entropy_mean\n\n                if \"sts-b\" in tasks and \"mrpc\" in tasks:\n                    stsb_idx = test_batch[\"task_id\"] == tasks.index(\"sts-b\")\n                    mrpc_idx = test_batch[\"task_id\"] == tasks.index(\"mrpc\")\n                    num_items = min(\n                        len(test_batch_entropy[stsb_idx]),\n                        len(test_batch_entropy[mrpc_idx]),\n                    )\n                    stsb_idx = stsb_idx.nonzero()[:num_items]\n                    mrpc_idx = mrpc_idx.nonzero()[:num_items]\n                    test_batch_entropy[stsb_idx] = test_batch_entropy[mrpc_idx]\n                    test_batch_entropy_mean[stsb_idx] = test_batch_entropy_mean[\n                        mrpc_idx\n                    ]\n\n                select_size = min(\n                    self.my_loader.args.train_batch_size,\n                    test_batch[\"input_ids\"].shape[0],\n                )  # Handled the last batch if it is lower than the batch size\n\n                top_entropy = torch.topk(test_batch_entropy, select_size)\n\n                for k, v in test_batch.items():\n                    test_batch[k] = torch.index_select(v, 0, top_entropy.indices)\n\n                self.batch_count += 1\n\n                return test_batch\n\n            @staticmethod\n            def batchify_data(data, curr_batch):\n                for k in data.keys():\n                    if k in curr_batch.keys():\n                        curr_batch[k] = torch.cat((curr_batch[k], data[k]), dim=0)\n                    else:\n                        curr_batch[k] = data[k]\n                return curr_batch\n\n        class CustomLoader:\n            def __init__(self, loaders, datasets, loader_args):\n                self.loaders = loaders\n                self.dataset = datasets\n                self.args = loader_args\n                self.current_epoch = 0\n\n            def __iter__(self):\n                iterator = MtUcertaintyIterator(self)\n\n                # for determinism across runs\n                # https://github.com/pytorch/examples/issues/501\n                for l in self.loaders:\n                    if isinstance(l.sampler, DistributedSampler):\n                        l.sampler.set_epoch(self.current_epoch)\n                self.current_epoch += 1\n                return iterator\n\n            def __len__(self):\n                loader_len = [len(loader) for loader in self.loaders]\n                if self.args.uniform_mt_sampling:\n                    return int(\n                        self.args.percent_of_max_data_size\n                        * max(loader_len)\n                        * len(self.loaders)\n                        / self.args.train_batch_size\n                    )\n                elif self.args.use_mt_uncertainty:\n                    return int(\n                        max(loader_len)\n                        * len(self.loaders)\n                        * self.args.percent_of_max_data_size\n                    )\n                else:\n                    return sum(loader_len)\n\n        model = self.model\n        tasks = self.data_args.tasks\n\n        data_loaders = []\n        for dataset in self.train_dataset.datasets:\n            train_sampler = (\n                RandomSampler(dataset)\n                if self.args.local_rank == -1\n                else DistributedSampler(dataset)\n            )\n\n            data_loader = DataLoader(\n                dataset,\n                batch_size=self.args.train_batch_size,\n                sampler=train_sampler,\n                collate_fn=self.data_collator.collate_batch,\n            )\n            data_loaders.append(data_loader)\n\n        return CustomLoader(data_loaders, self.train_dataset, self.args)\n\n    def evaluate(\n        self,\n        eval_dataset: Optional[Dataset] = None,\n        prediction_loss_only: Optional[bool] = None,\n        context: str = None,\n        do_test_if_needed: bool = True,\n    ):\n        datasets = eval_dataset or self.eval_datasets\n        logger.info(\"*** Evaluate on dev ***\")\n        for task_name, eval_dataset in datasets.items():\n            logger.info(task_name)\n            self.compute_metrics = self.build_compute_metrics_fn(eval_dataset)\n            eval_result = super().evaluate(\n                eval_dataset=eval_dataset, prediction_loss_only=True\n            )\n            self.update_eval_results(eval_result, task_name)\n            for key, value in self.eval_results[task_name].items():\n                logger.info(\"  %s = %s\", key, value)\n\n    def predict(\n        self,\n        eval_dataset: Optional[Dataset] = None,\n        prediction_loss_only: Optional[bool] = None,\n    ):\n        logging.info(\"*** Test ***\")\n        datasets = eval_dataset or self.test_datasets\n        for task_name, test_dataset in datasets.items():\n            logger.info(task_name)\n            predictions = super().predict(test_dataset=test_dataset).predictions\n            output_mode = glue_output_modes[task_name] \n            if output_mode == \"classification\":\n                predictions = np.argmax(predictions, axis=1)\n\n            output_test_file = os.path.join(\n                self.args.output_dir,\n                f\"{task_name}_test_iter_{self.global_step}.tsv\",\n            )\n            if self.is_world_master():\n                with open(output_test_file, \"w\") as writer:\n                    logger.info(\"***** Test results {} *****\".format(task_name))\n                    writer.write(\"index\\tprediction\\n\")\n                    for index, item in enumerate(predictions):\n                        if output_mode == \"regression\":\n                            writer.write(\"%d\\t%3.3f\\n\" % (index, item))\n                        else:\n                            writer.write(\n                                \"%d\\t%s\\n\" % (index, test_dataset.get_labels()[item])\n                            )\n\n    def update_eval_results(self, results, task_name):\n        self.eval_results[task_name] = self.eval_results.get(task_name, {})\n        for key, value in results.items():\n            if key in self.eval_results[task_name] and 'loss' not in key and 'epoch' not in key:\n                value = max(self.eval_results[task_name][key], value)\n            self.eval_results[task_name][key] = value\n\n\n    @staticmethod\n    def build_compute_metrics_fn(\n        eval_dataset\n    ) -> Callable[[EvalPrediction], Dict]:\n        def compute_metrics_fn(p: EvalPrediction):\n            return compute_glue_metrics(eval_dataset.task_name, p)\n\n        return compute_metrics_fn\n\n",
    "Experiment Result": "Model Architecture Configuration (CaMtlArguments in src/model/ca_mtl.py):\n- `model_name_or_path`: Path to pretrained model or model identifier (e.g., \"CA-MTL-base\", \"CA-MTL-large\", \"bert-base-cased\", etc.).\n- `freeze_encoder_layers`: Specifies a layer range (e.g., \"0-5\") to freeze encoder layers. If set, specific conditional modules (\"random_weight_matrix\", \"film.gb_weights\", \"ln_weight_modulation.gb_weights\", \"adapter\") within the frozen range remain unfrozen.\n\nCA-MTL Base Encoder Specifics (src/model/encoders/ca_mtl_base.py):\n- Utilizes: block diagonal attention, conditional layer normalization for the top half layers (layers 6-10), a conditional bias attention term added to the original attention matrix, a conditional adapter for the top layer only (layer 11), and a conditional alignment layer after the embedding layer.\n\nCA-MTL Large Encoder Specifics (src/model/encoders/ca_mtl_large.py):\n- Utilizes: block diagonal attention, conditional layer normalization for the top half layers (layers 11-22), a conditional bias attention term added to the original attention matrix, a down/projection bottleneck for all layers, and a conditional alignment layer after the embedding layer.\n\nMulti-Task Training Arguments (MultiTaskTrainingArguments in src/mtl_trainer.py):\n- `use_mt_uncertainty`: Boolean flag to enable Multi-Task Uncertainty sampling method (default: False).\n- `uniform_mt_sampling`: Boolean flag to sample each task an equal amount of times per epoch (default: False).\n- `percent_of_max_data_size`: When `uniform_mt_sampling` is True, this float (0.0 to 1.0) specifies the number of samples per task per epoch, relative to the maximum dataset length (default: 1.0).\n- `warmup_proportion`: Float representing the proportion of training steps for learning rate warmup (default: 0.1)."
}{
    "Title": "Adapters Strike Back",
    "Main Contributions": "This paper provides an in-depth and systematic study of adapters for vision transformers (ViTs), identifying pitfalls in previous implementations and proposing an improved architecture called Adapter+. The main contributions include: (1) a comprehensive study on adapter position, inner structure, and parameter initialization for ViTs, (2) the proposal of a learnable, channel-wise scaling for adapters in computer vision tasks, and (3) the introduction of Adapter+, which achieves state-of-the-art average accuracy on VTAB (77.6% without per-task hyperparameter optimization) and FGVC (90.7% with the lowest parameters), demonstrating an excellent parameter-accuracy trade-off and high robustness across diverse task subgroups.",
    "Methodology": "The methodology centers on optimizing the configuration of bottleneck adapter modules for Vision Transformers. The core Adapter+ architecture uses a 'Post-Adapter' position, where the adapter is placed at the end of the transformer layer, after the FFN and its skip connection. It incorporates a learnable, channel-wise scaling mechanism for the adapter's output, and its parameters are initialized using the Houlsby initialization method. The adapter module itself consists of a down-projection, a GELU non-linearity, and an up-projection, forming a bottleneck structure. The study systematically evaluates different adapter positions (Pre, Post, Parallel, Intermediate), inner structure components (biases, layer normalization, layer-wise vs. channel-wise scaling), and initialization strategies (Houlsby, BERT, LoRA) to determine the optimal configuration.",
    "Experimental Setup": "Experiments were conducted on two standard benchmarks for task adaptation: VTAB (Visual Task Adaptation Benchmark), consisting of 19 tasks grouped into Natural, Specialized, and Structured categories, and FGVC (fine-grained visual classification), comprising five datasets. A ViT-B/16 network pre-trained on ImageNet-21k was used as the backbone model. All models were trained with an AdamW optimizer (learning rate 10^-3, weight decay 10^-4, batch size 64), a cosine learning rate schedule with a linear warm-up over 10 epochs, for a total of 100 epochs. Stochastic depth with linearly increasing drop rates (0 to 0.1 for frozen network, 0.1 for adapters) was applied for regularization. Input images were resized to 224x224 px, with additional random resize crop and horizontal flipping for FGVC. Re-evaluations of competing methods ensured fair comparisons, considering data normalization and complete training schedules.",
    "Limitations": "The paper primarily addresses and overcomes limitations of previous adapter implementations, such as suboptimal configurations and initialization issues, leading to their underperformance. For Adapter+ itself, the paper highlights its robustness and states it 'requires little to no manual intervention when addressing a novel scenario,' implying a lack of significant limitations for its proposed architecture and training strategy within the scope of vision task adaptation. No explicit weaknesses, constraints, or assumptions specific to Adapter+ were mentioned.",
    "Future Research Directions": "The paper does not explicitly state future research directions. It focuses on presenting Adapter+ as a refined, state-of-the-art solution that addresses previous shortcomings of adapter methods. The conclusion emphasizes its superiority and excellent parameter-accuracy trade-off, setting a new strong baseline for future work in parameter-efficient transfer learning.",
    "Experiment Code": "class Adapter(nn.Module):    def __init__(        self,        embed_dim,        bottleneck_dim=8,        drop_path=0.0,        dropout=0.0,        act_layer=nn.GELU,        norm_layer=nn.LayerNorm,        scaling=1.0,        init=\"houlsby\",        bias=True,        pre_dropout=False,    ):        super().__init__()        self.bottleneck = nn.Sequential(            nn.Dropout(dropout) if dropout > 0 and pre_dropout else nn.Identity(),            nn.Linear(embed_dim, bottleneck_dim, bias=bias),            act_layer() if act_layer else nn.Identity(),            nn.Dropout(dropout) if dropout > 0 and not pre_dropout else nn.Identity(),            nn.Linear(bottleneck_dim, embed_dim, bias=bias),        )        self.norm_a = norm_layer(embed_dim) if norm_layer else nn.Identity()        self.drop_path_a = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()        self.bottleneck_dim = bottleneck_dim        if scaling == \"learned\":            self.scaling = nn.Parameter(torch.ones(1))        elif scaling == \"channel\":            self.scaling = nn.Parameter(torch.ones(embed_dim))        else:            self.scaling = scaling        if init == \"houlsby\":            std = 0.01            nn.init.trunc_normal_(                self.bottleneck[1].weight, std=std, a=-2 * std, b=2 * std            )            if self.bottleneck[1].bias is not None:                nn.init.zeros_(self.bottleneck[1].bias)            nn.init.trunc_normal_(                self.bottleneck[4].weight, std=std, a=-2 * std, b=2 * std            )            if self.bottleneck[4].bias is not None:                nn.init.zeros_(self.bottleneck[4].bias)        elif init == \"lora\":            nn.init.kaiming_uniform_(self.bottleneck[1].weight, a=math.sqrt(5))            if self.bottleneck[1].bias is not None:                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(                    self.bottleneck[1].weight                )                bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0                nn.init.uniform_(self.bottleneck[1].bias, -bound, bound)            nn.init.zeros_(self.bottleneck[4].weight)            if self.bottleneck[4].bias is not None:                nn.init.zeros_(self.bottleneck[4].bias)        elif init == \"bert\":            nn.init.normal_(self.bottleneck[1].weight, mean=0.0, std=0.02)            if self.bottleneck[1].bias is not None:                nn.init.zeros_(self.bottleneck[1].bias)            nn.init.normal_(self.bottleneck[4].weight, mean=0.0, std=0.02)            if self.bottleneck[4].bias is not None:                nn.init.zeros_(self.bottleneck[4].bias)        else:            raise ValueError(f\"Initialization {init} not implemented!\")    def forward(        self, x: torch.Tensor, skip: Optional[torch.Tensor] = None    ) -> torch.Tensor:        x = self.norm_a(x)        x = self.drop_path_a(self.bottleneck(x))        x = x * self.scaling        y = x        if skip is not None:            y = y + skip        return y\nclass AdapterBlock(Block):\n    def forward_post(self, x: torch.Tensor) -> torch.Tensor:\n        x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x))))\n        x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))\n        x = self.adapter(x, skip=x)\n        return x\n\nclass VisionTransformerAdapter(VisionTransformer):\n    def __init__(self, ..., block_fn=AdapterBlock, adapter_config=None, ...):\n        super().__init__(..., block_fn=block_fn, ...)\n        # ... other initializations ...\n        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]\n        self.blocks = nn.Sequential(*[block_fn(..., adapter_config=adapter_config, ...) for i in range(depth)])\n\ndef _create_vision_transformer_adapter(variant: str, pretrained: bool = False, adapter=False, **kwargs) -> VisionTransformer:\n    # ... (simplified) ...\n    if adapter:\n        block_fn = kwargs.pop(\"block_fn\", Block)\n        if block_fn == Block:\n            block_fn = AdapterBlock\n        elif block_fn == ResPostBlock:\n            block_fn = AdapterResPostBlock\n        else:\n            raise ValueError(f\"Adapters not implemented for {block_fn}!\")\n        return build_model_with_cfg(\n            VisionTransformerAdapter,\n            variant,\n            pretrained,\n            block_fn=block_fn,\n            **kwargs,\n        )\n\nclass AdapterModel(pl.LightningModule):\n    def __init__(self, cfg, img_size=224, num_classes=1000,):\n        super().__init__()\n        self.cfg = cfg\n        self.vit = timm.create_model(\n            cfg.vit.model,\n            adapter=True,\n            pretrained=True,\n            num_classes=num_classes,\n            img_size=img_size,\n            drop_path_rate=cfg.vit.drop_path,\n            adapter_config=cfg.get(\"adapter\", None),\n            lora_config=cfg.get(\"lora\", None),\n            prompt_config=cfg.get(\"prompt\", None),\n        )\n        if cfg.get(\"adapter\", None) or cfg.get(\"lora\", None) or cfg.get(\"prompt\", None):\n            if not cfg.vit.finetune:\n                self.vit.requires_grad_(False)\n            self.vit.head.requires_grad_(True)\n            for m in self.vit.modules():\n                if isinstance(m, Adapter):\n                    m.requires_grad_(True)\n                if cfg.train.train_ln:\n                    if isinstance(m, nn.LayerNorm):\n                        m.requires_grad_(True)\n\ndef add_weight_decay(model, weight_decay=1e-5, skip_list=(), exclude_list=()):\n    decay = []\n    no_decay = []\n    for name, param in model.named_parameters():\n        if not param.requires_grad or name in exclude_list:\n            continue\n        if (\n            len(param.shape) == 1\n            or name.endswith(\".bias\")\n            or name.endswith(\".scaling\")\n            or name in skip_list\n        ):\n            no_decay.append(param)\n        else:\n            decay.append(param)\n    return [\n        {\"params\": no_decay, \"weight_decay\": 0.0},\n        {\"params\": decay, \"weight_decay\": weight_decay},\n    ]\n",
    "Experiment Result": "The Adapter module employs a bottleneck structure consisting of a down-projection, a GELU non-linearity, and an up-projection. Its parameters are initialized using the Houlsby initialization method (trunc_normal_ with std=0.01 for weights and zeros for biases). The adapter's output incorporates a learnable, channel-wise scaling mechanism. The core Adapter+ architecture places the adapter in a 'Post-Adapter' position, meaning it is applied after the FFN and its skip connection within a transformer block. Other adapter positions evaluated include 'Pre', 'Parallel', 'Intermediate', and 'Houlsby' (referring to a dual adapter placement at both attention and FFN outputs). When integrating adapters, the base Vision Transformer parameters are frozen by default, with only the classification head and the adapter modules being trainable. Optionally, the Vision Transformer's Layer Normalization layers can also be made trainable. The scaling parameters of the adapter are specifically excluded from weight decay during optimization. The internal layer normalization of the Adapter module is typically set to None for Adapter+ configuration."
}{
    "Title": "Towards Modular LLMs by Building and Reusing a Library of LoRAs",
    "Main Contributions": "This research addresses the problem of reusing trained parameter-efficient adapters (LoRAs) to improve Large Language Model (LLM) performance on new tasks. The key contributions include: i) studying the creation of LoRA-based modular multi-task LLMs where experts are trained independently and the router is post-hoc; ii) proposing Model-Based Clustering (MBC) to build a library of adapters by clustering tasks based on the similarity of their LoRA parameters, which optimizes for transfer across multi-task datasets; and iii) introducing Arrow, a novel zero-shot routing mechanism that dynamically selects relevant adapters for new inputs without retraining, by leveraging the SVD decomposition of LoRA parameters. The paper demonstrates that MBC-based adapters and Arrow routing lead to superior generalization, matching or outperforming traditional joint training.",
    "Methodology": "The methodology focuses on building and reusing a library of LoRA adapters. For building the library, several approaches are considered: training private adapters (one per task), training a single shared adapter, and using Poly/MHR adapters (K 'basis' adapters as linear combinations). The core contribution for library building is Model-Based Clustering (MBC), a two-stage process: first, private LoRAs are trained for a fixed number of steps; then, tasks are clustered using k-means based on the cosine similarity of their flattened LoRA parameters, and finally, one adapter is trained per cluster using the combined datasets. For reusing the library, routing strategies include zero-shot methods (uniform 'µ Routing', 'TP Routing' with a task predictor, 'CM Routing' based on centroid matching, and the novel 'Arrow Routing') and supervised adaptation methods ('Poly Routing', 'LoraHub Routing', and 'π-tuning Routing'). Arrow Routing estimates a layer-specific routing matrix by applying SVD to the LoRA parameters (AiBTi) to find expert prototypes (first right singular vector), then routes per token and per layer by computing the absolute dot product alignment between hidden states and prototypes. Selected adapters are combined via linear weighting.",
    "Experimental Setup": "Experiments were conducted on Phi-2 (2.8B parameters) and Mistral 7B LLMs, with LoRA adapters patching only attention layers (rank 4, dropout 0.05, learning rate 1e-4). The multi-task dataset for library building consisted of 256 tasks from Flan v2, with 10,000 examples per task (1,000 for validation). Overlaps with evaluation tasks were removed. For zero-shot evaluation, 10 held-out tasks were used, including common-sense reasoning (WinoGrande, HellaSwag, PIQA), question answering (BoolQ, OpenbookQA, ARC-easy/hard), coding (HumanEval, MBPP), and general reasoning (BBH). Supervised adaptation was evaluated on 12 held-out SuperNatural Instructions (SNI) tasks with up to 10,000 examples each. Performance was measured using average accuracy for zero-shot tasks and Rouge-L scores for supervised adaptation. MBC typically used 10 clusters, with 40% of training steps for clustering and 60% for training cluster adapters. Baselines included Base (no adaptation), Shared (single multi-task LoRA), FullFT (full model finetuning), Poly, MHR, Private, and various routing strategies.",
    "Limitations": "The current investigation is primarily focused on LoRA adapters, limiting its direct applicability to other adapter types. The paper notes that Poly/MHR adapters are not clearly reusable for zero-shot generalization as their 'latent skills' do not correspond to specific tasks. It's observed that while Arrow routing narrows the performance gap with MBC, MBC sometimes performs better. For smaller libraries, the gains from sophisticated routing strategies diminish. The linearity of LoRA experts is suggested as a potential reason for differences in routing importance compared to sparse Mixture-of-Experts models with MLP experts, an area for further investigation. The scalability of the proposed approach to even greater data and model sizes remains an open question.",
    "Future Research Directions": "Future work includes extending the approach to a heterogeneous 'universe' of adapters beyond LoRA, such as soft and hard prompts, MLPs, and combinations thereof. Further investigation is needed to understand why greater diversity in expert clusters (lower similarity) tends to yield higher performance. The research also aims to explore the diminishing gains of routing for smaller libraries and its implications for the linear nature of LoRA experts versus non-linear MLP experts in sparse Mixture-of-Experts models. Finally, applying the proposed Arrow routing strategy to modular continual learning is a promising direction, potentially offering robustness against catastrophic forgetting due to its local, gradient-free nature.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Spectral Adapter: Fine-Tuning in Spectral Space",
    "Main Contributions": "The paper introduces Spectral Adapter, a Parameter-Efficient Fine-Tuning (PEFT) method that incorporates spectral information of pretrained weight matrices. It proposes two mechanisms: additive tuning (Spectral AdapterA) and orthogonal rotation (Spectral AdapterR) of top singular vectors. The key findings include demonstrating that spectral fine-tuning improves the rank capacity of low-rank adapters given a fixed trainable parameter budget, enhancing parameter efficiency, tuning performance, and benefiting multi-adapter fusion. This work is the first to fine-tune spectral space in a parameter-efficient and storage-economic way, offering a practical generic paradigm for fine-tuning tasks.",
    "Methodology": "The core methodology involves performing Singular Value Decomposition (SVD) of pretrained weight matrices (W=USV^T) and then fine-tuning the top-r columns of the singular vector matrices (U and V). Spectral AdapterA additively tunes these top columns, similar to LoRA, defined as W_tuned = [U1+AU U2]S[V1+AV V2]. Spectral AdapterR orthogonally rotates the top columns, resembling Orthogonal Fine-Tuning (OFT), defined as W_tuned = [U1RU U2]S[V1RV V2]. The orthogonality constraint for Spectral AdapterR is efficiently maintained using Cayley parameterization. Trainable parameters AU, AV are initialized to zero, while RU, RV are initialized to identity matrices. Theoretical analyses show that Spectral AdapterA has double the rank capacity of LoRA and that tuning top singular vectors is robust due to better subspace alignment.",
    "Experimental Setup": "The proposed spectral adapter was evaluated on large language models (LLMs) and diffusion models. For LLMs, DeBERTaV3-base (185M) was fine-tuned on GLUE benchmarks, Mistral 7B on GSM8K, and Llama3 8B on Orca Math dataset. For diffusion models, Chilloutmix diffusion model was fine-tuned for multi-object tuning, face generation, and custom concept generation (vase, chair, table). Baselines included LoRA, DoRA, OFT, AdaLoRA, SVDiff, LiDB, VeRA, Gradient Fusion, Orthogonal Adaptation, and FedAvg. Hyperparameters for baselines followed their original reports or official implementations, and Spectral AdapterA/R hyperparameters were tuned. Fine-tuning involved q, k, v matrices for LLMs and embedding layers, U-Net, and text-encoder for diffusion models. Evaluation metrics included accuracy (GLUE, GSM8K), training loss, validation scores, visual quality of generated images, and alignment scores computed using CLIP embeddings' cosine similarity. Experiments were conducted on NVIDIA RTX A6000 GPUs.",
    "Limitations": "One limitation lies in the current choice of tuning only the top spectral space. Although its validity is theoretically verified under simple settings, further investigation into tuning different columns of singular vector matrices is deemed critical for a deeper understanding of spectral information's role in fine-tuning. Another constraint is the increasing time consumption of the Singular Value Decomposition (SVD) procedure as model sizes grow, indicating a need for faster SVD methods. Additionally, the paper suggests that fine-tuning the spectral representation of only specific components (e.g., just the attention layer) of large models warrants further study.",
    "Future Research Directions": "Future research directions include a more in-depth investigation into tuning different columns of singular vector matrices beyond just the top ones, to gain a comprehensive understanding of the role of spectral information in fine-tuning. Exploring the fine-tuning of spectral representations of specific components within large models, such as only the attention layer, is also suggested. The paper also recommends dynamically combining spectral adaptation with other existing PEFT methods, such as AdaLoRA. Furthermore, to address the computational overhead, research into faster Singular Value Decomposition (SVD) methods, potentially utilizing techniques like randomized SVD, is encouraged as model sizes continue to increase.",
    "Experiment Code": "import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport copy # Used in merge_spectraloft_into_weight\n\n# Helper function for Cayley parameterization, defined within SpectralLinearLayer_OFT but also needed for merging.\ndef cayley(data: torch.Tensor) -> torch.Tensor:\n    r, _ = data.shape\n    skew = 0.5 * (data - data.T)\n    I = torch.eye(r, device=data.device)\n    Q = torch.mm(I - skew, torch.inverse(I + skew))\n    return Q\n\n# From adapter_efficiency/mix_spectral/Mix-of-Show/mixofshow/models/edlora.py\nclass SpectralLinearLayer_OFT(nn.Module):\n    def __init__(self, name, original_module, rank=4, alpha=1, top=True, idx=0, revised_r=-1):\n        super().__init__()\n        self.name = name\n        if original_module.__class__.__name__ == 'Conv2d':\n            self.conv = True\n            in_channels, out_channels = original_module.in_channels, original_module.out_channels\n        else:\n            self.conv = False\n            in_channels, out_channels = original_module.in_features, original_module.out_features\n        W = original_module.weight.data.view(out_channels, in_channels)\n        U, S, V = torch.svd(W)\n        self.U = torch.nn.Parameter(U, requires_grad=False)\n        self.S = torch.nn.Parameter(S, requires_grad=False)\n        self.V = torch.nn.Parameter(V, requires_grad=False)\n        self.spectral_A = torch.nn.Parameter(torch.zeros(revised_r,revised_r), requires_grad=True) # For U rotation\n        self.spectral_B = torch.nn.Parameter(torch.zeros(revised_r,revised_r), requires_grad=True) # For V rotation\n        self.spectral_C = torch.nn.Parameter(torch.ones(revised_r), requires_grad=True) # For S scaling\n        original_module.forward = self.forward\n        self.original_module = original_module\n        self.top = top\n        self.idx = idx\n        assert revised_r>0\n        self.rank = revised_r # The actual rank used for adaptation\n\n    def forward(self, hidden_states):\n        if self.top:\n            pad_U = self.U.clone()\n            # Apply orthogonal rotation to U's top-r columns using Cayley parametrization\n            pad_U[:,self.idx*self.rank:(self.idx+1)*self.rank] = self.U[:,self.idx*self.rank:(self.idx+1)*self.rank]@cayley(self.spectral_A)\n            pad_S = self.S.clone()\n            # Apply scaling to S's top-r values\n            pad_S[self.idx*self.rank:(self.idx+1)*self.rank] = self.S[self.idx*self.rank:(self.idx+1)*self.rank]*self.spectral_C\n            pad_V = self.V.clone()\n            # Apply orthogonal rotation to V's top-r columns using Cayley parametrization\n            pad_V[:,self.idx*self.rank:(self.idx+1)*self.rank] = self.V[:,self.idx*self.rank:(self.idx+1)*self.rank]@cayley(self.spectral_B)\n        else:\n            raise Exception('Only top-r tuning is implemented.')\n        pad_W = pad_U@pad_S.diag()@pad_V.T\n        if self.conv : # Not implemented for Conv2d\n            raise Exception('Conv2d adaptation not implemented in this snippet.')\n        else:\n            return F.linear(hidden_states, pad_W, bias=self.original_module.bias)\n\n# From adapter_efficiency/mix_spectral/Mix-of-Show/mixofshow/pipelines/trainer_edlora.py\n# Excerpt from EDLoRATrainer.set_finetune_cfg illustrating instantiation of SpectralLinearLayer_OFT\n# (This code would be executed during model setup):\n# For text_encoder linear layers:\n# lora_module = SpectralLinearLayer_OFT(name + '.' + child_name, child_module, **text_encoder_cfg['lora_cfg'], idx=0, revised_r=text_encoder_cfg['lora_cfg']['rank'])\n# self.text_encoder_lora.append(lora_module)\n# params_list.extend(list(lora_module.parameters()))\n\n# For unet linear/conv1x1 layers:\n# lora_module = SpectralLinearLayer_OFT(name + '.' + child_name, child_module, **unet_cfg['lora_cfg'], idx=0, revised_r=unet_cfg['lora_cfg']['rank'])\n# self.unet_lora.append(lora_module)\n# params_list.extend(list(lora_module.parameters()))\n\n\n# From adapter_efficiency/mix_spectral/Mix-of-Show/mixofshow/utils/convert_edlora_to_diffusers.py\ndef merge_spectraloft_into_weight(original_state_dict, lora_state_dict, model_type, alpha, top=True, idx=0):\n    # Assumes 'cayley' function is available in scope.\n\n    # ... (name parsing logic to find spectral_A_name, spectral_B_name, spectral_C_name, U_name, S_name, V_name)\n    # The full implementation would dynamically resolve these names based on the original_layer_name (k)\n    # For brevity, a simplified example of how the merging occurs:\n\n    new_state_dict = copy.deepcopy(original_state_dict)\n    load_cnt = 0\n    for k in new_state_dict.keys(): # Iterate over keys of the original model's state_dict\n        # Assume spectral_A_name, spectral_B_name, etc. are resolved for the current k\n        # For example, if k is 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight'\n        # then spectral_A_name would be 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.spectral_A'\n\n        # This simplified check demonstrates the logic; actual code uses a more robust naming convention.\n        if 'spectral_B' in lora_state_dict.keys(): # check if any spectral_B parameter exists in the lora_state_dict for current layer type\n            # Example placeholder for dynamically resolved names from a lora_state_dict matching 'k'\n            # In a real scenario, this would involve parsing `k` to find the corresponding lora_state_dict keys\n            spectral_A_params_key = k.replace('.weight', '.spectral_A') # This is a placeholder, actual logic is more complex\n            spectral_B_params_key = k.replace('.weight', '.spectral_B') # This is a placeholder\n            spectral_C_params_key = k.replace('.weight', '.spectral_C') # This is a placeholder\n            U_params_key = k.replace('.weight', '.U') # This is a placeholder\n            S_params_key = k.replace('.weight', '.S') # This is a placeholder\n            V_params_key = k.replace('.weight', '.V') # This is a placeholder\n            \n            if (spectral_A_params_key in lora_state_dict and spectral_B_params_key in lora_state_dict and \n                spectral_C_params_key in lora_state_dict and U_params_key in lora_state_dict and \n                S_params_key in lora_state_dict and V_params_key in lora_state_dict):\n\n                load_cnt += 1\n                original_params = new_state_dict[k]\n                spectral_A_params = lora_state_dict[spectral_A_params_key].to(original_params.device)\n                spectral_B_params = lora_state_dict[spectral_B_params_key].to(original_params.device)\n                spectral_C_params = lora_state_dict[spectral_C_params_key].to(original_params.device)\n                U_params = lora_state_dict[U_params_key].to(original_params.device)\n                S_params = lora_state_dict[S_params_key].to(original_params.device)\n                V_params = lora_state_dict[V_params_key].to(original_params.device)\n                r = spectral_A_params.shape[0] # Rank of the adapter\n\n                if top:\n                    pad_U = U_params.clone() \n                    # Apply scaled Cayley rotation to U's top-r columns\n                    pad_U[:,idx*r:(idx+1)*r] = U_params[:,idx*r:(idx+1)*r]@(alpha*(cayley(spectral_A_params)-torch.eye(r).to(spectral_A_params.device))+torch.eye(r).to(spectral_A_params.device))\n                    pad_V = V_params.clone()\n                    # Apply scaled Cayley rotation to V's top-r columns\n                    pad_V[:,idx*r:(idx+1)*r] = V_params[:,idx*r:(idx+1)*r]@(alpha*(cayley(spectral_B_params)-torch.eye(r).to(spectral_A_params.device))+torch.eye(r).to(spectral_A_params.device))\n                    pad_S = S_params.clone()\n                    # Apply scaled additive adjustment to S's top-r values\n                    pad_S[idx*r:(idx+1)*r] = S_params[idx*r:(idx+1)*r]*(alpha*(spectral_C_params-torch.ones(r).to(spectral_A_params.device))+torch.ones(r).to(spectral_A_params.device))\n                else:\n                    raise Exception('Only top-r tuning is implemented.')\n                \n                # Reconstruct the tuned weight matrix\n                spectral_param = pad_U@pad_S.diag()@pad_V.T\n                new_state_dict[k] = spectral_param # Update the main weight for the layer\n    return new_state_dict",
    "Experiment Result": "The core methodology described, focusing on 'Spectral AdapterR', involves: \n- **Singular Value Decomposition (SVD)**: The pretrained weight matrices (W) are factorized into U, S, V^T (W = USV^T) at initialization within the `SpectralLinearLayer_OFT` module. U, S, and V are stored as non-trainable parameters.\n- **Fine-tuning Strategy**: The method tunes the top-`r` columns of the singular vector matrices (U and V) through orthogonal rotations and scales the corresponding top-`r` singular values (S).\n- **Orthogonality Constraint**: For the orthogonal rotations applied to U and V, the orthogonality constraint is maintained using Cayley parameterization. This is implemented via the `cayley` function.\n- **Trainable Parameters**: Three sets of parameters are introduced per adapted layer:\n    - `spectral_A` (rank `r` x `r` matrix): Learned parameters that, when transformed by the Cayley function, produce the orthogonal rotation matrix `RU` for the U matrix.\n    - `spectral_B` (rank `r` x `r` matrix): Learned parameters that, when transformed by the Cayley function, produce the orthogonal rotation matrix `RV` for the V matrix.\n    - `spectral_C` (rank `r` vector): Learned parameters that directly scale the singular values in S.\n- **Parameter Initialization**:\n    - `spectral_A` and `spectral_B` are initialized to zero matrices. When passed through the Cayley transformation, these result in initial identity rotation matrices (RU = I, RV = I), as specified in the method.\n    - `spectral_C` is initialized to a vector of ones. This means the singular values are initially scaled by 1.\n- **Rank (`r`)**: The number of top singular vectors/values to be fine-tuned (`top-r`) is specified by the `revised_r` argument passed to `SpectralLinearLayer_OFT`, which is typically configured via `lora_cfg['rank']` in the `finetune_cfg` (e.g., a common default or configured value is `8`).\n- **Alpha Parameter (`alpha`)**: An `alpha` scaling factor is applied during the merging process to control the strength of the adaptation. It scales the deviation from the identity transformation for rotations (`alpha*(cayley(params)-I) + I`) and from the initial scaling of one for singular values (`S_original * (alpha*(C_params-ones) + ones)`).\n- **Adapted Modules**: The `SpectralLinearLayer_OFT` module replaces `Linear` layers and `Conv2d` layers with (1,1) kernel size in both the text encoder and the UNet model."
}{
    "Title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers",
    "Main Contributions": "The paper proposes COMPACTER (Compact Adapter) layers, a parameter-efficient method for fine-tuning large-scale language models. COMPACTER builds on ideas from adapters, low-rank optimization, and parameterized hypercomplex multiplication (PHM) layers. It achieves an excellent trade-off between task performance and the number of trainable parameters by computing task-specific weight matrices as a sum of Kronecker products between shared 'slow' weights and 'fast' rank-one matrices defined per COMPACTER layer. This approach reduces parameter complexity from O(kd) for regular adapters to O(k+d). COMPACTER trains only 0.047% of a pretrained model's parameters (e.g., T5BASE) while performing on par with standard fine-tuning on GLUE and outperforming it on SuperGLUE and in low-resource settings. The work also provides a parameter complexity analysis and a systematic evaluation of various parameter-efficient fine-tuning methods.",
    "Methodology": "COMPACTER integrates into a pretrained Transformer model by inserting adapter layers after the attention and feed-forward modules. Unlike standard adapters, COMPACTER replaces the down-projection (Dl) and up-projection (Ul) layers with Low-rank Parameterized Hypercomplex Multiplication (LPHM) layers. An LPHM layer's weight matrix (W) is computed as a sum of 'n' Kronecker products: W = SUM(Ai ⊗ Bi). Here, Ai are 'slow' weights shared across all adapter layers, capturing general information. Bi are adapter-specific 'fast' weights, which are parameterized as low-rank matrices (specifically, rank-one matrices where Bi = si * ti^T, with si and ti being rank-one weights). This allows for flexible sharing and significant parameter reduction. Only the adapter layers and layer normalizations are trained, while the pretrained model's parameters are fixed. A variant, COMPACTER++, keeps the COMPACTER layer only after the feed-forward layer in each transformer block.",
    "Experimental Setup": "The underlying model used is the state-of-the-art encoder-decoder T5BASE (222M parameters) from HuggingFace PyTorch implementation, with some evaluations also on T5SMALL (60M parameters). Performance is evaluated on the GLUE and SUPERGLUE benchmarks, which cover various NLP tasks like paraphrase detection, sentiment classification, natural language inference, and question-answering. For validation, 1k samples are split from the training set, and original validation data is used as the test set. For datasets with less than 10k samples, the original validation set is halved for validation and testing. Models are fine-tuned for 3 epochs on large datasets and 20 epochs on low-resource datasets. Adapter bottleneck sizes are {96, 48, 24}, and COMPACTER's 'n' hyperparameter is set to {4, 8, 12}. The AdamW optimizer is used, with learning rates tuned from {3e-5, 3e-4, 3e-3, 3e-2, 3e-1}. The output layer of the pretrained model is frozen by default. Efficiency is evaluated by training for 1 epoch on the MNLI dataset, measuring trained parameters, average peak memory usage (fixed GPU budget of 24 GB), and training time per epoch.",
    "Limitations": "The work notes that sharing all adapter parameters across layers, as in some prior methods, is too restrictive and underperforms. Prompt tuning methods exhibit high sensitivity to initialization and learning rate, often lagging behind fine-tuning, and require very large models to perform well, with increasing sequence length leading to memory overhead. INTRINSIC-SAID suffers from substantial memory overhead due to storing large random projection matrices and is very slow to train, making it intractable for large PLMs despite theoretical efficiency. For smaller T5 models (T5SMALL), parameter-efficient fine-tuning methods, including COMPACTER, perform worse than full fine-tuning. Additionally, a significant proportion of trainable parameters in COMPACTER and COMPACTER++ still come from layer normalizations and biases within the LPHM layers.",
    "Future Research Directions": "Potential future research directions include combining COMPACTER with contextual parameter generation to create adapter modules, exploring adaptation without updating layer normalization by leveraging recent advances in normalization-free models, and applying general techniques like AdapterDrop to COMPACTER for further efficiency improvements. The authors also suggest investigating higher rank 'r' values for the Bi matrices in LPHM beyond r=1 for more complex tasks or overcomplete knowledge distillation, and further reducing parameters by exploring methods to remove biases from adapters.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nfrom typing import Union, Optional\nimport torch.nn.functional as F\n\nfrom .inits import glorot_uniform, glorot_normal\nfrom .kronecker import kronecker_product, kronecker_product_einsum_batched\n\ndef matvec_product(W: torch.Tensor, x: torch.Tensor,\n                       bias: Optional[torch.Tensor],\n                       phm_rule: Union[torch.Tensor],\n                       kronecker_prod=False) -> torch.Tensor:\n    \"\"\"\n    Functional method to compute the generalized matrix-vector product based on the paper\n    \"Parameterization of Hypercomplex Multiplications (2020)\"\n    https://openreview.net/forum?id=rcQdycl0zyk\n    y = Hx + b , where W is generated through the sum of kronecker products from the Parameterlist W, i.e.\n    W is a an order-3 tensor of size (phm_dim, in_features, out_features)\n    x has shape (batch_size, phm_dim*in_features)\n    phm_rule is an order-3 tensor of shape (phm_dim, phm_dim, phm_dim)\n    H = sum_{i=0}^{d} mul_rule \\otimes W[i], where \\otimes is the kronecker product\n    \"\"\"\n    if kronecker_prod:\n       H = kronecker_product(phm_rule, W).sum(0)\n    else: \n       H = kronecker_product_einsum_batched(phm_rule, W).sum(0)\n\n    y = torch.matmul(input=x, other=H)\n    if bias is not None:\n        y += bias\n    return y\n\n\nclass PHMLinear(torch.nn.Module):\n    def __init__(self,\n                 in_features: int,\n                 out_features: int,\n                 phm_dim: int,\n                 phm_rule: Union[None, torch.Tensor] = None,\n                 bias: bool = True,\n                 w_init: str = \"phm\",\n                 c_init: str = \"random\",\n                 learn_phm: bool = True,\n                 shared_phm_rule=False,\n                 factorized_phm=False,\n                 shared_W_phm=False,\n                 factorized_phm_rule=False,\n                 phm_rank = 1,\n                 phm_init_range=0.0001,\n                 kronecker_prod=False) -> None:\n        super(PHMLinear, self).__init__()\n        assert w_init in [\"phm\", \"glorot-normal\", \"glorot-uniform\", \"normal\"]\n        assert c_init in [\"normal\", \"uniform\"]\n        assert in_features % phm_dim == 0, f\"Argument `in_features`={in_features} is not divisble be `phm_dim`{phm_dim}\"\n        assert out_features % phm_dim == 0, f\"Argument `out_features`={out_features} is not divisble be `phm_dim`{phm_dim}\"\n        self.in_features = in_features\n        self.out_features = out_features\n        self.learn_phm = learn_phm\n        self.phm_dim = phm_dim\n        self._in_feats_per_axis = in_features // phm_dim\n        self._out_feats_per_axis = out_features // phm_dim\n        self.phm_rank = phm_rank\n        self.phm_init_range = phm_init_range\n        self.kronecker_prod=kronecker_prod\n        self.shared_phm_rule = shared_phm_rule\n        self.factorized_phm_rule = factorized_phm_rule \n        if not self.shared_phm_rule:\n            if self.factorized_phm_rule:\n                self.phm_rule_left = nn.Parameter(torch.FloatTensor(phm_dim, phm_dim, 1),\n                       requires_grad=learn_phm)\n                self.phm_rule_right = nn.Parameter(torch.FloatTensor(phm_dim, 1, phm_dim),\n                       requires_grad=learn_phm)\n            else:\n                self.phm_rule = nn.Parameter(torch.FloatTensor(phm_dim, phm_dim, phm_dim), \n                       requires_grad=learn_phm)\n        self.bias_flag = bias\n        self.w_init = w_init\n        self.c_init = c_init\n        self.shared_W_phm = shared_W_phm \n        self.factorized_phm = factorized_phm\n        if not self.shared_W_phm:\n            if self.factorized_phm:\n                self.W_left = nn.Parameter(torch.Tensor(size=(phm_dim, self._in_feats_per_axis, self.phm_rank)),\n                              requires_grad=True)\n                self.W_right = nn.Parameter(torch.Tensor(size=(phm_dim, self.phm_rank, self._out_feats_per_axis)),\n                              requires_grad=True)\n            else:\n                self.W = nn.Parameter(torch.Tensor(size=(phm_dim, self._in_feats_per_axis, self._out_feats_per_axis)),\n                              requires_grad=True)\n        if self.bias_flag:\n            self.b = nn.Parameter(torch.Tensor(out_features))\n        else:\n            self.register_parameter(\"b\", None)\n        self.reset_parameters()\n\n    def init_W(self):\n        if self.w_init == \"glorot-normal\":\n            if self.factorized_phm:\n                for i in range(self.phm_dim):\n                    self.W_left.data[i] = glorot_normal(self.W_left.data[i])\n                    self.W_right.data[i] = glorot_normal(self.W_right.data[i])\n            else:\n                for i in range(self.phm_dim):\n                    self.W.data[i] = glorot_normal(self.W.data[i])\n        elif self.w_init == \"glorot-uniform\":\n            if self.factorized_phm:\n                for i in range(self.phm_dim):\n                    self.W_left.data[i] = glorot_uniform(self.W_left.data[i])\n                    self.W_right.data[i] = glorot_uniform(self.W_right.data[i])\n            else:\n                for i in range(self.phm_dim):\n                    self.W.data[i] = glorot_uniform(self.W.data[i])\n        elif self.w_init == \"normal\":\n            if self.factorized_phm:\n                for i in range(self.phm_dim):\n                    self.W_left.data[i].normal_(mean=0, std=self.phm_init_range)\n                    self.W_right.data[i].normal_(mean=0, std=self.phm_init_range)\n            else:\n                for i in range(self.phm_dim):\n                    self.W.data[i].normal_(mean=0, std=self.phm_init_range)\n        else:\n            raise ValueError\n\n    def reset_parameters(self):\n        if not self.shared_W_phm:\n           self.init_W()\n\n        if self.bias_flag:\n            self.b.data = torch.zeros_like(self.b.data)\n\n        if not self.shared_phm_rule:\n            if self.factorized_phm_rule:\n                if self.c_init == \"uniform\":\n                   self.phm_rule_left.data.uniform_(-0.01, 0.01)\n                   self.phm_rule_right.data.uniform_(-0.01, 0.01)\n                elif self.c_init == \"normal\":\n                   self.phm_rule_left.data.normal_(std=0.01)\n                   self.phm_rule_right.data.normal_(std=0.01)\n                else:\n                   raise NotImplementedError\n            else:\n                if self.c_init == \"uniform\":\n                   self.phm_rule.data.uniform_(-0.01, 0.01)\n                elif self.c_init == \"normal\":\n                   self.phm_rule.data.normal_(mean=0, std=0.01)\n                else:\n                   raise NotImplementedError\n\n    def set_phm_rule(self, phm_rule=None, phm_rule_left=None, phm_rule_right=None):\n        \"\"\"If factorized_phm_rules is set, phm_rule is a tuple, showing the left and right\n        phm rules, and if this is not set, this is showing  the phm_rule.\"\"\"\n        if self.factorized_phm_rule:\n            self.phm_rule_left = phm_rule_left\n            self.phm_rule_right = phm_rule_right \n        else:\n            self.phm_rule = phm_rule \n \n    def set_W(self, W=None, W_left=None, W_right=None):\n        if self.factorized_phm:\n            self.W_left = W_left\n            self.W_right = W_right\n        else:\n            self.W = W\n\n    def forward(self, x: torch.Tensor, phm_rule: Union[None, nn.ParameterList] = None) -> torch.Tensor:\n        if self.factorized_phm:\n           W = torch.bmm(self.W_left, self.W_right)\n        if self.factorized_phm_rule:\n           phm_rule = torch.bmm(self.phm_rule_left, self.phm_rule_right)\n        return matvec_product(\n               W=W if self.factorized_phm else self.W,\n               x=x,\n               bias=self.b,\n               phm_rule=phm_rule if self.factorized_phm_rule else self.phm_rule, \n               kronecker_prod=self.kronecker_prod)\n",
    "Experiment Result": "{\n  \"train_task_adapters\": true,\n  \"add_adapter_in_feed_forward\": true,\n  \"add_adapter_in_self_attention\": true,\n  \"hypercomplex_adapters\": true,\n  \"hypercomplex_division\": 8,\n  \"learn_phm\": true,\n  \"hypercomplex_nonlinearity\": \"glorot-uniform\",\n  \"shared_phm_rule\": true,\n  \"factorized_phm\": true,\n  \"shared_W_phm\": false,\n  \"factorized_phm_rule\": false,\n  \"phm_c_init\": \"normal\",\n  \"phm_rank\": 1,\n  \"phm_init_range\": 0.01,\n  \"add_layer_norm_before_adapter\": false,\n  \"add_layer_norm_after_adapter\": true,\n  \"non_linearity\": \"swish\",\n  \"task_reduction_factor\": 16,\n  \"unfreeze_lm_head\": false,\n  \"unfreeze_layer_norms\": true\n}"
}{
    "Title": "The Expressive Power of Low-Rank Adaptation",
    "Main Contributions": "This paper presents the first theoretical analysis of the expressive power of Low-Rank Adaptation (LoRA) for Fully Connected Neural Networks (FNNs) and Transformer Networks (TFNs). It identifies the minimum LoRA-rank required for a frozen model to exactly match a target model and quantifies the approximation error when the LoRA-rank is below this threshold. For FNNs, it proves that any smaller target model can be accurately represented if the LoRA-rank is sufficient (width * depth of f / M, where M is the ratio of frozen to target depth). For TFNs, it shows adaptation to a target model of the same size with rank-(embedding size/2) LoRA adapters for attention weight matrices. The study offers theoretical insights into hyperparameter tuning and algorithm development, which are empirically validated.",
    "Methodology": "The methodology starts with analyzing linear models, extending the Eckart-Young-Mirsky theorem to products of low-rank adapted matrices. For FNNs, it employs a two-step process: (i) 'Linearization' by setting large biases to activate all ReLUs in initial layers, and (ii) 'Weight Matrix Alignment' to match parameters using low-rank adapters and updated biases. This is further extended to multi-layer FNNs using 'model partition' strategies (uniform or general with varying LoRA-ranks). For TFNs, the approach addresses nonlinearities (softmax, ReLU) by segmenting transformer blocks and aligning outputs before activations, primarily adapting self-attention layers. All analyses rely on a non-singularity assumption for weight matrices, which is proven to hold for randomly generated matrices.",
    "Experimental Setup": "Experiments are conducted on both synthetic and real datasets. For synthetic data, linear models and FNNs (D=16, varying depths) and TFNs (D=16, L=1, 2 attention heads) are used. Frozen models are either randomly initialized with Xavier uniform distribution or 'pretrained' to be closer to the target model. Validation uses Mean Squared Error (MSE) for regression and accuracy for classification tasks (binary and multi-class). LoRA adapters derived from theoretical construction are compared against those optimized by Adam with tuned learning rates ({10^-2, 10^-3, 10^-4}) and weight decay ({0, 10^-2, 10^-3, 10^-4}). Generalization performance is assessed with 400-800 training samples. Real-world validation employs the GLUE benchmark with RoBERTa-base (110M parameters) and RoBERTa-large (340M parameters), utilizing GPU resources and standard GLUE metrics.",
    "Limitations": "The work exclusively focuses on the expressive power of LoRA, consciously excluding optimization and generalization aspects. Theoretical proofs rely on a mild non-singularity assumption for weight matrices and a bounded input space for FNNs. For TFNs, skip connections and layer norms are omitted for analytical feasibility, and the analysis is restricted to models with identical embedding size and depth. The paper's theoretical construction of LoRA adapters is noted to be suboptimal compared to gradient-based methods in some low-rank regions for multi-layer FNNs, possibly due to rigid intermediate output matching or uniform partitioning. For TFNs, the current work lacks quantification of approximation error when ranks are lower than required.",
    "Future Research Directions": "Future research includes quantifying approximation errors for TFNs when LoRA-ranks are below the required threshold, refining LoRA adapter update algorithms for more parameter-efficient constructions and tighter error bounds, and extending TFN analysis to more general architectures (e.g., varying embedding sizes, depths, and incorporating skip connections and layer norms). Additionally, investigating gradient-based optimization algorithms for LoRA's efficiency and exploring the theoretical aspects of LoRA's generalization performance to unseen data are open research avenues.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning",
    "Main Contributions": "The paper addresses matrix estimation problems in low-rank reinforcement learning (RL) and bandits, focusing on recovering expected arm rewards or transition kernels with low entry-wise error, even with correlated data. It introduces simple spectral-based matrix estimation approaches that efficiently recover singular subspaces and achieve nearly-minimal entry-wise error. Key contributions include: 1) Proposing three matrix estimation problems (low-rank bandits, low-rank MDPs with generative model, low-rank MDPs with forward model) and providing strong performance guarantees for spectral methods, utilizing leave-one-out arguments and Poisson approximation techniques for correlated data. 2) Developing SME-AE, an efficient regret-minimization algorithm for low-rank bandits with state-of-the-art regret guarantees scaling as O((m+n)log^3(T) * \bar{\\Delta} / \\Delta_min^2). 3) Presenting a minimax-optimal sample complexity algorithm for best policy identification in reward-free low-rank MDPs, achieving O(nA/\\epsilon^2) up to logarithmic factors.",
    "Methodology": "The core methodology involves simple spectral decomposition. For matrix estimation, an empirical matrix \\tilde{M} is constructed from data, and the estimate \\hat{M} is obtained by taking its best rank-r approximation. \\hat{P} (for transition matrices) is derived by normalizing rows of \\hat{M}. To handle correlated data (especially in MDPs), the proofs develop and combine leave-one-out arguments and Poisson approximation techniques. The proof strategy involves: 1) Multinomial approximation of Markovian data, 2) Approximation towards Poisson random matrices with independent entries, and 3) Applying a leave-one-out analysis (including a dilation trick for symmetry) to decouple statistical dependencies. For low-rank bandits, the SME-AE algorithm employs an iterative process of sampling, matrix estimation via spectral decomposition, and arm elimination based on estimated reward gaps. For reward-free RL in low-rank MDPs, the approach has two phases: model estimation using spectral decomposition from trajectories to build estimates of transition matrices, followed by a planning phase to compute the optimal policy.",
    "Experimental Setup": "The research paper is primarily theoretical, focusing on mathematical proofs and performance guarantees rather than empirical experiments. The 'experimental setup' refers to the data generation models for which the theoretical guarantees are derived: 1) Low-Rank Bandits (Model I): Arm (i,j) is sampled (e.g., uniformly), and a noisy reward M_i,j + \\xi_t is observed, where \\xi_t are zero-mean and bounded. 2) Low-Rank MDPs (Model IIa, Generative Model): For estimating transition matrix P (or frequency matrix M = diag(\\nu)P), data consists of T pairs (x_t, x_{t+1}) where x_t is drawn from a distribution and x_{t+1} from P_{x_t,:}. 3) Low-Rank MDPs (Model IIb, Forward Model): Data consists of a single trajectory (x_1, ..., x_T) of a Markov chain, where x_1 is from \\nu_0 and x_{t+1} from P_{x_t,:}. The forward model's data is split into subsets to manage correlations. Validation is through rigorous finite-time performance guarantees, regret bounds, and sample complexity analyses, comparing against known minimax lower bounds.",
    "Limitations": "The design of algorithms for low-rank structures with provable performance guarantees in RL remains largely open. A specific limitation of the proposed regret bound for low-rank bandits (SME-AE) is the 'cubic dependence in log^3(T)', which is identified as an artifact of the proof techniques, specifically due to the Poisson approximation used for entry-wise guarantees. While the proposed algorithm improves upon some prior works in terms of scaling with matrix dimensions (m+n instead of n*m or sqrt(n)*(n+m)), other related works might exhibit better dependence on T and minimum reward gaps. The comparison with other matrix estimation methods notes that some require strong assumptions like access to 'anchor rows and columns' or are limited to 'generative models' with independent data samples, which the authors' method avoids.",
    "Future Research Directions": "The authors believe their low-rank matrix estimation results can find many more applications in low-rank RL. Specific future research directions include: (i) Applying the results to reward-free RL in episodic MDPs, which is a simpler setting than studied; (ii) Extending to offline RL scenarios where data is a single trajectory generated under a behavior policy; (iii) Applying to traditional RL where the reward function R needs to be learned, positioning this problem between the studied Models I and II; (iv) Utilizing the methods for model-free RL to directly learn the Q-function; (v) Adapting to low-rank RL problems with continuous state spaces by combining the methods with appropriate discretization, assuming smooth transition probabilities.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Low-rank Optimal Transport: Approximation, Statistics and Debiasing",
    "Main Contributions": "This paper addresses the need for scalable Optimal Transport (OT) solvers for large datasets by advancing the understanding and practical application of Low-rank Optimal Transport (LOT). The main contributions include deriving the rate of convergence of LOT to true OT, providing the first statistical complexity upper-bound for LOT's plug-in estimator (O(sqrt(1/n)) independent of dimension), introducing a debiased LOT (DLOTr,c) that is non-negative, metrizes weak convergence, and interpolates between MMD and OT. It also establishes links between low-rank factorization bias and clustering methods (generalizing k-means) and proposes practical strategies for adaptive step-length tuning and improved initialization for LOT algorithms.",
    "Methodology": "The core methodology involves constraining the discrete OT problem to couplings with low-nonnegative rank. The problem (Eq. 3) is reformulated (Eq. 4) and solved using a mirror descent scheme. The paper extends LOT for arbitrary probability measures by factorizing couplings into a sum of Kronecker products. Approximation error is analyzed using entropy numbers. For statistical analysis, a plug-in estimator for LOT is considered. A debiased version, DLOTr,c, is introduced to ensure desirable properties for machine learning applications, showing its relation to MMD and OT. Furthermore, LOT's self-matching cost (LOTk,c(µ,µ)) is interpreted as a generalized k-means clustering method. Practical improvements to the mirror descent algorithm include an adaptive step-size strategy (Eq. 8) that normalizes by the squared dual-norm of the gradient and novel initialization methods based on clustering (k-means for Euclidean space (Eq. 9) and generalized k-means for non-Euclidean cases (Eq. 10)).",
    "Experimental Setup": "Experiments were conducted on 3 synthetic problems and 1 real-world dataset (Newsgroup20 dataset, text embedded into 50D distributions). For statistical rates, two independent empirical measures from a mixture of 10 anisotropic Gaussians on Rd were used, with varying sample sizes (n) and dimensions (d), considering multiple ranks (r). Gradient flows of DLOTr,c and LOTr,c were compared by minimizing losses from a Gaussian distribution to a moon shape distribution in 2D, with r=100 and 1000 samples. Clustering applications utilized 6 scikit-learn datasets, comparing squared Euclidean distance (k-means) with shortest-path distance on a graph, for fixed ranks (r=2, 3, or 4). Initialization effects were studied on the Newsgroup20 dataset with approximately 250 samples, comparing k-means, generalized k-means, rank-2, and random initializations, tracking LOT cost and stopping criterion over algebraic operations. All experiments were run on a MacBook Pro 2019 laptop.",
    "Limitations": "Existing entropic regularized OT solvers scale quadratically, posing computational challenges. While low-rank approaches show empirical promise, their theoretical properties were not well-established prior to this work. The LOT optimization problem is non-convex, meaning convergence can be sensitive to initialization and potentially lead to spurious local minima. The provided statistical upper bound for the plug-in estimator does not have a matching lower bound, thus a complete statistical complexity result is not achieved. The constant Kr in Proposition 4 is not explicitly controlled in the general setting, requiring additional assumptions. The fixed gamma schedule for mirror descent in previous work requires problem-specific tuning, as the admissible range varies.",
    "Future Research Directions": "Future research should focus on further investigating the empirical behavior of the LOT estimator. Specific areas include developing methods to find suitable local minima for the non-convex LOT problem and exploring alternative adaptive strategies for step-size selection to improve the convergence of the mirror descent scheme. Additionally, a key theoretical direction is to derive a lower bound for the statistical complexity that matches the upper bound presented in this paper, to provide a more complete understanding of LOT's statistical properties.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Low-rank lottery tickets: finding efficient low-rank neural networks via matrix differential equations",
    "Main Contributions": "The paper introduces Dynamic Low-Rank Training (DLRT), a novel algorithm that finds efficient low-rank subnetworks in neural networks directly during the training phase. This addresses the significant memory footprint and computational demands of large neural networks. DLRT restricts weight matrices to a low-rank manifold and dynamically adapts their ranks using techniques derived from dynamic model order reduction for matrix differential equations. It provides approximation, stability, and descent guarantees, leading to significantly reduced training and evaluation time and memory resources while maintaining comparable accuracy to full-rank networks. This approach is likened to finding \"low-rank winning tickets\" without heavy reliance on initial weight guesses.",
    "Methodology": "DLRT reinterprets neural network training as a continuous-time gradient flow, formulating it as a system of matrix Ordinary Differential Equations (ODEs) for the low-rank factors (Uk, Sk, Vk) of the weight matrices Wk = UkSkV⊤k. The algorithm employs an \"unconventional KLS integrator\" and its rank-adaptive extension to numerically solve these ODEs. This involves alternating K-steps and L-steps (updating Kk=UkSk and Lk=VkS⊤k, respectively, and forming new orthonormal bases) and an S-step (updating Sk). Rank adaptivity is achieved by augmenting basis dimensions and subsequently truncating singular values of Sk based on a user-defined threshold (ϑ). Gradients are computed efficiently by taping them with respect to the low-rank factors (Kk, Lk, Sk) rather than the full weight matrix, reducing computational overhead. Numerical integration uses either Explicit Euler (SGD) or Adam optimizers. QR decomposition is used for orthonormal basis computation, and SVD for singular value truncation. For convolutional layers, filters are reshaped into matrices to enable low-rank decomposition.",
    "Experimental Setup": "The DLRT algorithm was evaluated across various neural network architectures, including fully-connected and convolutional networks (LeNet5, ResNet-50, AlexNet, VGG16), on datasets such as MNIST, Cifar10, and ImageNet1K. For MNIST, networks with 5 layers and up to 5120 neurons were trained, alongside LeNet5, using Adam or SGD optimizers, ReLU/softmax activations, sparse categorical cross-entropy loss, and batch sizes of 128-256 for up to 250 epochs. For ImageNet1K and Cifar10, ResNet-50, AlexNet, and VGG16 were trained with SGD and momentum. Comparisons were made against full-rank baselines and numerous existing compression/pruning methods (e.g., SVD prune, LRNN, GAL, SSL, NISP, PP, CP, SFP, ThiNet, RNP), focusing on training/prediction times, rank evolution, test accuracy, parameter count, and compression ratios. The implementation used TensorFlow and PyTorch, running on AMD Ryzen 9 3950X CPU and Nvidia RTX 3090/A-100 GPUs.",
    "Limitations": "The efficiency of DLRT is contingent on the ranks (rk) being significantly smaller than the dimensions of the weight matrices (nk, nk+1). If the singular value truncation threshold (ϑ) is too small, the method offers no advantages over standard training. DLRT primarily reduces training costs related to model parameters and the optimizer, but does not inherently reduce activation costs, requiring combination with other techniques like micro-batching or checkpointing for further reduction. The truncation threshold ϑ introduces an additional hyperparameter that currently requires external tuning. Although achieving superior compression, DLRT may yield slightly lower accuracy compared to some baseline pruning methods. Initial training epochs may also exhibit higher parameter counts until rank reduction stabilizes.",
    "Future Research Directions": "While not explicitly detailed, potential future research directions include investigating methods to automatically tune the singular value truncation threshold (ϑ), reducing the need for manual hyperparameter selection. Further exploration could involve combining DLRT with complementary techniques such as micro-batching or checkpointing to achieve additional reductions in activation costs. Applying and evaluating DLRT on more complex or emerging neural network architectures (e.g., Transformers) and extending its applicability to diverse domains beyond image classification could also be fruitful avenues for future work.",
    "Experiment Code": "import torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch import float16   \n\nclass dlr_opt:\n\n    def __init__(self,NN,tau = 0.01,theta = 0.1,absolute = False,\n                KLS_optim = None,**kwargs):\n\n        \"\"\"\n        initializer for the dlr_opt (dynamical low rank optimizer) class.\n        INPUTS:\n        NN: neural network with custom layers, methods and attributes needed (look at Lenet5 for an example) \n        tau : learning rate (integration step)\n        theta : tolerance for singular values\n        absolute : flag variable, True if theta has to be interpreted as an absolute tolerance  \n        KLS_optim : Pytorch integrator to perform the integration step\n        \"\"\"\n\n        self.NN = NN\n        self.tau = tau\n        self.theta = theta\n        self.absolute = absolute\n        self.kw = dict(kwargs)\n        self.KLS_optim = KLS_optim\n\n        if self.KLS_optim is not None:\n\n            self.integrator = self.KLS_optim(self.NN.parameters(),lr = self.tau,**kwargs)\n\n        else:\n\n            self.integrator = torch.optim.SGD(self.NN.parameters(),lr = self.tau,**kwargs)\n\n\n    @torch.no_grad()\n    def K_postprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n                    \n                    U_hat = torch.hstack((l.K[:,:l.dynamic_rank],l.U[:,:l.dynamic_rank]))\n\n                    try:\n                        U_hat,_ = torch.linalg.qr(U_hat)\n                    except:\n                        U_hat,_ = np.linalg.qr(U_hat)\n                        U_hat = torch.tensor(U_hat)\n                    l.U_hat[:,:2*l.dynamic_rank] = U_hat\n                    l.M_hat[:2*l.dynamic_rank,:l.dynamic_rank] = l.U_hat[:,:2*l.dynamic_rank].T@l.U[:,:l.dynamic_rank]\n                \n                else:\n\n                    try:\n                        U_hat,_ = torch.linalg.qr(l.K)\n\n                    except:\n                        U_hat,_ = np.linalg.qr(U_hat)\n                        U_hat = torch.tensor(U_hat)\n                    l.M_hat.data = U_hat.T@l.U.data\n                    l.U.data = U_hat\n\n    @torch.no_grad()\n    def postprocess_step(self):\n        \n        self.K_postprocess_step()\n        self.L_postprocess_step()\n\n    @torch.no_grad()\n    def K_integration_step(self):\n        \n        self.zero_bias_grad()\n        self.integrator.step()\n\n    @torch.no_grad()\n    def zero_bias_grad(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'bias') and l.bias is not None:\n\n                l.bias.grad = None\n\n            if hasattr(l,'weight') and l.weight is not None:\n\n                l.weight.grad = None\n\n    @torch.no_grad()\n    def L_postprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n\n                    V_hat = torch.hstack((l.L[:,:l.dynamic_rank],l.V[:,:l.dynamic_rank]))\n                    try :\n                        V_hat,_ = torch.linalg.qr(V_hat)\n                    except:\n                        V_hat,_ = np.linalg.qr(V_hat.detach().numpy())\n                        V_hat= torch.tensor(V_hat)\n                    l.V_hat[:,:2*l.dynamic_rank] = V_hat\n                    l.N_hat[:2*l.dynamic_rank,:l.dynamic_rank] = l.V_hat[:,:2*l.dynamic_rank].T@l.V[:,:l.dynamic_rank]\n\n                else:\n\n                    try :\n                        V_hat,_ = torch.linalg.qr(l.L)\n                    except:\n                        V_hat,_ = np.linalg.qr(V_hat.detach().numpy())\n                        V_hat= torch.tensor(V_hat)\n                    l.N_hat.data = V_hat.T@l.V.data\n                    l.V.data = V_hat\n\n\n    \n    @torch.no_grad()\n    def L_integration_step(self):\n\n\n        self.integrator.step()\n        self.integrator.zero_grad()\n\n    @torch.no_grad()\n    def K_and_L_integration_step(self):\n        \n        self.zero_bias_grad()\n        self.integrator.step()\n\n    @torch.no_grad()\n    def S_preprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n\n                    s = l.M_hat[:2 * l.dynamic_rank, :l.dynamic_rank]@l.S_hat[: l.dynamic_rank, :l.dynamic_rank]@l.N_hat[:2 * l.dynamic_rank, :l.dynamic_rank].T\n                    l.S_hat[:2*l.dynamic_rank,:2*l.dynamic_rank] = s\n\n                else:\n\n                    s = l.M_hat@l.S_hat@l.N_hat.T\n                    l.S_hat.data = s\n\n\n\n    @torch.no_grad()\n    def K_preprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n                \n                    K = l.U[:,:l.dynamic_rank]@l.S_hat[:l.dynamic_rank,:l.dynamic_rank]\n                    l.K[:,:l.dynamic_rank] = K\n\n                else:\n\n                    K = l.U.data@l.S_hat\n                    l.K.data = K\n\n\n\n    @torch.no_grad()\n    def L_preprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n\n                    L = l.V[:,:l.dynamic_rank]@l.S_hat[:l.dynamic_rank,:l.dynamic_rank].T\n                    l.L[:,:l.dynamic_rank] = L\n\n                else:\n\n                    L = l.V.data@l.S_hat.T\n                    l.L.data = L\n\n\n    @torch.no_grad()\n    def S_postprocess_step(self):\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                if not l.fixed:\n\n                    # rank adaption\n\n                    s_small = torch.clone(l.S_hat[:2 * l.dynamic_rank, :2 * l.dynamic_rank])\n                    try:\n                        u2, d, v2 = torch.linalg.svd(s_small)\n                    except Exception as e:\n                        print(e)\n                        print(s_small)\n                        u2, d, v2 = np.linalg.svd(s_small)\n\n                    tmp = 0.0\n                    tol = self.theta * torch.linalg.norm(d) if not self.absolute else self.theta \n                    rmax = int(np.floor(d.shape[0] / 2))\n                    for j in range(0, 2 * rmax - 1):\n                        tmp = torch.linalg.norm(d[j:2 * rmax - 1])\n                        if tmp < tol:\n                            rmax = j\n                            break\n\n                    rmax = min([rmax, l.rmax])\n                    rmax = max([rmax, 2])\n\n                    l.S_hat[:rmax,:rmax] = torch.diag(d[:rmax])\n                    l.U[:, :rmax] = l.U_hat[:, :2 * l.dynamic_rank]@u2[:, :rmax]\n                    l.V[:,:rmax] =  l.V_hat[:,:2 * l.dynamic_rank]@(v2[:, :rmax])\n                    l.dynamic_rank = int(rmax)\n\n    \n    @torch.no_grad()\n    def S_integration_step(self):\n\n        self.integrator.step()\n        self.integrator.zero_grad()\n    \n\n    @torch.no_grad()\n    def preprocess_step(self):\n\n        self.K_preprocess_step()\n        self.L_preprocess_step()\n\n    @torch.no_grad()\n    def step(self,closure = None):\n\n        \"\"\"\n        optimizer step for the dlrt.\n        INPUTS:\n        closure : function to compute the loss and backpropagate a second time (Pytorch standard)\n        \"\"\"\n\n        # self.K_integration_step()\n        # self.L_integration_step()\n        self.K_and_L_integration_step()\n        self.K_postprocess_step()\n        self.L_postprocess_step()\n        self.S_preprocess_step()\n        self.zero_grad()\n        if closure is not None:\n            with torch.set_grad_enabled(True):\n                loss = closure()\n                loss.backward()\n        self.S_integration_step()\n        self.S_postprocess_step()\n    \n    @torch.no_grad()\n    def zero_grad(self):\n        for p in self.NN.parameters():\n            if p.requires_grad:\n                p.grad = None\n\n\n    @torch.no_grad()\n    def activate_S_fine_tuning(self):\n\n        params = []\n\n        for l in self.NN.layer:\n\n            if hasattr(l,'lr') and l.lr:\n\n                l.K.requires_grad = False\n                l.L.requires_grad = False\n                l.S_hat = torch.nn.Parameter(l.S_hat[:l.dynamic_rank,:l.dynamic_rank])\n                l.fixed = True\n                l.U = torch.nn.Parameter(l.U[:,:l.dynamic_rank],requires_grad = False)\n                l.V = torch.nn.Parameter(l.V[:,:l.dynamic_rank],requires_grad = False)\n                l.step = 'S'\n                params.append(l.S_hat)\n        params = torch.nn.ParameterList(params)\n        self.integrator = self.KLS_optim(params,lr = self.tau,**self.kw)\n\n\n    @torch.no_grad()\n    def S_finetune_step(self):\n\n        self.integrator.step()",
    "Experiment Result": "Network Architecture:\n- LeNet5 model using custom low-rank convolutional (`Conv2d_lr`) and linear (`Linear`) layers.\n- Layer configuration (from `models_folder/Lenet5.py`):\n    - `Conv2d_lr(in_channels=1, out_channels=20, kernel_size=5, stride=1, rank=20)`\n    - `torch.nn.ReLU()`\n    - `torch.nn.MaxPool2d(kernel_size=2, stride=2)`\n    - `Conv2d_lr(in_channels=20, out_channels=50, kernel_size=5, stride=1, rank=50)`\n    - `torch.nn.ReLU()`\n    - `torch.nn.MaxPool2d(kernel_size=2, stride=2)`\n    - `torch.nn.Flatten()`\n    - `Linear(800, out_features=500, rank=500)`\n    - `torch.nn.ReLU()`\n    - `Linear(500, out_features=10)` (This last layer is a standard linear layer as `rank` is `None`)\n- All specified low-rank layers use adaptive rank (`fixed=False` is default in custom layers when `rank` is provided).\n\nDataset:\n- MNIST dataset.\n- Data split: 60,000 samples for training (further split into 50,000 for training and 10,000 for validation) and 10,000 for testing.\n- Image preprocessing: Reshaped to (1, 28, 28) and normalized by dividing by 255.\n\nOptimizer:\n- `dlr_opt` (Dynamical Low Rank Optimizer) is used.\n- Internal KLS optimizer: `torch.optim.SGD`.\n- Learning rate (`tau`): 0.05 (default from `run_lenet_mnist.py`).\n- Rank adaptation threshold (`theta`): Explored values include 0.4 and 0.45 (from `run_lenet_mnist.py`). A default of 0.08 is also mentioned in `dlrt_factorization_run.py`.\n- Rank initialization:\n    - For adaptive rank layers, `U` and `V` factors are initialized as random orthonormal matrices.\n    - `S_hat` is initialized as a diagonal matrix from absolute random normal values.\n    - For fixed rank layers (if used), `S_hat` values are modified by a decay factor of `1/(decay)**k`.\n- Basis orthogonalization: `torch.linalg.qr` (with `numpy.linalg.qr` as a fallback) is used for orthonormal basis computation during the `K_postprocess_step` and `L_postprocess_step`.\n- Singular value truncation: `torch.linalg.svd` (with `numpy.linalg.svd` as a fallback) is used in `S_postprocess_step` for rank adaptation. The dynamic rank is adjusted based on the `theta` threshold, ensuring a minimum rank of 2.\n\nTraining:\n- Epochs: 20.\n- Batch Size: 128.\n- Cross-validation runs: 5.\n- Loss function: `torch.nn.CrossEntropyLoss`.\n- Gradient computation: Gradients are computed with respect to the low-rank factors (`K`, `L`, `S_hat`) via multiple forward and backward passes (`populate_gradients` method with 'K', 'L', and 'S' steps) orchestrated by the `dlr_opt.step` method.\n\nComputational Details:\n- Device: CUDA is used if available, otherwise CPU.\n- Convolutional layer reshaping: Filters are implicitly reshaped into matrices using `F.unfold` within the `Conv2d_lr` forward pass to enable low-rank decomposition."
}{
    "Title": "Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation",
    "Main Contributions": "The paper demonstrates that leveraging inherent low-dimensional data structures and compressible dynamics within model parameters allows for enjoying the benefits of overparameterization without its computational burdens. Theoretically, it proves that learning dynamics in deep overparameterized low-rank matrix recovery are confined to invariant low-dimensional subspaces, enabling the construction and training of compact, compressed factorizations. Practically, the work develops efficient compression methods for overparameterized factorizations, improving efficiency for deep low-rank matrix completion and introducing \"Deep LoRA\" for language model fine-tuning. Deep LoRA reduces overfitting, simplifies hyperparameter setup, and maintains efficiency, particularly with limited data, by finding lower-rank solutions and being robust to rank choice.",
    "Methodology": "The approach is grounded in theoretical findings for deep matrix factorization, where the existence of invariant low-dimensional subspaces for each weight matrix during gradient descent is rigorously proven. This allows for the construction and training of compact factorizations. For deep matrix completion, the method is generalized by continuously, albeit slowly, updating the compressed subspaces (UL,1, V1,1) during training using a small, discrepant learning rate (γ). For language model fine-tuning, the paper proposes \"Deep LoRA,\" which employs a deep (three-layer) overparameterized factorization for the trainable update (∆Wk) for each pretrained weight, applying the aforementioned compression technique to the learning dynamics of individual weights. The initial factors for compression are derived by analyzing the None spaces of initial gradients.",
    "Experimental Setup": "For deep matrix factorization, the setup involved L-layer overparameterized factorizations with a squared Frobenius norm loss, scaled orthogonal initialization, and gradient descent. Simulations visualized SVD dynamics (L=3, d=30, r*=3, ϵl=1) and compared original vs. compressed trajectories (L=3, d=1000, r=r*=5, ϵl=10^-3). For deep matrix completion, the problem was defined with a masked Frobenius norm loss, comparing original and compressed methods with varying discrepant update rates for UL,1, V1,1 (γ=0.01 or γ=0), using L=3, d=1000, r=r*=5, ϵl=10^-3, and 20% observed entries. For model fine-tuning with Deep LoRA, a pretrained BERT base model and T5 base model (for NLG) from HuggingFace were used, adapting all 72 attention and feedforward weights. Both vanilla LoRA and Deep LoRA were tested with r=8 (unless specified), L=3 for Deep LoRA, optimized with Adam, and specific learning rates (Vanilla LoRA: η=10^-4, α=8; Deep LoRA: η=10^-2, γ=10^-2). Evaluation was performed on the GLUE benchmark and STS-B for NLU (with 1024, 16, 64, 256 samples) and the E2E dataset for NLG (16 samples), across multiple trials with different seeds, using metrics like performance gap, Pearson correlation, BLEU, ROUGE, and METEOR. All experiments were conducted on a single NVIDIA Tesla V100 GPU.",
    "Limitations": "The theoretical results on network compression primarily exploit the specific gradient structure of deep matrix factorizations, implying that direct generalization to fully non-linear settings is a current challenge. Initial direct application of the compression method to deep matrix completion did not work well, as the compressed subspaces computed at initialization could be misaligned due to perturbation by the observation mask, necessitating the introduction of slow updates for the subspaces during training.",
    "Future Research Directions": "Future work includes extending the analysis of compressibility to non-linear settings (e.g., ReLU activated networks) by identifying low-dimensional subspaces for similar dynamics. For Deep LoRA, potential extensions involve evaluating its efficacy in other modalities like diffusion models (especially with limited data), exploring the use of SGD for outer factors to reduce memory costs given high initial subspace alignment, and investigating second-order methods to accelerate fine-tuning along the rank-r subspace. Additionally, the research suggests exploring implications for representation learning, connecting low-rank bias to phenomena such as deep neural collapse and progressive neural collapse.",
    "Experiment Code": "from dataclasses import dataclass, field\nfrom enum import StrEnum\nfrom typing import Optional, Tuple, Union\n\nfrom dataclasses_json import dataclass_json\n\n\nclass ExtendedEnum(StrEnum):\n\n    @classmethod\n    def values(cls):\n        return [e.value for e in cls]\n\n\nclass LoraAdaptType(ExtendedEnum):\n    ONLY_QUERY_VALUE = \"only-query-value\"\n    ATTENTION_MLP = \"attention-mlp\"\n    ALL_DENSE = \"all-dense\"\n\n\n@dataclass_json\n@dataclass\nclass TaskConfig:\n    # Lora hparams\n    lora_adapt_type: LoraAdaptType = LoraAdaptType.ONLY_QUERY_VALUE\n    lora_depth: int = 3\n    lora_init_scale: float = 1e-3\n    lora_rank: Optional[int] = None\n    lora_compress: bool = False\n    lora_gamma: float = 0\n\n\nimport flax.linen as nn\nimport jax.numpy as jnp\nfrom chex import ArrayTree\n\nfrom . import misc_utils, model_utils\n\n\nclass MatrixFactorization(nn.Module):\n    shape: Tuple[int, int]\n    init_scale: float\n    depth: int\n    rank: Optional[int]\n\n    def setup(self):\n        assert self.depth >= 2, \"Depth must be at least 2\"\n        set_width = self.rank if self.rank else max(self.shape)\n        misc_utils.check_rank(set_width, self.shape)\n\n        if self.depth == 2:\n            init_fn = nn.initializers.normal(stddev=1)\n            last_init_fn = nn.zeros_init()\n        else:\n            init_fn = nn.initializers.orthogonal(scale=self.init_scale)\n            last_init_fn = init_fn\n\n        layers = []\n        layers.append(\n            self.param(\n                \"W1\",\n                init_fn,\n                (set_width, self.shape[1]),\n            )\n        )\n        for i in range(2, self.depth):\n            layers.append(\n                self.param(\n                    f\"W{i}\",\n                    init_fn,\n                    (set_width, set_width),\n                )\n            )\n        layers.append(\n            self.param(\n                f\"W{self.depth}\",\n                last_init_fn,\n                (self.shape[0], set_width),\n            )\n        )\n        self.layers = layers\n\n    def __call__(self):\n        return jnp.linalg.multi_dot(self.layers[::-1])\n\n\nclass CompressedMatrixFactorization(nn.Module):\n    shape: Tuple[int, int]\n    init_scale: float\n    depth: int\n    rank: int\n\n    def setup(self):\n        self.left_factor = self.param(\n            \"left\", nn.initializers.orthogonal(), (self.shape[0], self.rank)\n        )\n        self.right_factor = self.param(\n            \"right\", nn.initializers.orthogonal(), (self.shape[1], self.rank)\n        )\n        self.mf = MatrixFactorization(\n            (self.rank, self.rank), self.init_scale, self.depth, None\n        )\n\n    def __call__(self):\n        return jnp.linalg.multi_dot([self.left_factor, self.mf(), self.right_factor.T])\n\n\nclass Lora(nn.Module):\n    flat_params_shape_dict: dict\n    init_scale: float\n    depth: int\n    rank: Optional[int]\n    compressed: bool\n\n    def setup(self):\n        mfs = {}\n        for flat_param_path, shape in self.flat_params_shape_dict.items():\n            if self.compressed:\n                assert (\n                    self.rank is not None\n                ), \"Rank must be specified for compressed LoRA\"\n                mf = CompressedMatrixFactorization(\n                    shape=shape,\n                    init_scale=self.init_scale,\n                    depth=self.depth,\n                    rank=self.rank,\n                    name=flat_param_path,\n                )\n                assert self.depth >= 3, \"Depth must be at least 3 for compressed LoRA\"\n            else:\n                mf = MatrixFactorization(\n                    shape=shape,\n                    init_scale=self.init_scale,\n                    depth=self.depth,\n                    rank=self.rank,\n                    name=flat_param_path,\n                )\n            mfs[flat_param_path] = mf\n        self.mfs = mfs\n\n    def __call__(self):\n        return {k: v() for k, v in self.mfs.items()}\n\n    def adapt(self, model_params: ArrayTree) -> ArrayTree:\n        updates = self()\n\n        def f(k, v):\n            flat_k = \"/\".join(k)\n            if flat_k in updates.keys():\n                return v + updates[flat_k]\n            else:\n                return v\n\n        return flax.traverse_util.path_aware_map(\n            f,\n            model_params,\n        )\n\n\ndef create_lora_model_from_config(\n    task_config: TaskConfig, model_params: ArrayTree\n) -> Lora:\n    \"Creates LoRA model from task config and pretrain model parameters.\"\n\n    filtered_flat_model_params_shape_dict = (\n        model_utils.get_filtered_flat_params_shape_dict(\n            model_params,\n            task_config.lora_adapt_type,\n        )\n    )\n\n    lora_model = Lora(\n        flat_params_shape_dict=filtered_flat_model_params_shape_dict,\n        depth=task_config.lora_depth,\n        init_scale=task_config.lora_init_scale,\n        rank=task_config.lora_rank if not task_config.lora_compress else None,\n        compressed=False,\n    )\n\n    return lora_model\n\n\nfrom functools import partial\n\nimport jax\nimport jax.numpy as jnp\nimport numpy as np\nimport optax\nfrom chex import ArrayTree\nfrom flax.training.train_state import TrainState\nfrom jax import Array\nfrom optax import Schedule\n\nfrom . import metrics, model_utils, models\nfrom .configs import TaskConfig\nfrom .models import Lora\n\n\nclass LoraState(TrainState):\n    dropout_rng: Array\n\n\ndef create_lora_loss_fn(\n    model_state: TrainState,\n    lora_state: LoraState,\n    is_regression: bool,\n    is_train: bool,\n) -> Callable:\n    \"Returns function that computes loss for model/lora state.\"\n\n    def loss_fn(lora_params: ArrayTree, batch: dict[str, np.ndarray]) -> Array:\n        labels = batch.pop(\"labels\")\n        adapted_model_params = lora_state.apply_fn(\n            {\"params\": lora_params}, model_state.params\n        )\n        logits = model_state.apply_fn(\n            **batch,\n            params=adapted_model_params,\n            dropout_rng=lora_state.dropout_rng,\n            train=is_train,\n        )[0]\n        if is_regression:\n            loss = metrics.mse_loss(logits, labels)\n        else:\n            if \"decoder_attention_mask\" in batch:\n                loss = metrics.ce_loss(\n                    logits, labels, padding=batch[\"decoder_attention_mask\"]\n                )\n            else:\n                loss = metrics.ce_loss(logits, labels)\n        return loss\n\n    return loss_fn\n\n\ndef create_train_step_fn(\n    task_config: TaskConfig, learning_rate_fn: optax.Schedule\n) -> Callable:\n\n    is_regression = task_config.finetune_task_name == \"stsb\"\n\n    @partial(jax.jit, donate_argnums=(1,))\n    def train_step_fn(\n        model_state: TrainState, lora_state: LoraState, batch: dict[str, np.ndarray]\n    ) -> tuple[LoraState, dict[str, Array]]:\n        _, new_dropout_rng = jax.random.split(lora_state.dropout_rng)\n        loss_and_grad_fn = jax.value_and_grad(\n            create_lora_loss_fn(model_state, lora_state, is_regression, is_train=True)\n        )\n        loss, grads = loss_and_grad_fn(lora_state.params, batch)\n        new_lora_state = lora_state.apply_gradients(grads=grads)\n        new_lora_state = new_lora_state.replace(dropout_rng=new_dropout_rng)\n        metrics = {\"loss\": loss, \"learning_rate\": learning_rate_fn(lora_state.step)}\n        return new_lora_state, metrics\n\n    return train_step_fn\n\n\ndef create_lora_state(\n    task_config: TaskConfig,\n    model_params: ArrayTree,\n    learning_rate_fn: Schedule,\n    lora_rng: Array,\n    dropout_rng: Array,\n) -> tuple[LoraState, Lora]:\n    lora_model = models.create_lora_model_from_config(task_config, model_params)\n    lora_variables = lora_model.init(lora_rng)\n    lora_params = lora_variables[\"params\"]\n    tx = create_optimizer(learning_rate_fn, task_config.weight_decay)\n    return (\n        LoraState.create(\n            apply_fn=partial(lora_model.apply, method=lora_model.adapt),\n            params=lora_params,\n            tx=tx,\n            dropout_rng=dropout_rng,\n        ),\n        lora_model,\n    )\n\n\ndef create_compressed_lora_train_state(\n    uncompressed_lora_state: LoraState,\n    uncompressed_lora_model: Lora,\n    model_state: TrainState,\n    batch: dict[str, np.ndarray],\n    task_config: TaskConfig,\n):\n    assert task_config.lora_compress, \"Lora compression is not enabled.\"\n    rank = task_config.lora_rank\n    assert rank is not None, \"Rank must be specified.\"\n    assert rank % 2 == 0, \"Rank must be even.\"\n    compressed_lora_model = models.Lora(\n        flat_params_shape_dict=model_utils.get_filtered_flat_params_shape_dict(\n            model_state.params, task_config.lora_adapt_type\n        ),\n        depth=task_config.lora_depth,\n        init_scale=task_config.lora_init_scale,\n        rank=rank,\n        compressed=True,\n    )\n\n    uncompressed_e2e = uncompressed_lora_model.apply(\n        {\"params\": uncompressed_lora_state.params}\n    )\n\n    # Get gradient of uncompressed factors\n    loss_fn = create_lora_loss_fn(\n        model_state,\n        uncompressed_lora_state,\n        task_config.finetune_task_name == \"stsb\",\n        False,\n    )\n\n    uncompressed_grads = jax.grad(loss_fn)(uncompressed_lora_state.params, batch)\n\n    # Move to numpy (do compression on CPU to save GPU memory)\n    uncompressed_lora_params_numpy = jax.tree_map(\n        np.array, uncompressed_lora_state.params\n    )\n    uncompressed_grads_numpy = jax.tree_map(np.array, uncompressed_grads)\n    uncompressed_e2e_numpy = jax.tree_map(np.array, uncompressed_e2e)\n\n    def svd(A):\n        U, s, VT = np.linalg.svd(A, full_matrices=True)\n        return U, s, VT.T\n\n    def get_left_right_factors(W1, W1_grad, e2e):\n\n        m, n = W1.shape\n        assert m == n, \"Need square matrix at this point\"\n\n        half_rank = rank // 2\n        Ugrad, _, Vgrad = svd(W1_grad)\n        Va = W1.T @ Ugrad[:, half_rank:] / task_config.lora_init_scale\n        Vb = Vgrad[:, half_rank:]\n        V0 = Va @ svd(np.concatenate([Va, -Vb], axis=1))[2][: Va.shape[1], n:]\n        V = svd(V0)[0][:, ::-1]\n        right = V[:, :rank]\n        left = e2e @ right / (task_config.lora_init_scale**task_config.lora_depth)\n\n        return left, right\n\n    compressed_lora_params_numpy = {}\n\n    pbar = tqdm(uncompressed_grads_numpy.items())\n    pbar.set_description(\"Compressing LoRA parameters\")\n\n    for k, g in pbar:\n        comp_mf_params = {}\n        m, n = uncompressed_lora_params_numpy[k][\"W1\"].shape\n        if m != n:\n            # WL.T will act like W1\n            right, left = get_left_right_factors(\n                uncompressed_lora_params_numpy[k][f\"W{task_config.lora_depth}\"].T,\n                g[f\"W{task_config.lora_depth}\"].T,\n                uncompressed_e2e_numpy[k].T,\n            )\n        else:\n            left, right = get_left_right_factors(\n                uncompressed_lora_params_numpy[k][\"W1\"],\n                g[\"W1\"],\n                uncompressed_e2e_numpy[k],\n            )\n        comp_mf_params[\"left\"] = left\n        comp_mf_params[\"right\"] = right\n        mf_params = {}\n        for w in g.keys():\n            mf_params[w] = task_config.lora_init_scale * jnp.eye(rank)\n        comp_mf_params[\"mf\"] = mf_params\n        compressed_lora_params_numpy[k] = comp_mf_params\n\n    compressed_lora_params = jax.tree_map(jnp.array, compressed_lora_params_numpy)\n\n    inner_tx = uncompressed_lora_state.tx\n    outer_tx = create_optimizer(\n        create_learning_rate_fn(\n            task_config.num_train_steps,\n            task_config.num_warmup_steps,\n            task_config.lora_gamma * task_config.learning_rate,\n            task_config.decay_ratio,\n        ),\n        task_config.weight_decay,\n    )\n    tx = optax.multi_transform(\n        {\"inner\": inner_tx, \"outer\": outer_tx},\n        flax.traverse_util.path_aware_map(\n            lambda p, _: \"outer\" if p[-1] == \"left\" or p[-1] == \"right\" else \"inner\",\n            compressed_lora_params,\n        ),\n    )\n\n    return LoraState.create(\n        apply_fn=partial(\n            compressed_lora_model.apply, method=compressed_lora_model.adapt\n        ),\n        params=compressed_lora_params,\n        tx=tx,\n        dropout_rng=uncompressed_lora_state.dropout_rng,\n    )",
    "Experiment Result": "The Deep LoRA method is configured through the `TaskConfig` dataclass in `dlt/configs.py`. Key experimental settings related to the method are:\n\n-   `lora_depth`: Integer specifying the number of layers in the overparameterized factorization for the trainable update. The method proposes a \"deep (three-layer)\" factorization, so `lora_depth` is typically set to `3` in experiments comparing against standard LoRA (which often uses `depth=2`).\n-   `lora_rank`: Optional integer defining the rank of the factorization. When `lora_compress` is `True`, `lora_rank` must be specified. Typical values observed in experiments include `8`, `16`, `32`, `64`.\n-   `lora_init_scale`: Floating-point value for the initialization scale of the LoRA factors, usually `1e-3`.\n-   `lora_adapt_type`: Enum `LoraAdaptType` (`ONLY_QUERY_VALUE`, `ATTENTION_MLP`, `ALL_DENSE`) determines which weight matrices in the pretrained model are adapted by LoRA. `ALL_DENSE` is frequently used in the provided scripts.\n-   `lora_compress`: Boolean flag (`True`/`False`) to enable the compression technique for the LoRA factors. When `True`, `CompressedMatrixFactorization` is used, and the system updates compressed subspaces.\n-   `lora_gamma`: Floating-point value representing the small, discrepant learning rate (γ) used to continuously update the `left` and `right` compressed subspaces (`UL,1`, `V1,1`) during training. When `lora_compress` is `True`, this rate is multiplied by the base `learning_rate` for the outer optimization loop. Observed values include `1` (which means `gamma * learning_rate` is `learning_rate`) and `1e-2`. A default value of `0` means these factors are not updated with a separate learning rate.\n-   `learning_rate`: Base learning rate for the inner optimization loop, typically `1e-4`."
}{
    "Title": "Black-Box Tuning for Language-Model-as-a-Service",
    "Main Contributions": "This paper proposes Black-Box Tuning (BBT), a novel framework to optimize continuous prompts for Language-Model-as-a-Service (LMaaS) scenarios where gradients of large pre-trained language models (PTMs) are unavailable. It introduces a derivative-free optimization approach that operates in a randomly projected low-dimensional subspace, leveraging the low intrinsic dimensionality of large PTMs. The experimental results demonstrate that BBT, using RoBERTaLARGE with few-shot labeled samples, significantly outperforms manual prompting, GPT-3's in-context learning, and even gradient-based methods like prompt tuning and full model tuning on various language understanding tasks. This work pioneers the optimization of large-scale PTMs via derivative-free methods for user-side prompt tuning on resource-limited devices.",
    "Methodology": "The methodology addresses the challenge of optimizing continuous prompts in high-dimensional spaces without gradient access. It formulates common language understanding tasks as classification, mapping inputs and labels to PTM-compatible formats. To overcome the intractability of high-dimensional derivative-free optimization, BBT projects the original prompt space (p ∈ RD) onto a much smaller subspace (z ∈ Rd, d≪D) using a random linear projection matrix A ∈ RD×d. The optimization is performed on z in this low-dimensional subspace. The objective function minimizes a loss L (cross entropy or hinge loss) over predictions from the black-box PTM inference API f(Az + p0; ˜X), where p0 is an initial prompt embedding. The random matrix A is initialized by sampling from a uniform distribution. The Covariance Matrix Adaptation Evolution Strategy (CMA-ES), a derivative-free optimizer, is employed to update the prompt embeddings. For sentence-pair tasks, p0 can be pre-trained on NLI datasets (e.g., MNLI); otherwise, it's initialized with random word embeddings from the PTM's vocabulary.",
    "Experimental Setup": "Experiments were conducted on 7 common language understanding tasks: sentiment analysis (SST-2, Yelp Polarity), topic classification (AG’s News, DBPedia), natural language inference (SNLI, RTE), and paraphrase (MRPC). RoBERTaLARGE was chosen as the backbone PTM. A few-shot learning setting (16-shot per class) was used, with development and test sets constructed from original datasets. BBT was compared against gradient-based baselines (Prompt Tuning, P-Tuning v2, Model Tuning) and gradient-free baselines (Manual Prompt, In-context Learning, Feature-based methods like Feature-MLP and Feature-BiLSTM). Default hyperparameters for BBT included a prompt length of 50, subspace dimension of 500, population size of 20, uniform random projection, cross entropy loss, and an API call budget of 8000. Ablation studies were performed on loss functions, subspace dimensionality, prompt length, random projection type, and population size, typically in a 64-shot setting to reduce variance, with some 16-shot results also provided. All methods were implemented in PyTorch on a single NVIDIA GTX 3090 GPU, with training time measured with and without ONNX Runtime acceleration.",
    "Limitations": "The intrinsic dimensionality of PTMs is approximate in real-world scenarios, potentially leading to sub-optimal performance in the randomly generated subspace. The current approach uses hand-crafted templates and label words, which might not be optimal, suggesting the reported performance is a lower bound. The study focuses primarily on language understanding tasks with RoBERTaLARGE, leaving the application to generative PTMs (e.g., GPT, T5, BART) for future work. While CMA-ES generally performs well, Adam with an appropriate learning rate can achieve comparable results in larger low-dimensional subspaces (e.g., d=1000), implying CMA-ES is not universally superior in all subspace settings.",
    "Future Research Directions": "Future work includes exploring more advanced methods for constructing the random projection matrix, such as sequential random embedding and other cutting-edge techniques, to better account for the ϵ-effective dimensionality of PTMs. Training the projection matrix 'A' with multi-task supervision to discover better and smaller subspaces is another promising direction. Applying the framework to larger PTMs (which typically exhibit lower intrinsic dimensionalities) to enable the use of even smaller subspaces and more efficient DFO algorithms like Bayesian optimization is suggested. Integrating advanced prompt-based learning techniques, such as prompt engineering, label words engineering, more extensive prompt pre-training, and prompt ensembling, is expected to further enhance performance. Finally, extending the framework to generative PTMs by converting downstream tasks into a unified text-to-text format is also a key future direction.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Black-Box Tuning for Language-Model-as-a-Service",
    "Main Contributions": "This paper proposes Black-Box Tuning (BBT), a novel framework to optimize continuous prompts for Language-Model-as-a-Service (LMaaS) scenarios where gradients of large pre-trained language models (PTMs) are unavailable. The key contribution is enabling task-specific prompt optimization by only accessing PTM inference APIs. BBT achieves this by performing derivative-free optimization (DFO) in a randomly generated low-dimensional subspace, leveraging the low intrinsic dimensionality of large PTMs. Empirical results demonstrate that BBT significantly outperforms manual prompt, GPT-3's in-context learning, and even gradient-based methods like prompt tuning and full model tuning on various language understanding tasks in a few-shot setting.",
    "Methodology": "The methodology addresses the optimization of continuous prompts (p) for a black-box PTM inference API (f) using derivative-free optimization. To overcome the high dimensionality of continuous prompts, BBT projects the original high-dimensional prompt space (D-dimensional) onto a much smaller subspace (d-dimensional) using a random linear projection matrix (A). Optimization is then performed on a low-dimensional vector (z) in this subspace, where the final prompt is derived as Az + p0 (p0 being an initial prompt embedding). The values of the random matrix A are sampled from a uniform distribution. The CMA-ES (Covariance Matrix Adaptation Evolution Strategy), a widely used evolutionary algorithm, is employed for the derivative-free optimization in this continuous, non-convex, low-dimensional space. Loss functions considered include Cross Entropy, Hinge Loss, and Negative Accuracy, with Cross Entropy performing slightly better. For initialization, prompt embeddings p0 can be pre-trained on publicly available NLI tasks for sentence-pair tasks, or randomly drawn from the PTM's vocabulary for other tasks.",
    "Experimental Setup": "Experiments were conducted on RoBERTaLARGE as the backbone model, due to its suitability for language understanding tasks and proven small intrinsic dimensionality. Seven common language understanding datasets were used, including SST-2, Yelp polarity (sentiment analysis), AG’s News, DBPedia (topic classification), SNLI, RTE (NLI), and MRPC (paraphrase). A few-shot setting (16-shot per class for main results, 64-shot for ablations) was employed, constructing training and development sets of k samples per class, and using original development/test sets as test sets. Baselines included gradient-based methods (Prompt Tuning, P-Tuning v2, Model Tuning) and gradient-free methods (Manual Prompt, In-context Learning, Feature-based methods like Feature-MLP and Feature-BiLSTM). Hyper-parameters for BBT were set with a default prompt length of 50, subspace dimension of 500, population size of 20, uniform random projection, Cross Entropy loss, and a budget of 8000 API calls. Performance was measured by mean and standard deviation of accuracy or F1-score over 3 different data splits. All methods were implemented with PyTorch and run on a single NVIDIA GTX 3090 GPU, with some training times measured with ONNX Runtime.",
    "Limitations": "The intrinsic dimension can be approximate, and the subspace generated by random projection might be sub-optimal. The current work uses hand-crafted templates and label words, suggesting that the reported performance represents a lower bound, and more sophisticated prompt engineering could yield further improvements. Although CMA-ES, a derivative-free optimizer, tends to find better solutions due to its exploration mechanism compared to Adam on small training data, Adam shows faster convergence on the training set. The study focuses solely on language understanding tasks, not generative PTMs.",
    "Future Research Directions": "Future research can explore more suitable derivative-free optimization approaches, such as sequential random embedding, or advanced methods for constructing the random projection matrix (e.g., training the projection matrix with multi-task supervision). Applying Black-Box Tuning to generative PTMs (like GPT, T5, or BART) by converting downstream tasks into a unified text-to-text format is another promising direction. Furthermore, integrating advanced techniques like prompt engineering, label words engineering, prompt pre-training, and prompt ensembling with BBT could significantly enhance performance. Investigation into using even smaller subspaces and more efficient DFO algorithms like Bayesian optimization for larger PTMs is also suggested, leveraging their generally lower intrinsic dimensionalities.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models",
    "Main Contributions": "This research addresses the challenge of transferring continuous prompts between different language models in a zero-shot setting, aiming to avoid expensive gradient computations on large models. The main contributions include proposing a novel zero-shot continuous prompt transfer method that encodes source prompts into a relative space and searches for corresponding target prompts. Key findings confirm that 'task semantics' in continuous prompts can be generalized across various language models. Moreover, the study demonstrates that combining 'task semantics' from multiple source models can further enhance transfer performance. The approach facilitates multi-source transfer, unlike previous methods.",
    "Methodology": "The methodology involves an 'encode-then-search' strategy. First, continuous prompt tuning optimizes virtual token embeddings for a downstream task. To transfer, source prompt embeddings are encoded into a relative representation using a set of common tokens (anchors) shared between source and target models. This encoding is based on cosine similarity between prompt embeddings and anchor embeddings. Second, in the target space, target prompt embeddings are randomly initialized and then searched by maximizing the cosine similarity between their relative representations and those of the source prompts, using gradient descent. The searched target embeddings are subsequently normalized based on the mean and standard deviation of the target model's word embeddings. For multi-source transfer, the objective is extended to maximize the sum of similarities between the target relative embedding and the relative embeddings from multiple source models.",
    "Experimental Setup": "The method was evaluated on the LAMA (Petroni et al., 2019) factual probing dataset, specifically the TREx split, which contains 41 distinct relations as sub-tasks. OptiPrompt (Zhong et al., 2021) was used to induce continuous prompts on source language models. Experiments utilized various BERT, RoBERTa, and ALBERT models (base and large variants) as source and target models. GPT-2 models (small, medium, large) were also included in an additional cross-architecture transfer study. The default prompt length was set to 5 virtual tokens, and 8192 anchors (common tokens) were used. The evaluation metric was micro-average accuracy across all 41 sub-tasks. Baselines included direct transfer, random prompts, manual prompts, direct tuning (as an upper bound), discretization, and a neural projector.",
    "Limitations": "A notable limitation is that larger source models (e.g., BERTlarge, RoBERTalarge) exhibited lower transfer performance. This is attributed to the potential for model-specific information in their highly expressive embedding spaces, which limits generalizability beyond task semantics. Additionally, GPT-2 models, when used as source models, did not consistently induce meaningful prompts and often underperformed manual prompting, with the underlying reasons remaining unexplored. The cosine similarity measure used in encoding is insensitive to vector magnitude, necessitating a subsequent normalization step for target embeddings. Using the entire shared vocabulary as anchors was found to marginally decrease performance, likely due to noise from poorly trained rare word embeddings.",
    "Future Research Directions": "Future research could explore the reasons behind the poor transferability of continuous prompts induced on GPT-2 (decoder-only) models when used as sources. A promising direction is to investigate direct human-model interactions that bypass discrete language, potentially by prompting pretrained language models using continuous prompts transferred from sources like encoded brain signals (e.g., from Zou et al., 2021).",
    "Experiment Code": "File Path: rel2abs_util.py\nContent:\nfrom transformers import AutoConfig\nfrom transformers import RobertaTokenizer, RobertaModel, RobertaConfig\nfrom transformers import BertTokenizer, BertModel, BertConfig\nfrom transformers import AlbertConfig, AlbertTokenizer, AlbertModel\nfrom transformers import GPT2Config, GPT2Model, GPT2Tokenizer\nfrom transformers import BartConfig, BartTokenizer, BartModel\nfrom transformers import T5Config, T5Tokenizer, T5Model\nimport numpy as np\n\ndef get_model_tokenizer(model_name):\n    config = AutoConfig.from_pretrained(model_name)\n    if isinstance(config, RobertaConfig):\n        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n        base_model = RobertaModel.from_pretrained(model_name)\n        model_family = 'roberta'\n    elif isinstance(config, BertConfig):\n        tokenizer = BertTokenizer.from_pretrained(model_name)\n        base_model = BertModel.from_pretrained(model_name)\n        model_family = 'bert'\n    elif isinstance(config, AlbertConfig):\n        tokenizer = AlbertTokenizer.from_pretrained(model_name)\n        base_model = AlbertModel.from_pretrained(model_name)\n        model_family = 'albert'\n    elif isinstance(config, GPT2Config):\n        tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n        base_model = GPT2Model.from_pretrained(model_name)\n        model_family = 'gpt2'\n    elif isinstance(config, BartConfig):\n        tokenizer = BartTokenizer.from_pretrained(model_name)\n        base_model = BartModel.from_pretrained(model_name)\n        model_family = 'bart'\n    elif isinstance(config, T5Config):\n        tokenizer = T5Tokenizer.from_pretrained(model_name)\n        base_model = T5Model.from_pretrained(model_name)\n        model_family = 'T5'\n    else:\n        raise ValueError('Model %s not supported yet!'%(model_name))\n    \n    return tokenizer, base_model, model_family\n\ndef build_vocab(tokenizer):\n    vocab = list(tokenizer.get_vocab())\n    inverse_vocab = {w: i for i, w in enumerate(vocab)}\n    return vocab, inverse_vocab\n\ndef select_random_samples(matrix, indices):\n    k = matrix.shape[1]\n    m = indices.shape[0]\n    selected_embeddings = np.empty((m, k))\n    \n    for i, idx in enumerate(indices):\n        selected_embeddings[i] = matrix[idx]\n    \n    return selected_embeddings\n\ndef vocab_cleaning(vocab):\n    vocab = [token.replace(\"Ġ\", \"\") for token in vocab] # for roberta\n    vocab = [token.replace(\" \", \"\") for token in vocab] # for albert\n    return vocab\n\ndef get_abs_anchors(model_name1, model_name2, num_anchor, common_vocab, seed, all_anchors, model_name3=None):\n    bert_tokenizer, bert_base_model, model_family1 = get_model_tokenizer(model_name1)\n    roberta_tokenizer, roberta_base_model, model_family2 = get_model_tokenizer(model_name2)\n    if model_name3 != None:\n        model_tokenizer3, model3, model_family3 = get_model_tokenizer(model_name3)\n\n    bert_UNK = bert_tokenizer.unk_token\n    roberta_UNK = roberta_tokenizer.unk_token\n    if model_name3 != None:\n        model3_UNK = model_tokenizer3.unk_token\n\n    if model_family1 in ['gpt2']:\n        bert_base_embeddings = bert_base_model.wte.weight.detach().cpu()\n    elif model_family1 in ['bart', 'T5']:\n        bert_base_embeddings = bert_base_model.shared.weight.detach().cpu()\n    else:\n        bert_base_embeddings = bert_base_model.embeddings.word_embeddings.weight.detach().cpu()\n\n    if model_family2 in ['gpt2']:\n        roberta_base_embeddings = roberta_base_model.wte.weight.detach().cpu()\n    elif model_family2 in ['bart', 'T5']:\n        roberta_base_embeddings = roberta_base_model.shared.weight.detach().cpu()\n    else:\n        roberta_base_embeddings = roberta_base_model.embeddings.word_embeddings.weight.detach().cpu()\n    \n    if model_name3 != None:\n        if model_family3 in ['gpt2']:\n            model3_embeddings = model3.wte.weight.detach().cpu()\n        elif model_family3 in ['bart', 'T5']:\n            model3_embeddings = model3.shared.weight.detach().cpu()\n        else:\n            model3_embeddings = model3.embeddings.word_embeddings.weight.detach().cpu()\n\n    if common_vocab != None:\n        with open(common_vocab, 'r') as f:\n            lines = f.readlines()\n            filtered_vocab = [x.strip() for x in lines]\n    else:\n        bert_vocab, _ = build_vocab(bert_tokenizer)\n        roberta_vocab, _ = build_vocab(roberta_tokenizer)\n\n        if model_name3 != None:\n            model_vocab3, _ = build_vocab(model_tokenizer3)\n\n\n        print('model 1 and 2 vocabs:', len(bert_vocab), len(roberta_vocab))\n        bert_vocab = vocab_cleaning(bert_vocab)\n        roberta_vocab = vocab_cleaning(roberta_vocab)\n\n        if model_name3 != None:\n            model_vocab3 = vocab_cleaning(model_vocab3)\n            filtered_vocab = list(set(bert_vocab) & set(roberta_vocab) & set(model_vocab3))\n        else:\n            filtered_vocab = list(set(bert_vocab) & set(roberta_vocab))\n\n    bert_filtered_indices = []\n    roberta_filtered_indices = []\n\n    if model_name3 != None:\n        model3_filtered_indices = []\n\n    # wf = open('aligned_vocab/%s_%s_aligned_vocab.txt' % (model_family1, model_family2), 'w')\n    for word in filtered_vocab:\n        # wf.write(word+'\\n')\n\n        bert_tokens = bert_tokenizer.tokenize(' ' + word)\n        if (len(bert_tokens) == 1) and (bert_tokens[0] != bert_UNK):\n            bert_index = bert_tokenizer.convert_tokens_to_ids(bert_tokens)[0]\n        else:\n            continue\n        \n        roberta_tokens = roberta_tokenizer.tokenize(' ' + word)\n        if (len(roberta_tokens) == 1) and (roberta_tokens[0] != roberta_UNK):\n            roberta_index = roberta_tokenizer.convert_tokens_to_ids(roberta_tokens)[0]\n        else:\n            continue\n        \n        if model_name3 != None:\n            model3_tokens = model_tokenizer3.tokenize(' ' + word)\n            if (len(model3_tokens) == 1) and (model3_tokens[0] != model3_UNK):\n                model3_index = model_tokenizer3.convert_tokens_to_ids(model3_tokens)[0]\n            else:\n                continue\n\n            model3_filtered_indices.append(model3_index)\n        \n        # wf.write('%s, %s\\n' % (bert_tokens[0], roberta_tokens[0]))\n        bert_filtered_indices.append(bert_index)\n        roberta_filtered_indices.append(roberta_index)\n            \n    assert len(bert_filtered_indices) == len(roberta_filtered_indices)\n    if model_name3 != None:\n        assert len(bert_filtered_indices) == len(model3_filtered_indices)\n\n    print('Number of filtered shared tokens %d' % len(bert_filtered_indices))\n\n    std = np.std(roberta_base_embeddings.reshape(-1).numpy())\n    mean = np.mean(roberta_base_embeddings.reshape(-1).numpy())\n\n    if all_anchors:\n        bert_base_embeddings = select_random_samples(bert_base_embeddings.numpy(), np.array(bert_filtered_indices))\n        roberta_base_embeddings = select_random_samples(roberta_base_embeddings.numpy(),np.array(roberta_filtered_indices))\n        if model_name3 != None:\n            model3_embeddings = select_random_samples(model3_embeddings.numpy(),np.array(model3_filtered_indices))\n        else:\n            model3_embeddings = None\n    else:\n        selected_indices = np.random.choice(list(range(0, len(bert_filtered_indices))), num_anchor, replace=False)\n        bert_base_embeddings = select_random_samples(bert_base_embeddings.numpy(), np.array([bert_filtered_indices[i] for i in selected_indices]))\n        roberta_base_embeddings = select_random_samples(roberta_base_embeddings.numpy(), np.array([roberta_filtered_indices[i] for i in selected_indices]))\n        if model_name3 != None:\n            model3_embeddings = select_random_samples(model3_embeddings.numpy(), np.array([model3_filtered_indices[i] for i in selected_indices]))\n        else:\n            model3_embeddings = None\n\n    return bert_base_embeddings, roberta_base_embeddings, (mean, std), model3_embeddings\n\nFile Path: evaluate.py\nContent:\nimport os\nimport torch\nfrom OptiPrompt.code.models import Prober\nfrom OptiPrompt.code.utils import evaluate, load_data, batchify, get_relation_meta, load_vocab\n\nMAX_NUM_VECTORS = 10\n\ndef get_new_token(vid):\n    assert(vid > 0 and vid <= MAX_NUM_VECTORS)\n    return '[V%d]'%(vid)\n\ndef convert_manual_to_dense(manual_template, model):\n    def assign_embedding(new_token, token):\n        \"\"\"\n        assign the embedding of token to new_token\n        \"\"\"\n        id_a = model.tokenizer.convert_tokens_to_ids([new_token])[0]\n        id_b = model.tokenizer.convert_tokens_to_ids([token])[0]\n        with torch.no_grad():\n            model.base_model.embeddings.word_embeddings.weight[id_a] = model.base_model.embeddings.word_embeddings.weight[id_b].detach().clone()\n\n    new_token_id = 0\n    template = []\n    for word in manual_template.split():\n        if word in ['[X]', '[Y]']:\n            template.append(word)\n        else:\n            tokens = model.tokenizer.tokenize(' ' + word)\n            for token in tokens:\n                new_token_id += 1\n                template.append(get_new_token(new_token_id))\n                assign_embedding(get_new_token(new_token_id), token)\n\n    return ' '.join(template)\n\ndef prepare_for_dense_prompt(model):\n    new_tokens = [get_new_token(i+1) for i in range(MAX_NUM_VECTORS)]\n    model.tokenizer.add_tokens(new_tokens)\n    model.mlm_model.resize_token_embeddings(len(model.tokenizer))\n\ndef init_template(args, model):\n    if args.init_manual_template:\n        relation = get_relation_meta(args)\n        template = convert_manual_to_dense(relation['template'], model)\n    else:\n        template = '[X] ' + ' '.join(['[V%d]'%(i+1) for i in range(args.num_vectors)]) + ' [Y] .'\n    return template\n\ndef load_optiprompt(model, original_vocab_size, vs):\n    # copy fine-tuned new_tokens to the pre-trained model\n    with torch.no_grad():\n        model.base_model.embeddings.word_embeddings.weight[original_vocab_size:] = torch.Tensor(vs)\n\n\nclass EvaluatePrompt:\n    def __init__(self, args):\n        args.model_name = args.tgt_model\n        args.model_dir = None\n        args.k = 5\n        args.eval_batch_size = 8\n\n        dev_data = os.path.join(args.data_path, args.relation, 'dev.jsonl')\n        test_data = os.path.join(args.data_path, args.relation, 'test.jsonl')\n\n        self.model = Prober(args)\n        self.original_vocab_size = len(list(self.model.tokenizer.get_vocab()))\n        prepare_for_dense_prompt(self.model)\n\n        if args.common_vocab is not None:\n            self.vocab_subset = load_vocab(args.common_vocab)\n            self.filter_indices, self.index_list = self.model.init_indices_for_filter_logprobs(self.vocab_subset)\n        else:\n            self.filter_indices = None\n            self.index_list = None\n\n        template = init_template(args, self.model)\n\n        self.valid_samples = load_data(dev_data, template, vocab_subset=self.vocab_subset, mask_token=self.model.MASK)\n        self.valid_samples_batches, self.valid_sentences_batches = batchify(self.valid_samples, args.eval_batch_size)\n\n        self.test_samples = load_data(test_data, template, vocab_subset=self.vocab_subset, mask_token=self.model.MASK)\n        self.test_samples_batches, self.test_sentences_batches = batchify(self.test_samples, args.eval_batch_size)\n\n        self.args = args\n        \n    def evaluate_valid(self, embeddings):\n        load_optiprompt(self.model, self.original_vocab_size, embeddings)\n        precision, _ = evaluate(self.model, self.valid_samples_batches, self.valid_sentences_batches, self.filter_indices, self.index_list)\n\n        return precision\n    \n    def evaluate_test(self, embeddings):\n        load_optiprompt(self.model, self.original_vocab_size, embeddings)\n        precision, _ = evaluate(self.model, self.test_samples_batches, self.test_sentences_batches, self.filter_indices, self.index_list)\n\n        return precision\n\n\nif __name__ == '__main__':\n    EvaluatePrompt().evaluate()\n\nFile Path: rel2abs_GO.py\nContent:\nimport torch\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom evaluate import EvaluatePrompt\n\n\nclass Rel2abs_Decoder:\n    def __init__(self, args, logger, target, src_anchors, anchors, tgt_distribution):\n        self.absolute = args.absolute\n        self.topk = args.topk\n\n        self.budget = args.budget\n        self.learning_rate = args.lr\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        target = torch.tensor(target).type(torch.float32).to(self.device)\n\n        src_anchors = torch.tensor(src_anchors).type(torch.float32).to(self.device)\n        self.target_rels = self.encode2rel(target, src_anchors)\n\n        if self.topk > 0:\n            self.target_rels, self.mask = self.zero_except_topk(self.target_rels)\n\n        self.mean = torch.tensor(tgt_distribution[0]).to(self.device)\n        self.std = torch.tensor(tgt_distribution[1]).to(self.device)\n\n        self.anchors = torch.tensor(anchors).type(torch.float32).to(self.device)\n        self.candidate = torch.empty((self.target_rels.shape[0], anchors.shape[1])).to(self.device)\n        self.candidate.requires_grad = True\n        torch.nn.init.xavier_normal_(self.candidate)\n\n        self.target_abss = None\n\n        self.eval_func = EvaluatePrompt(args)\n\n        self.cos_loss = nn.CosineEmbeddingLoss()\n        self.y = torch.ones(self.target_rels.shape[0]).to(self.device)\n\n        self.logger = logger\n\n        non_zero_indices = self.target_rels.nonzero(as_tuple=True)\n        non_zero_values = self.target_rels[non_zero_indices]\n        mean = non_zero_values.mean().item()\n        std = non_zero_values.std().item()\n        self.logger.info('Relative representations stat: mean %.4f, std %.4f' % (mean, std))\n    \n    def zero_except_topk(self, input_tensor):\n        if self.absolute:\n            _, topk_indices = torch.topk(torch.abs(input_tensor), self.topk)\n        else:\n            _, topk_indices = torch.topk(input_tensor, self.topk)\n\n        mask = torch.zeros_like(input_tensor).to(self.device)\n        mask.scatter_(-1, topk_indices, 1)\n        masked_tensor = input_tensor * mask\n        return masked_tensor, mask\n    \n    def regularize_tensor(self, tensor):\n        current_mean = torch.mean(tensor).to(self.device)\n        current_std = torch.std(tensor).to(self.device)\n        \n        normalized_tensor = (tensor - current_mean) / current_std\n        regularized_tensor = normalized_tensor * self.std + self.mean\n        \n        return regularized_tensor\n\n    def encode2rel(self, x, anchors):\n        A = F.normalize(x, dim=-1)\n        B = F.normalize(anchors, dim=-1)\n        return torch.matmul(A, B.T)\n\n    def set_target_abs(self, y):\n        self.target_abss = torch.tensor(y).type(torch.float32)\n        self.target_abss.requires_grad = False\n\n    def eval(self, x):\n        if self.target_abss == None:\n            raise AssertionError('No target abs embedding defined?')\n        cosine = nn.functional.cosine_similarity(x, self.target_abss, dim=-1)\n        return torch.mean(cosine).item()\n\n    def search(self):\n        optimizer = optim.Adam([self.candidate], lr=self.learning_rate)\n\n        best_precision = -1\n        best_candidate = None\n\n        pbar = tqdm(range(self.budget))\n        for i in pbar:\n            regularized_candidate = self.regularize_tensor(self.candidate)\n            x_rel = self.encode2rel(regularized_candidate, self.anchors)\n            if self.topk > 0:\n                x_rel = x_rel * self.mask\n\n            loss = self.cos_loss(x_rel, self.target_rels, self.y)\n\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            if (i+1) % 50 == 0:\n                with torch.no_grad():\n                    this_candidate = regularized_candidate.detach().cpu().numpy()\n                    precision = self.eval_func.evaluate_valid(this_candidate)\n                if precision > best_precision:\n                    best_candidate = this_candidate\n                    best_precision = precision\n                    self.logger.info('Get best precision: %.4f at step %d! loss: %.4f' % (best_precision, i+1, loss.item()))\n            pbar.set_description('best precision: %.4f, loss: %.4f' % (best_precision, loss.item()))\n\n        with torch.no_grad():\n            test_precision = self.eval_func.evaluate_test(best_candidate)\n        self.logger.info('Test precision: %.4f' % test_precision)\n\n        return best_candidate\n\nFile Path: rel2abs_GO_mix.py\nContent:\nimport torch\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom evaluate import EvaluatePrompt\n\nclass Rel2abs_Decoder:\n    def __init__(self, args, logger, target1, src_anchors1, target2, src_anchors2, anchors, tgt_distribution):\n        self.budget = args.budget\n        self.learning_rate = args.lr\n        self.absolute = args.absolute\n        self.topk = args.topk\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        target1 = torch.tensor(target1).type(torch.float32).to(self.device)\n        src_anchors1 = torch.tensor(src_anchors1).type(torch.float32).to(self.device)\n        self.target_rels1 = self.encode2rel(target1, src_anchors1)\n\n        target2 = torch.tensor(target2).type(torch.float32).to(self.device)\n        src_anchors2 = torch.tensor(src_anchors2).type(torch.float32).to(self.device)\n        self.target_rels2 = self.encode2rel(target2, src_anchors2)\n\n        if self.topk > 0:\n            self.target_rels2, self.mask = self.zero_except_topk(self.target_rels2)\n            self.target_rels1 = self.target_rels1 * self.mask\n\n        assert self.target_rels1.shape == self.target_rels2.shape\n\n        self.mean = torch.tensor(tgt_distribution[0]).to(self.device)\n        self.std = torch.tensor(tgt_distribution[1]).to(self.device)\n\n        self.anchors = torch.tensor(anchors).type(torch.float32).to(self.device)\n        self.candidate = torch.empty((self.target_rels1.shape[0], anchors.shape[1])).to(self.device)\n        self.candidate.requires_grad = True\n        torch.nn.init.xavier_normal_(self.candidate)\n\n        self.target_abss = None\n\n        self.eval_func = EvaluatePrompt(args)\n\n        self.cos_loss = nn.CosineEmbeddingLoss()\n        self.y = torch.ones(self.target_rels1.shape[0]).to(self.device)\n\n        self.logger = logger\n    \n    def zero_except_topk(self, input_tensor):\n        if self.absolute:\n            _, topk_indices = torch.topk(torch.abs(input_tensor), self.topk)\n        else:\n            _, topk_indices = torch.topk(input_tensor, self.topk)\n \n        mask = torch.zeros_like(input_tensor).to(self.device)\n        mask.scatter_(-1, topk_indices, 1)\n        masked_tensor = input_tensor * mask\n        return masked_tensor, mask\n    \n    def regularize_tensor(self, tensor):\n        current_mean = torch.mean(tensor).to(self.device)\n        current_std = torch.std(tensor).to(self.device)\n        \n        normalized_tensor = (tensor - current_mean) / current_std\n        regularized_tensor = normalized_tensor * self.std + self.mean\n        \n        return regularized_tensor\n\n    def encode2rel(self, x, anchors):\n        A = F.normalize(x, dim=-1)\n        B = F.normalize(anchors, dim=-1)\n        return torch.matmul(A, B.T)\n\n    def set_target_abs(self, y):\n        self.target_abss = torch.tensor(y).type(torch.float32)\n        self.target_abss.requires_grad = False\n\n    def eval(self, x):\n        if self.target_abss == None:\n            raise AssertionError('No target abs embedding defined?')\n        cosine = nn.functional.cosine_similarity(x, self.target_abss, dim=-1)\n        return torch.mean(cosine).item()\n\n    def search(self):\n        optimizer = optim.Adam([self.candidate], lr=self.learning_rate)\n\n        best_precision = -1\n        best_candidate = None\n\n        pbar = tqdm(range(self.budget))\n        for i in pbar:\n\n            regularized_candidate = self.regularize_tensor(self.candidate)\n            x_rel = self.encode2rel(regularized_candidate, self.anchors)\n            if self.topk > 0:\n                x_rel = x_rel * self.mask\n            \n            loss = (self.cos_loss(x_rel, self.target_rels1, self.y) + self.cos_loss(x_rel, self.target_rels2, self.y)) / 2\n\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            if (i+1) % 50 == 0:\n                with torch.no_grad():\n                    this_candidate = regularized_candidate.detach().cpu().numpy()\n                    precision = self.eval_func.evaluate_valid(this_candidate)\n                if precision > best_precision:\n                    best_candidate = this_candidate\n                    best_precision = precision\n                    self.logger.info('Get best precision: %.4f at step %d! loss: %.4f' % (best_precision, i+1, loss.item()))\n\n            pbar.set_description('best precision: %.4f, loss: %.4f' % (best_precision, loss.item()))\n\n        with torch.no_grad():\n            test_precision = self.eval_func.evaluate_test(best_candidate)\n        self.logger.info('Test precision: %.4f' % test_precision)\n        \n        return best_candidate\n\nFile Path: get_emb.py\nContent:\nimport numpy as np\nimport torch\nimport random\nimport argparse\nfrom rel2abs_util import get_abs_anchors\nimport os\nimport logging\n\nlogging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n                datefmt='%m/%d/%Y %H:%M:%S',\n                level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef save_embeddings(args, embeddings):\n    save_path = os.path.join(args.tgt_prompt_path, args.relation, args.transferred_prompt_filename)\n    with open(save_path, 'wb') as f:\n        logger.info('Saving transferred prompt embeddings to %s' % save_path)\n        np.save(f, embeddings)\n\ndef fix_seed(seed):\n    # random\n    random.seed(seed)\n    # Numpy\n    np.random.seed(seed)\n    # Pytorch\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\n\ndef transfer(args):\n    v_base = np.load(os.path.join(args.src_prompt_path, args.relation, args.prompt_filename))\n\n    bert_base_anchors, bert_large_anchors, tgt_distribution, _ = get_abs_anchors(\n        args.src_model, \n        args.tgt_model, \n        args.num_anchor, \n        args.common_vocab, \n        args.seed,\n        args.all_anchors\n        )\n\n    logger.info('Start searching for prompt embeddings for relation %s' % args.relation)\n\n    from rel2abs_GO import Rel2abs_Decoder\n    decoder = Rel2abs_Decoder(args, logger, v_base, bert_base_anchors, bert_large_anchors, tgt_distribution)\n    x = decoder.search()\n\n    save_embeddings(args, x)\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--relation', type=str, default='P17')\n    parser.add_argument('--src_prompt_path', type=str, default='OptiPrompt/optiprompt-outputs/bert-base-cased')\n    parser.add_argument('--tgt_prompt_path', type=str, default='OptiPrompt/optiprompt-outputs/bert-large-cased')\n    parser.add_argument('--prompt_filename', type=str, default='prompt_vecs.npy')\n    parser.add_argument('--transferred_prompt_filename', type=str, default='transfered_prompt_vecs.npy')\n    parser.add_argument('--src_model', type=str, default='bert-base-cased')\n    parser.add_argument('--tgt_model', type=str, default='bert-large-cased')\n    parser.add_argument('--num_anchor', type=int, default=8192)\n    parser.add_argument('--common_vocab', type=str, default='OptiPrompt/common_vocabs/common_vocab_cased_be_ro_al.txt')\n    parser.add_argument('--seed', type=int, default=42)\n    parser.add_argument('--num_vectors', type=int, default=5)\n    parser.add_argument('--log_path', type=str, default='OptiPrompt/output')\n    parser.add_argument('--log_tag', type=str, default='')\n\n    # args for validation\n    parser.add_argument('--relation_profile', type=str, default='OptiPrompt/relation_metainfo/LAMA_relations.jsonl')\n    parser.add_argument('--data_path', type=str, default='OptiPrompt/data/autoprompt_data')\n    parser.add_argument('--init_manual_template', action='store_true')\n    parser.add_argument('--absolute', action='store_true')\n    parser.add_argument('--topk', type=int, default=0)\n    parser.add_argument('--budget', type=int, default=2000)\n    parser.add_argument('--lr', type=float, default=5e-3)\n    parser.add_argument('--all_anchors', action='store_true')\n\n    args = parser.parse_args()\n\n    if args.init_manual_template:\n        if args.topk > 0:\n            log_file = os.path.join(args.log_path, 'training_top%d_manual%s.log' % (args.topk, args.log_tag))\n        else:\n            log_file = os.path.join(args.log_path, 'training_%d_manual%s.log' % (args.num_anchor, args.log_tag))\n    else:\n        if args.topk > 0:\n            log_file = os.path.join(args.log_path, 'training_%dtokens_top%d%s.log' % (args.num_vectors, args.topk, args.log_tag))\n        else:\n            log_file = os.path.join(args.log_path, 'training_%dtokens_%d%s.log' % (args.num_vectors, args.num_anchor, args.log_tag))\n\n\n    logger.addHandler(logging.FileHandler(log_file))\n\n    logger.info(args)\n\n    fix_seed(args.seed)\n    transfer(args)\n\nFile Path: get_emb_mix.py\nContent:\nimport numpy as np\nimport torch\nimport random\nimport argparse\nfrom rel2abs_util import get_abs_anchors\nimport os\nimport logging\n\nlogging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n                datefmt='%m/%d/%Y %H:%M:%S',\n                level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef save_embeddings(args, embeddings):\n    save_path = os.path.join(args.tgt_prompt_path, args.relation, args.transferred_prompt_filename)\n    with open(save_path, 'wb') as f:\n        logger.info('Saving transferred prompt embeddings to %s' % save_path)\n        np.save(f, embeddings)\n\ndef fix_seed(seed):\n    # random\n    random.seed(seed)\n    # Numpy\n    np.random.seed(seed)\n    # Pytorch\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\n\ndef transfer(args):\n    v_base1 = np.load(os.path.join(args.src_prompt_path1, args.relation, args.prompt_filename))\n    v_base2 = np.load(os.path.join(args.src_prompt_path2, args.relation, args.prompt_filename))\n\n    src_anchors1, tgt_anchors, tgt_distribution, src_anchors2 = get_abs_anchors(\n        args.src_model1, \n        args.tgt_model, \n        args.num_anchor, \n        args.common_vocab, \n        args.seed,\n        args.all_anchors,\n        model_name3= args.src_model2, \n        )\n    \n    logger.info('Start searching for prompt embeddings for relation %s' % args.relation)\n    \n    from rel2abs_GO_mix import Rel2abs_Decoder\n    decoder = Rel2abs_Decoder(args, \n                              logger, \n                              v_base1, \n                              src_anchors1, \n                              v_base2, \n                              src_anchors2, \n                              tgt_anchors, \n                              tgt_distribution\n                              )\n    x = decoder.search()\n\n    save_embeddings(args, x)\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--relation', type=str, default='P17')\n    parser.add_argument('--prompt_path', type=str, default='OptiPrompt/optiprompt-outputs')\n    parser.add_argument('--prompt_filename', type=str, default='prompt_vecs.npy')\n    parser.add_argument('--transferred_prompt_filename', type=str, default='transfered_prompt_vecs.npy')\n    parser.add_argument('--src_model1', type=str, default='bert-base-cased')\n    parser.add_argument('--src_model2', type=str, default='roberta-base')\n    parser.add_argument('--tgt_model', type=str, default='bert-large-cased')\n    parser.add_argument('--num_anchor', type=int, default=8192)\n    parser.add_argument('--common_vocab', type=str, default='OptiPrompt/common_vocabs/common_vocab_cased_be_ro_al.txt')\n    parser.add_argument('--seed', type=int, default=42)\n    parser.add_argument('--num_vectors', type=int, default=5)\n    parser.add_argument('--log_path', type=str, default='OptiPrompt/analyze_embed/output/log')\n    parser.add_argument('--log_tag', type=str, default='')\n\n    # args for validation\n    parser.add_argument('--relation_profile', type=str, default='OptiPrompt/relation_metainfo/LAMA_relations.jsonl')\n    parser.add_argument('--data_path', type=str, default='OptiPrompt/data/autoprompt_data')\n    parser.add_argument('--init_manual_template', action='store_true')\n    parser.add_argument('--budget', type=int, default=2000)\n    parser.add_argument('--lr', type=float, default=5e-3)\n    parser.add_argument('--all_anchors', action='store_true')\n    parser.add_argument('--topk', type=int, default=0)\n    parser.add_argument('--absolute', action='store_true')\n\n    args = parser.parse_args()\n\n    args.src_prompt_path1 = os.path.join(args.prompt_path, args.src_model1)\n    args.src_prompt_path2 = os.path.join(args.prompt_path, args.src_model2)\n    args.tgt_prompt_path = os.path.join(args.prompt_path, args.tgt_model)\n\n    if args.init_manual_template:\n        if args.topk > 0:\n            log_file = os.path.join(args.log_path, 'mix_training_top%d_manual%s.log' % (args.topk, args.log_tag))\n        else:\n            log_file = os.path.join(args.log_path, 'mix_training_%d_manual%s.log' % (args.num_anchor, args.log_tag))\n    else:\n        if args.topk > 0:\n            log_file = os.path.join(args.log_path, 'mix_training_top%d%s.log' % (args.topk, args.log_tag))\n        else:\n            log_file = os.path.join(args.log_path, 'mix_training_%d%s.log' % (args.num_anchor, args.log_tag))\n        \n    logger.addHandler(logging.FileHandler(log_file))\n\n    logger.info(args)\n\n    fix_seed(args.seed)\n    transfer(args)",
    "Experiment Result": "Common experimental settings:\n- `relation`: (str) Default 'P17'\n- `prompt_filename`: (str) Name of the source prompt embedding file, default 'prompt_vecs.npy'\n- `transferred_prompt_filename`: (str) Name for saving transferred prompt embeddings, default 'transfered_prompt_vecs.npy'\n- `tgt_model`: (str) Target model name (e.g., 'bert-large-cased')\n- `num_anchor`: (int) Number of anchor tokens to use for relative representation, default 8192\n- `common_vocab`: (str) Path to a file containing common vocabulary between models, default 'OptiPrompt/common_vocabs/common_vocab_cased_be_ro_al.txt'\n- `seed`: (int) Random seed for reproducibility, default 42\n- `num_vectors`: (int) Number of virtual tokens in the prompt, default 5\n- `budget`: (int) Number of optimization steps for searching target prompt embeddings, default 2000\n- `lr`: (float) Learning rate for the optimization, default 5e-3\n- `all_anchors`: (action='store_true') If set, use all common vocabulary words as anchors instead of sampling `num_anchor`\n- `topk`: (int) If > 0, consider only the top-k most similar anchor dimensions in the relative representation, default 0 (no top-k filtering)\n- `absolute`: (action='store_true') If set, use absolute values for `topk` selection (when `topk` > 0).\n\nSingle-source specific settings (from `get_emb.py`):\n- `src_prompt_path`: (str) Path to source prompt embeddings, default 'OptiPrompt/optiprompt-outputs/bert-base-cased'\n- `src_model`: (str) Source model name (e.g., 'bert-base-cased')\n- `tgt_prompt_path`: (str) Path to save target prompt embeddings, default 'OptiPrompt/optiprompt-outputs/bert-large-cased'\n\nMulti-source specific settings (from `get_emb_mix.py`):\n- `prompt_path`: (str) Base path for all prompt outputs, default 'OptiPrompt/optiprompt-outputs'\n- `src_model1`: (str) First source model name (e.g., 'bert-base-cased')\n- `src_model2`: (str) Second source model name (e.g., 'roberta-base')\n- `src_prompt_path1`: Derived from `prompt_path` and `src_model1`\n- `src_prompt_path2`: Derived from `prompt_path` and `src_model2`\n- `tgt_prompt_path`: Derived from `prompt_path` and `tgt_model`"
}{
    "Title": "Co-training Improves Prompt-based Learning for Large Language Models",
    "Main Contributions": "The paper demonstrates that co-training can significantly improve the performance of prompt-based learning for Large Language Models (LLMs) by effectively utilizing unlabeled data. It shows that co-training can enhance the original prompt model and simultaneously facilitate the learning of a smaller, task-specific downstream model. The approach is effective in both partial access (e.g., GPT-3 output probabilities) and full access (e.g., T0 gradients for soft prompt tuning) settings, leading to improved results on challenging datasets where a notable performance gap existed between prompt-based and fully-supervised methods. It also finds that pseudo-labels from a prompted model serve as an effective signal for fine-tuning smaller task-specific models.",
    "Methodology": "The methodology integrates co-training with prompt-based learning by defining two complementary views. View φ0(X) is derived from a large prompt-based model (GPT-3 output probabilities or T0's initial word embeddings), and View φ1(X) uses the frozen representation from a smaller pre-trained language model (e.g., DeBERTa's penultimate layer). Two settings are explored: 1. Partial Access (e.g., GPT-3): Model h0 is a learnable 'label model' that calibrates individual prompt outputs using prompt-specific matrices (initialized with Calibrate-Before-Use) and ensembles multiple prompts. Model h1 is the last few layers of DeBERTa. 2. Full Access (e.g., T0): Model h0 is a set of continuous soft prompt vectors (initialized with repeated [PAD] token embeddings and combined with hard prompt encoding) that are prepended to the input embedding for the frozen T0 model. Model h1 remains DeBERTa. During co-training iterations, models iteratively label a large unlabeled dataset, and each model is trained on confident pseudo-labels from the other. Confident data selection is performed using either 'model confidence' (sorting by scores, potentially with minimum class frequency) or a 'cut statistic' (graph-based heuristic based on K-nearest neighbors and agreement of pseudo-labels). The process uses relabeling, where pseudo-labels are regenerated in each iteration.",
    "Experimental Setup": "The research evaluated the approach on several standard natural language processing benchmarks known for a large gap between prompt-based and fully-supervised learning: RTE (binary textual entailment), CB (ternary textual entailment), TREC (6-way question classification), and BoolQ (binary reading comprehension). In the partial access setting, GPT-3 was used as the large prompt model (h0) with DeBERTa-large as the smaller model (h1), typically with k=4 few-shot examples. In the full access setting, T0-3B was used for h0 (via soft prompt tuning) and DeBERTa-large for h1, in a zero-shot context. Co-training involved an initial coverage β=0.5, per-step increase β'=0.1, and T=5 total steps, with a minimum label frequency γ=0.01. Hyperparameters for training h0 (label model/soft prompt) and h1 (DeBERTa) were based on common practices or existing work, with early stopping based on balanced accuracy on a pseudo-labeled validation set. The cut statistic was used for confident data selection in view 1 (and view 0 for full access), and model confidence for view 0 in partial access. Baselines included GPT-3 32-shot, Calibrate Before Use (CBU), Prompt-based FT (Gao etal., 2021), and Snorkel-based methods. All models were trained on two NVIDIA A100 80GB GPUs.",
    "Limitations": "The study identified several limitations: 1. **Noisy Initial Signal:** Co-training performance decreases if the initial signal provided by the prompted model is too noisy (e.g., BoolQ dataset with T0, where initial pseudo-labels had very high total noise). 2. **Insufficient Unlabeled Data:** The method can overfit when there is not enough unlabeled data to obtain good generalization performance, especially with highly flexible hypothesis classes (e.g., CB dataset with T0, where the soft prompt overfit the small pseudo-labeled training set). 3. **Gap in View Signal Quality:** The benefit is limited when there's a large gap in fully-supervised accuracy between the two views, suggesting that the weaker view might not provide enough signal for effective co-training. 4. **Hyperparameter Tuning:** While an effort was made to minimize this, the approach, like much prompt-based learning, implicitly assumes access to a small labeled set for selecting various model configurations (e.g., prompts and hyperparameters), making it not 'true' few-shot/zero-shot in the strictest sense.",
    "Future Research Directions": "Future research directions include: 1. Developing methods to overcome the identified limitations, specifically addressing issues with noisy initial signals from prompted models and situations with insufficient unlabeled data. 2. Investigating co-training in the context of 'true' few-shot/zero-shot learning, where no labeled data is used for hyperparameter selection or model configuration. 3. Exploring the use of warm-starting for models in co-training iterations to potentially reduce computational burden. 4. Conducting an in-depth comparison between the proposed hard prompt encoding combined with soft prompting and the traditional 'neutral encoding' soft-prompting setup to understand their impact on performance and label efficiency.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Co-training Improves Prompt-based Learning for Large Language Models",
    "Main Contributions": "The paper demonstrates that co-training, leveraging unlabeled data, significantly improves prompt-based learning for Large Language Models (LLMs) in few-shot and zero-shot settings. It tackles the brittleness and high model size requirements of prompting. Key findings include: (i) consistent performance improvement through iterative co-training, (ii) effectiveness of pseudo-labels from prompted models for fine-tuning smaller task-specific models, and (iii) notable performance gains on datasets challenging for traditional prompt-based methods, often bridging the gap with fully-supervised models. The approach also distills and refines knowledge into a smaller, performant model.",
    "Methodology": "The core methodology adapts co-training for prompt-based learning, using two views: φ0 from a large prompt model (GPT-3 or T0) and φ1 from a smaller pretrained model (DeBERTa). Two settings are explored: 1. Partial Access (e.g., GPT-3): h0 is a learnable 'label model' that calibrates and ensembles multiple one-shot GPT-3 prompts using a ReLU-scaled sum with learned weights; h1 is the last few layers of DeBERTa. 2. Full Access (e.g., T0): h0 is a continuous soft prompt (matrices prepended to input embeddings, with frozen T0 layers); h1 is again the last few layers of DeBERTa. The co-training algorithm iteratively trains h1 on h0's confident pseudo-labels and vice-versa, using either 'model confidence' or 'cut statistic' methods for confident data selection. Pseudo-labels are re-generated in each iteration ('relabeling'), and models are re-initialized from scratch each round.",
    "Experimental Setup": "The research was evaluated on standard NLP benchmarks: RTE, CB, TREC (for partial access), and RTE, CB, BoolQ (for full access, excluding datasets T0 was pretrained on, and BoolQ for GPT-3 due to quota). For partial access, k=4 labeled examples were used to initialize one-shot prompts. For full access, a zero-shot setting was used. Training hyperparameters were largely adopted from existing work, with co-training specific parameters (initial coverage β=0.5, coverage increase β'=0.1, T=5 iterations, minimum label frequency γ=0.01) tuned on a small gold-labeled TREC validation set. Validation during co-training used balanced accuracy on pseudo-labeled validation sets. Model Confidence was used for φ0 and Cut Statistic for φ1 in partial access, while Cut Statistic was used for both in full access. Baselines included GPT-3 32-shot, Calibrate Before Use (CBU), Prompt-based Fine-Tuning, and Snorkel variants. All models were trained on two NVIDIA A100 80Gb GPUs.",
    "Limitations": "The work shares a common limitation with much current prompt-based learning: it's not 'true' few-shot/zero-shot in the strictest sense, as it implicitly uses small labeled sets for selecting model configurations (e.g., prompts, hyperparameters). Co-training's benefits are limited when the initial signal from the prompted model is too noisy (e.g., BoolQ with high total noise), when there's insufficient unlabeled data to achieve good pseudo-label generalization (e.g., CB due to dataset size causing overfitting in soft prompting), or when there's a large discrepancy in fully-supervised accuracy between the two views (e.g., RTE partial vs. full access). The specific combination of hard prompt encoding with soft prompting is noted as a potential constraint that needs further investigation.",
    "Future Research Directions": "Future work could focus on investigating co-training within truly few-shot/zero-shot learning paradigms, minimizing any implicit reliance on labeled data for configuration. Developing methods to address the identified limitations is crucial, specifically: improving robustness when the initial prompted model signal is noisy (e.g., exploring different prompts or better initial h0 hypotheses), enhancing performance with limited unlabeled data (e.g., adjusting initial coverage or using less flexible h0 hypothesis classes), and mitigating issues arising from large accuracy gaps between the two views. Further exploration of warm-starting models in co-training is suggested to reduce computational burden. Finally, an in-depth comparison between traditional neutral-encoded soft-prompting and the proposed hard prompt + soft prompt encoding is an interesting avenue.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "DP-HyPO: An Adaptive Private Framework for Hyperparameter Optimization",
    "Main Contributions": "The paper introduces DP-HyPO, a pioneering adaptive private hyperparameter optimization (HPO) framework that bridges the gap between private and non-private HPO. It enables practitioners to adapt to previous runs and focus on potentially superior hyperparameters, allowing flexible use of non-DP adaptive HPO methods like Gaussian processes without substantial privacy costs from composition. The framework provides sharp Differential Privacy (DP) guarantees by utilizing the Rényi DP framework, strictly generalizing prior non-adaptive uniform sampling results without stability assumptions. Empirically, the Gaussian process-based DP-HyPO algorithm demonstrates superior performance compared to its uniform counterpart across diverse real-world datasets.",
    "Methodology": "DP-HyPO maintains an adaptive sampling distribution `π` at each iteration, which evolves based on accumulated information. The framework necessitates that the sampling distribution `π(j)` (at iteration `j`) has bounded density, constrained by constants `c` and `C` relative to a prior `π(0)`. To achieve this, a general recipe is proposed: any non-private adaptive HPO method's distribution `π(j)` is projected into a space `SC,c` of bounded density functions by solving a convex functional programming problem (`min f ||f - π(j)||^2 s.t. f ∈ SC,c`). The total number of training runs `T` is drawn from a random distribution (e.g., truncated negative binomial) to preserve privacy. An instantiation of DP-HyPO with Gaussian Processes (GP) is provided, where GPs build a surrogate model for performance, assign scores (estimated Upper Confidence Bound, UCB) to hyperparameters, and use a softmax function with an inverse temperature `β` to derive the sampling distribution, which is then projected into `SC,c`.",
    "Experimental Setup": "The DP-HyPO framework, specifically its Gaussian process-based instantiation (\"GP\"), was empirically evaluated against a Uniform DP-HyPO baseline (\"Uniform\") derived from prior work. Experiments were conducted in two privacy configurations: a white-box setting and a black-box setting. The white-box scenario involved training deep learning models on the MNIST and CIFAR-10 datasets. For MNIST, a standard CNN was trained with DP-SGD, optimizing learning rate `η` and clipping norm `R`. A semi-real simulation cached mean accuracies of five independently trained models, adding Gaussian noise (SD 0.1) upon sampling. The CIFAR-10 experiment used the same CNN and hyperparameters, but the landscape was generated by BoTorch, providing noisy scores from a normal distribution. The black-box setting involved a real-world Federated Learning (FL) task on a proprietary dataset from industry, optimizing learning rates for the central server (AdaGrad) and users (SGD), with the landscape also generated by BoTorch. Performance was measured by actual accuracy (MNIST, CIFAR-10) or loss (FL), with results aggregated over multiple runs (e.g., 400 for GP, 10000 for Uniform on MNIST). Key parameters included privacy budgets (`ε=15, δ=1e-5` for MNIST; `ε=12, δ=1e-5` for CIFAR-10), and GP-specific parameters like `C=2, c=0.75, τ=0.1, β=1` (varied `C` for FL). Hyperparameter spaces were discretized for practical implementation.",
    "Limitations": "The framework requires posterior sampling distributions to have densities bounded by constants `c` and `C`, which may not be naturally satisfied by non-private adaptive HPO methods, necessitating a projection technique. Practically, discretizing the hyperparameter space `Λ` is necessary for computational feasibility of the convex optimization problem, even though the theoretical formulation allows for general measurable spaces. Additionally, empirical results on MNIST showed only marginal superiority of DP-HyPO over its uniform counterpart, which the authors attribute to the potentially \"uncomplicated\" hyperparameter landscape of MNIST limiting the benefits of adaptive algorithms.",
    "Future Research Directions": "Two main future research directions are suggested: First, exploring alternative HPO specifications to improve empirical performance by leveraging more advanced HPO methods from the extensive existing literature. Second, establishing theoretical utility guarantees for the general DP-HyPO framework, or for specific configurations within it, by leveraging similar proof methodologies to those found in prior work like Theorem 3.3 in [26].",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Hyperparameter Optimization through Neural Network Partitioning",
    "Main Contributions": "The paper introduces 'Partitioned Neural Networks,' a novel and efficient method for hyperparameter optimization (HPO) that is inspired by the marginal likelihood, yet requires only a single training run and no validation data. The core contribution is enabling HPO by partitioning the training data and a neural network model into K data shards and parameter partitions, respectively. Each partition is optimized only on specific data shards, and the 'out-of-training-sample' loss on unseen data shards serves as the objective for hyperparameter optimization. This approach is demonstrated to be computationally cheaper and more scalable than prior marginal likelihood-based methods and is particularly beneficial for scenarios like federated learning where traditional HPO is challenging.",
    "Methodology": "The method optimizes a lower-bound approximation to the marginal likelihood, denoted as LML, which leverages a 'learning speed' perspective. Neural network weights are partitioned into C chunks (w1, ..., wC). Subnetworks w(k)s are formed by concatenating w1, ..., wk and setting subsequent parameters to default values (e.g., initialization). Model parameters wk are updated by optimizing the negative log-likelihood on data from shards D1:k using subnetwork w(k)s. Hyperparameters (ψ) are optimized with respect to the LML objective (Equation 4), which is computed as the sum of out-of-sample losses on current data shard Dk using subnetworks w(k-1)s trained on preceding shards D1:k-1. The authors use random weight partitioning for experiments, where a fixed proportion of weights in each layer is randomly assigned to partitions. Optimization is performed using stochastic gradient descent (SGD) for both model parameters and hyperparameters, with specialized scheduling for per-partition updates and scaled weight-decay for earlier partitions.",
    "Experimental Setup": "The method was evaluated on several tasks: a toy input selection problem (both fixed mask and differentiable mask learning), learning invariances through affine data augmentations, optimizing a feature extractor, and hyperparameter optimization in a federated learning (FL) setting. Datasets included synthetic data for input selection, MNIST, CIFAR10, TinyImagenet, and their rotated variants (rotCIFAR10, rotTinyImagenet, rotMNIST) for invariance learning. FL experiments used non-i.i.d. splits of MNIST and CIFAR10 across 100 clients. Architectures varied from MLPs for toy tasks to CNNs, fixupResNets (8, 14 layers), ResNet-50 with GroupNorm, and Wide ResNet-20. Baselines included Post-hoc Diagonal Laplace, standard training, Augerino, Differentiable Laplace, Last-layer marginal likelihood, traditional validation set optimization with fine-tuning, and FedAvg with/without Augerino. Validation was primarily based on test accuracy, log-likelihood, and analysis of learned mask probabilities. Experiments used 2, 3, or 4 chunks, often with non-uniform data/parameter distributions.",
    "Limitations": "The method introduces an additional computational overhead due to the necessity of an extra forward-backward pass for hyperparameter updates, although this overhead is significantly less than existing marginal likelihood approximation methods. Empirically, partitioned networks may require more training iterations to converge. The partitioning of the network inherently constrains its capacity, potentially leading to some loss of performance compared to a full, non-partitioned network trained with perfectly tuned hyperparameters. Furthermore, the partitioning strategy itself (number of chunks, relative data/parameter proportions) becomes an additional hyperparameter that may require tuning for optimal performance. The authors also noted pathological behavior in one of the baseline methods (Augerino), requiring careful tuning or clipping to prevent divergence.",
    "Future Research Directions": "Future research could explore dynamic partitioning of network parameters during training, rather than fixing them upfront. Investigating alternative partitioning schemes that allow updating multiple partitions with a single batch could potentially reduce computational overhead. Opportunities exist to alleviate the observed performance loss by adjusting training rounds or increasing network capacity. Optimizing the scheduling of hyperparameter updates (e.g., gradient accumulation, less frequent updates) is another area for exploration to manage computational overhead and variance. Finally, in the federated learning context, exploring different sequential updating schemes for partitions on client devices is a promising direction.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Implicit differentiation of Lasso-type models for hyperparameter optimization",
    "Main Contributions": "The paper introduces an efficient implicit differentiation algorithm for hyperparameter optimization (HO) of Lasso-type models, specifically tailored for non-smooth objectives and high-dimensional sparse data. The key contribution is an implicit differentiation method that avoids direct matrix inversion, which is common in traditional implicit differentiation but can be numerically unstable and prohibitive for non-smooth problems. It leverages the sparsity of Lasso solutions and decouples the computation of regression coefficients from the Jacobian. The method is shown to converge linearly to the true gradient once the solution's support is identified, and it outperforms various state-of-the-art HO methods (including other gradient-based and non-gradient-based approaches) on both simulated and real-world high-dimensional datasets for held-out loss and Stein Unbiased Risk Estimator (SURE) criteria.",
    "Methodology": "The methodology frames hyperparameter optimization as a nested bi-level problem, optimizing a differentiable criterion (e.g., held-out loss or SURE) with respect to hyperparameters, where the inner problem solves for Lasso or weighted Lasso regression coefficients. For non-smooth Lasso-type problems, traditional implicit differentiation methods based on optimality conditions for smooth functions are not applicable. The proposed 'Implicit Forward Iterative Differentiation' (Algorithm 2) overcomes this by exploiting the fixed-point iteration property of proximal Block Coordinate Descent (BCD) algorithms. It first solves the inner Lasso problem to identify the support of the solution (non-zero coefficients), and then applies forward differentiation recursion steps to compute the Jacobian. This two-step process avoids solving potentially ill-conditioned linear systems and exploits the sparsity of the Jacobian. The regularization parameter is parameterized as e^λ to handle positivity constraints and scaling. For the SURE criterion, a weakly differentiable approximation using Finite Differences Monte-Carlo is employed.",
    "Experimental Setup": "The method's performance was evaluated against several competitors, including other gradient-based methods (Implicit Differentiation, Forward Iterative Differentiation) and non-gradient-based methods (Grid-search, Random-search, Lattice Hypercube Sampling, Bayesian optimization). All inner optimization problems were solved using a vanilla BCD algorithm with a stopping tolerance of 10^-5. Gradient-based methods employed a line-search strategy, and initialization for Lasso was set to λ_max - log(10). For the weighted Lasso, a regularized HO problem was solved to obtain a robust initialization. Experiments were conducted on: 1. Held-out loss on real-world datasets: rcv1 (n=20k, p=20k), 20news (n=11k, p=130k), and finance (n=16k, p=1.6M). 2. SURE criterion on simulated data: n=100, p ranging from 200 to 10,000, with varying SNR. Metrics included distance to optimum for the validation loss, test set loss, and relative Mean Squared Error (for estimation tasks). The method was also applied to the non-convex MCP estimator with two hyperparameters on rcv1 and 20news. The code is open-source (https://github.com/QB3/sparse-ho) and uses Numba for performance.",
    "Limitations": "The theoretical guarantees (Propositions 1 and 2 regarding Jacobian convergence) assume uniqueness of the Lasso solution and do not explicitly cover non-convex penalty functions like MCP, although the method demonstrated proper numerical behavior on MCP. The HO problem itself can be non-convex for weighted Lasso or MCP, meaning gradient descent may converge to local minima, which was mitigated by a regularized initialization strategy in experiments. The SURE criterion requires prior knowledge of the noise variance. Comparing the computational efficiency of gradient-based and non-gradient-based methods is inherently challenging due to their different search space approaches (continuous vs. discrete). While the method itself is robust, other single-step automatic differentiation approaches might struggle with state-of-the-art Lasso solvers that employ discontinuous techniques like active sets or screening rules.",
    "Future Research Directions": "Future research could focus on extending the theoretical guarantees to non-convex Lasso-type formulations (e.g., MCP, Elastic-Net) which are currently only supported numerically. Further investigation into the behavior and theoretical guarantees in pathological settings where Lasso solutions are not unique, though rare, could also be a direction. Exploring the integration of more advanced, specialized inner solvers (beyond vanilla BCD) and their implications for the Jacobian computation, especially considering the potential for discontinuities, remains an open area for optimization.",
    "Experiment Code": "import numpy as np\nfrom scipy.sparse import issparse\n\n\nclass Forward():\n    \"\"\"Algorithm to compute the hypergradient using forward differentiation of\n    proximal coordinate descent.\n\n    The algorithm jointly and iteratively computes the regression coefficients\n    and the Jacobian using forward differentiation of proximal\n    coordinate descent.\n\n    Parameters\n    ----------\n    use_stop_crit: bool, optional (default=True)\n        Use stopping criterion in hypergradient computation. If False,\n        run to maximum number of iterations.\n    verbose: bool, optional (default=False)\n        Verbosity of the algorithm.\n    \"\"\"\n\n    def __init__(self, use_stop_crit=True, verbose=False):\n        self.use_stop_crit = use_stop_crit\n        self.verbose = verbose\n\n    def compute_beta_grad(\n            self, X, y, log_alpha, model, get_grad_outer, mask0=None,\n            dense0=None, quantity_to_warm_start=None, max_iter=1000, tol=1e-3,\n            full_jac_v=False):\n        \"\"\"Compute beta and hypergradient, with forward differentiation of\n        proximal coordinate descent.\n\n        Parameters\n        ----------\n        X: array-like, shape (n_samples, n_features)\n            Design matrix.\n        y: ndarray, shape (n_samples,)\n            Observation vector.\n        log_alpha: float or np.array, shape (n_features,)\n            Logarithm of hyperparameter.\n        model:  instance of ``sparse_ho.base.BaseModel``\n            A model that follows the sparse_ho API.\n        get_grad_outer: callable\n            Function which returns the gradient of the outer criterion.\n        mask0: ndarray, shape (n_features,)\n            Boolean of active feature of the previous regression coefficients\n            beta for warm start.\n        dense0: ndarray, shape (mask.sum(),)\n            Initial value of the previous regression coefficients\n            beta for warm start.\n        quantity_to_warm_start: ndarray\n            Previous Jacobian of the inner optimization problem.\n        max_iter: int\n            Maximum number of iteration for the inner solver.\n        tol: float\n            The tolerance for the inner optimization problem.\n        full_jac_v: bool\n            TODO\n        \"\"\"\n        # jointly compute the regression coefficients beta and the Jacobian\n        mask, dense, jac = compute_beta(\n            X, y, log_alpha, model, mask0=mask0, dense0=dense0,\n            jac0=quantity_to_warm_start, max_iter=max_iter, tol=tol,\n            compute_jac=True, verbose=self.verbose,\n            use_stop_crit=self.use_stop_crit)\n        if jac is not None:\n            jac_v = model.get_jac_v(X, y, mask, dense, jac, get_grad_outer)\n            if full_jac_v:\n                jac_v = model.get_full_jac_v(mask, jac_v, X.shape[1])\n        else:\n            jac_v = None\n\n        return mask, dense, jac_v, jac\n\n\ndef compute_beta(\n        X, y, log_alpha, model, mask0=None, dense0=None, jac0=None,\n        max_iter=1000, tol=1e-3, compute_jac=True, return_all=False,\n        save_iterates=False, verbose=False, use_stop_crit=True, gap_freq=10):\n    \"\"\"\n    Parameters\n    --------------\n    X: array-like, shape (n_samples, n_features)\n        Design matrix.\n    y: ndarray, shape (n_samples,)\n        Observation vector.\n    log_alpha: float or np.array, shape (n_features,)\n        Logarithm of hyperparameter.\n    beta0: ndarray, shape (n_features,)\n        initial value of the regression coefficients\n        beta for warm start\n    dbeta0: ndarray, shape (n_features,)\n        initial value of the jacobian dbeta for warm start\n    max_iter: int\n        number of iterations of the algorithm\n    tol: float\n        The tolerance for the optimization: if the updates are\n        smaller than ``tol``, the optimization code checks the\n        primal decrease for optimality and continues until it\n        is smaller than ``tol``\n    compute_jac: bool\n        to compute or not the Jacobian along with the regression\n        coefficients\n    model:  instance of ``sparse_ho.base.BaseModel``\n        A model that follows the sparse_ho API.\n    return_all: bool\n        to store the iterates or not in order to compute the Jacobian in a\n        backward way\n    use_stop_crit: bool\n        use a stopping criterion or do all the iterations\n    gap_freq : int\n        After how many passes on the data the dual gap should be computed\n        to stop the iterations.\n\n    Returns\n    -------\n    mask : ndarray, shape (n_features,)\n        The mask of non-zero coefficients in beta.\n    dense : ndarray, shape (n_nonzeros,)\n        The beta coefficients on the support\n    jac : ndarray, shape (n_nonzeros,) or (n_nonzeros, q)\n        The jacobian restricted to the support. If there are more than\n        one hyperparameter then it has two dimensions.\n    \"\"\"\n    n_samples, n_features = X.shape\n    is_sparse = issparse(X)\n    if not is_sparse and not np.isfortran(X):\n        X = np.asfortranarray(X)\n    L = model.get_L(X)\n\n    ############################################\n    alpha = np.exp(log_alpha)\n\n    if hasattr(model, 'estimator') and model.estimator is not None:\n        return model._use_estimator(X, y, alpha, tol)\n\n    try:\n        alpha.shape[0]\n        alphas = alpha.copy()\n    except Exception:\n        alphas = np.ones(n_features) * alpha\n    ############################################\n    # warm start for beta\n    beta, dual_var = model._init_beta_dual_var(X, y, mask0, dense0)\n    ############################################\n    # warm start for dbeta\n    dbeta, ddual_var = model._init_dbeta_ddual_var(\n        X, y, mask0=mask0, dense0=dense0, jac0=jac0, compute_jac=compute_jac)\n\n    # store the values of the objective\n    pobj0 = model._get_pobj0(dual_var, np.zeros(X.shape[1]), alphas, y)\n    pobj = []\n\n    ############################################\n    # store the iterates if needed\n    if return_all:\n        list_beta = []\n    if save_iterates:\n        list_beta = []\n        list_jac = []\n\n    for i in range(max_iter):\n        if verbose:\n            print(\"%i -st iteration over %i\" % (i, max_iter))\n        if is_sparse:\n            model._update_beta_jac_bcd_sparse(\n                X.data, X.indptr, X.indices, y, n_samples, n_features, beta,\n                dbeta, dual_var, ddual_var, alphas, L,\n                compute_jac=compute_jac)\n        else:\n            model._update_beta_jac_bcd(\n                X, y, beta, dbeta, dual_var, ddual_var, alphas,\n                L, compute_jac=compute_jac)\n\n        pobj.append(model._get_pobj(dual_var, X, beta, alphas, y))\n\n        if i > 1:\n            if verbose:\n                print(\"relative decrease = \", (pobj[-2] - pobj[-1]) / pobj0)\n\n        if use_stop_crit and i % gap_freq == 0 and i > 0:\n            if hasattr(model, \"_get_dobj\"):\n                dobj = model._get_dobj(dual_var, X, beta, alpha, y)\n                dual_gap = pobj[-1] - dobj\n                if verbose:\n                    print(\"dual gap %.2e\" % dual_gap)\n                if verbose:\n                    print(\"gap %.2e\" % dual_gap)\n                if dual_gap < pobj0 * tol:\n                    break\n            else:\n                if (pobj[-2] - pobj[-1] <= pobj0 * tol):\n                    break\n        if return_all:\n            list_beta.append(beta.copy())\n        if save_iterates:\n            list_beta.append(beta.copy())\n            list_jac.append(dbeta.copy())\n    else:\n        if verbose:\n            print('did not converge !')\n\n    mask = beta != 0\n    dense = beta[mask]\n    jac = model._get_jac(dbeta, mask)\n    if hasattr(model, 'dual'):\n        model.dual_var = dual_var\n        if compute_jac:\n            model.ddual_var = ddual_var\n    if save_iterates:\n        return np.array(list_beta), np.array(list_jac)\n    if return_all:\n        return mask, dense, list_beta\n    else:\n        if compute_jac:\n            return mask, dense, jac\n        else:\n            return mask, dense, None\nimport numpy as np\nfrom scipy.sparse import issparse\nfrom sparse_ho.algo.forward import compute_beta\n\n\nclass ImplicitForward():\n    \"\"\"Algorithm to compute the hypergradient using implicit forward\n    differentiation.\n\n    First the algorithm computes the regression coefficients.\n    Then the iterations of the forward differentiation are applied to compute\n    the Jacobian.\n\n    Parameters\n    ----------\n    tol_jac: float\n        Tolerance for the Jacobian computation.\n    max_iter: int\n        Maximum number of iterations for the inner solver.\n    n_iter_jac: int\n        Maximum number of iterations for the Jacobian computation.\n    use_stop_crit: bool, optional (default=True)\n        Use stopping criterion in hypergradient computation. If False,\n        run to maximum number of iterations.\n    verbose: bool, optional (default=False)\n        Verbosity of the algorithm.\n    \"\"\"\n\n    def __init__(\n            self, tol_jac=1e-3, max_iter=100, n_iter_jac=100,\n            use_stop_crit=True, verbose=False):\n        self.max_iter = max_iter\n        self.tol_jac = tol_jac\n        self.n_iter_jac = n_iter_jac\n        self.use_stop_crit = use_stop_crit\n        self.verbose = verbose\n\n    def get_beta_jac(\n            self, X, y, log_alpha, model, get_grad_outer, mask0=None,\n            dense0=None, quantity_to_warm_start=None, max_iter=1000, tol=1e-3,\n            full_jac_v=False):\n        \"\"\"Compute beta and hypergradient using implicit forward\n        differentiation.\n\n        Parameters\n        ----------\n        X: array-like, shape (n_samples, n_features)\n            Design matrix.\n        y: ndarray, shape (n_samples,)\n            Observation vector.\n        log_alpha: float or np.array, shape (n_features,)\n            Logarithm of hyperparameter.\n        model:  instance of ``sparse_ho.base.BaseModel``\n            A model that follows the sparse_ho API.\n        get_grad_outer: callable\n            Function which returns the gradient of the outer criterion.\n        mask0: ndarray, shape (n_features,)\n            Boolean of active feature of the previous regression coefficients\n            beta for warm start.\n        dense0: ndarray, shape (mask.sum(),)\n            Initial value of the previous regression coefficients\n            beta for warm start.\n        quantity_to_warm_start: ndarray\n            Previous Jacobian of the inner optimization problem.\n        max_iter: int\n            Maximum number of iteration for the inner solver.\n        tol: float\n            The tolerance for the inner optimization problem.\n        full_jac_v: bool\n            TODO\n        \"\"\"\n\n        mask, dense, jac = get_bet_jac_implicit_forward(\n            X, y, log_alpha, mask0=mask0, dense0=dense0,\n            jac0=quantity_to_warm_start,\n            tol_jac=tol, tol=tol, niter_jac=self.n_iter_jac, model=model,\n            max_iter=self.max_iter, verbose=self.verbose)\n        return mask, dense, jac\n\n    def compute_beta_grad(\n            self, X, y, log_alpha, model, get_grad_outer, mask0=None,\n            dense0=None, quantity_to_warm_start=None, max_iter=1000, tol=1e-3,\n            full_jac_v=False):\n        mask, dense, jac = get_bet_jac_implicit_forward(\n            X, y, log_alpha, mask0=mask0, dense0=dense0,\n            jac0=quantity_to_warm_start,\n            tol_jac=self.tol_jac, tol=tol, niter_jac=self.n_iter_jac,\n            model=model, max_iter=self.max_iter, verbose=self.verbose,\n            use_stop_crit=self.use_stop_crit)\n        jac_v = model.get_jac_v(X, y, mask, dense, jac, get_grad_outer)\n        if full_jac_v:\n            jac_v = model.get_full_jac_v(mask, jac_v, X.shape[1])\n\n        return mask, dense, jac_v, jac\n\n\ndef get_bet_jac_implicit_forward(\n        X, y, log_alpha, model, mask0=None, dense0=None, jac0=None,\n        tol=1e-3, max_iter=1000, niter_jac=1000, tol_jac=1e-6, verbose=False,\n        use_stop_crit=True):\n\n    mask, dense, _ = compute_beta(\n        X, y, log_alpha, mask0=mask0, dense0=dense0, jac0=jac0, tol=tol,\n        max_iter=max_iter, compute_jac=False, model=model, verbose=verbose,\n        use_stop_crit=use_stop_crit)\n    dbeta0_new = model._init_dbeta0(mask, mask0, jac0)\n    reduce_alpha = model._reduce_alpha(np.exp(log_alpha), mask)\n\n    _, dual_var = model._init_beta_dual_var(X, y, mask, dense)\n    jac = get_only_jac(\n        model.reduce_X(X, mask), model.reduce_y(y, mask), dual_var,\n        reduce_alpha, model.sign(dense, log_alpha), dbeta=dbeta0_new,\n        niter_jac=niter_jac, tol_jac=tol_jac, model=model, mask=mask,\n        dense=dense, verbose=verbose, use_stop_crit=use_stop_crit)\n\n    return mask, dense, jac\n\n\ndef get_only_jac(\n        Xs, y, dual_var, alpha, sign_beta, dbeta=None, niter_jac=100,\n        tol_jac=1e-4, model=\"lasso\", mask=None, dense=None, verbose=False,\n        use_stop_crit=True):\n    n_samples, n_features = Xs.shape\n\n    L = model.get_L(Xs)\n\n    residual_norm = []\n\n    if hasattr(model, 'dual'):\n        ddual_var = model._init_ddual_var(dbeta, Xs, y, sign_beta, alpha)\n        dbeta = model.dbeta\n    else:\n        if dbeta is None:\n            dbeta = model._init_dbeta(n_features)\n        ddual_var = model._init_ddual_var(dbeta, Xs, y, sign_beta, alpha)\n\n    for i in range(niter_jac):\n        if verbose:\n            print(\"%i -st iterations over %i\" % (i, niter_jac))\n        if issparse(Xs):\n            model._update_only_jac_sparse(\n                Xs.data, Xs.indptr, Xs.indices, y, n_samples,\n                n_features, dbeta, dual_var, ddual_var, L, alpha, sign_beta)\n        else:\n            model._update_only_jac(\n                Xs, y, dual_var, dbeta, ddual_var, L, alpha, sign_beta)\n        residual_norm.append(\n            model.get_jac_residual_norm(\n                Xs, y, n_samples, sign_beta, dbeta, dual_var,\n                ddual_var, alpha))\n        if use_stop_crit and i > 1:\n            # relative stopping criterion for the computation of the jacobian\n            # and absolute stopping criterion to handle warm start\n            rel_tol = np.abs(residual_norm[-2] - residual_norm[-1])\n            if (rel_tol < np.abs(residual_norm[-1]) * tol_jac\n                    or residual_norm[-1] < 1e-10):\n                break\n    # HACK we only need this for one test, do not rely on it\n    get_only_jac.n_iter = i\n\n    return dbeta\n",
    "Experiment Result": "The 'Implicit Forward Iterative Differentiation' (ImplicitForward) algorithm is extensively tested across various machine learning models and criteria. The regularization parameter (lambda) is consistently parameterized as `e^λ` to handle positivity constraints and scaling, often optimized using geometric spacing of alpha values or starting from `alpha_max / C`.\n\n**Models and Criteria:**\n-   **Lasso:** Used with HeldOutMSE, CrossVal (HeldOutMSE), and FiniteDiffMonteCarloSure.\n-   **ElasticNet:** Used with HeldOutMSE and CrossVal (HeldOutMSE).\n-   **WeightedLasso:** Used with HeldOutMSE and CrossVal (HeldOutMSE).\n-   **SparseLogreg:** Used with HeldOutLogistic and LogisticMulticlass.\n\n**Hyperparameter Optimization Settings for ImplicitForward:**\n-   **Tolerance for Jacobian computation (`tol_jac`):** Values range from `1e-3` (e.g., `examples/plot_held_out_enet.py`, `expes/expe_elastic/main.py`) to `1e-8` (e.g., `examples/plot_sparse_log_reg.py`) and even `1e-32` (e.g., `expes/hypergradient/main_hypergradient.py`) for high precision.\n-   **Maximum iterations for Jacobian computation (`n_iter_jac`):** Common values include `100` (e.g., `examples/plot_held_out_enet.py`, `expes/expe_elastic/main.py`), `1000` (e.g., `examples/plot_compare_optimizers.py`, `examples/plot_sparse_log_reg.py`), and up to `5000` or `100000` for more intensive evaluations.\n-   **Maximum iterations for inner solver (`max_iter`):** Typically set to `50` or `100` for quick runs, but often extended to `1000`, `10000`, or `50000` for full convergence. Some experiments use a `max_iter` equal to `n_iter_jac`.\n-   **Tolerance for inner solver (`tol`):** Ranges from `1e-3` to `1e-8`, with some tests using extremely tight tolerances like `1e-16` or `1e-32` for convergence analysis.\n-   **Stopping Criterion (`use_stop_crit`):** Defaults to `True`, but can be explicitly set to `False` in experiments focused on analyzing convergence behavior over a fixed number of iterations.\n\n**SURE Criterion Specifics:**\n-   When `FiniteDiffMonteCarloSure` is used (e.g., `examples/plot_meg_lasso_vs_wlasso.py`), the `sigma` parameter (noise level) is provided. The `finite_difference_step` is either given explicitly or computed using a heuristic `2.0 * sigma / (X.shape[0]) ** 0.3`.\n\n**Data Splitting:**\n-   Commonly, data is split into training and validation sets (e.g., `n_samples // 2` for each), or through K-Fold Cross-Validation (`KFold(n_splits=5, shuffle=True, random_state=42)`).\n\n**Outer Optimization:**\n-   The extracted examples primarily use `GradientDescent` or `LineSearch` as outer optimizers, with `Adam` also present in one example."
}{
    "Title": "Bayesian Optimization for Iterative Learning",
    "Main Contributions": "The paper presents a Bayesian Optimization (BO) approach, termed BOIL, for efficient hyperparameter tuning of deep (reinforcement) learning systems that exploit their iterative training structure. It introduces a method to compress the entire learning curve into a single numeric score based on training success and stability, rather than relying solely on final performance. The framework balances the cost of additional training steps against their assessment benefit. It further enhances efficiency through a selective data augmentation technique that leverages intermediate information from the iterative process, demonstrating superior performance in identifying optimal hyperparameters in minimal wall-clock time for DRL agents and convolutional neural networks.",
    "Methodology": "The BOIL algorithm models the cost-sensitive black-box function as a Gaussian Process (GP) over the joint space of input hyperparameters (x) and number of training iterations (t), using a product kernel. It compresses the entire learning curve into a numeric utility score using a Sigmoid (Logistic) preference function, whose growth (g0) and middle point (m0) parameters are learned by maximizing the GP's log marginal likelihood. To improve sample-efficiency and prevent GP covariance matrix ill-conditioning, it employs a selective data augmentation technique. This technique samples a subset of points from the observed learning curve at locations of maximum GP predictive uncertainty, dynamically controlling the number of augmented points based on a condition number threshold. The next hyperparameter and iteration count are chosen by maximizing an acquisition function (a modified Expected Improvement criterion) normalized by the predicted training cost (approximated by a linear regressor).",
    "Experimental Setup": "All experiments were averaged over 20 independent runs using NVIDIA 1080 GTX GPUs and the TensorFlow-GPU Python package. The algorithm was evaluated on Deep Reinforcement Learning (DRL) tasks: a Dueling DQN (DDQN) agent in the CartPole-v0 environment, and Advantage Actor Critic (A2C) agents in the InvertedPendulum-v2 and Reacher-v2 environments (from OpenAI gym and Mujoco). It was also tested on tuning hyperparameters for a Convolutional Neural Network (CNN) on the SVHN and CIFAR10 datasets. Square-exponential kernels were used for the GP, with parameters estimated by maximizing marginal likelihood. Baselines included Hyperband and Continuous Multi-Task/Fidelity BO (CM-T/F-BO). Ablation studies were conducted with vanilla BO and BO with only Logistic curve compression (BO-L). Maximum augmented points were set to 15, and the natural log of the GP condition number threshold was 20.",
    "Limitations": "A naive approach of augmenting training data by adding a full curve of points can lead to redundancy and severe ill-conditioning of the Gaussian Process covariance matrix, particularly in noisy DRL settings. Existing stopping criteria and models (like exponential decay in Freeze-thaw BO) are often not applicable to DRL due to the unpredictable fluctuations and noisiness of reward curves. From a broader impact perspective, the increasing automation facilitated by such algorithms could lead to humans becoming further removed from the modeling process, potentially making it harder to detect critical failures and contributing to the growing opacity of machine learning models.",
    "Future Research Directions": "The proposed framework is not limited to machine learning algorithms and can be applied more generally to any iterative process where progress can be exploited, such as optimizing manufacturing pipelines. Future work can contribute to the widespread deployment of supervised learning and reinforcement learning systems by further enhancing training efficiency and reducing their computational and environmental costs. The algorithm represents a step towards constructing fully automated pipelines for machine learning model training and deployment. It is also suggested that such automated training procedures should be integrated with the growing body of work on machine learning interpretability to rigorously analyze final training outcomes and ensure transparent decision-making.",
    "Experiment Code": "import numpy as npfrom bayes_opt.acquisition_functions import AcquisitionFunction, unique_rowsfrom bayes_opt import GaussianProcessfrom bayes_opt import ProductGaussianProcessfrom bayes_opt.acquisition_maximization import acq_max_with_name,acq_min_scipy_kwargsimport timefrom sklearn import linear_modelimport copyfrom bayes_opt.curve_compression import transform_logisticfrom sklearn.preprocessing import MinMaxScalercounter = 0class BOIL(object):    def __init__(self, func, SearchSpace,acq_name=\"ei_mu_max\",verbose=1):        self.method='boil'        self.verbose=verbose        if isinstance(SearchSpace,dict):            self.keys = list(SearchSpace.keys())            self.SearchSpace = []            for key in list(SearchSpace.keys()):                self.SearchSpace.append(SearchSpace[key])            self.SearchSpace = np.asarray(self.SearchSpace)        else:            self.SearchSpace=np.asarray(SearchSpace)            self.dim = len(SearchSpace)        scaler = MinMaxScaler()        scaler.fit(self.SearchSpace[:-1,:].T)        scalerT = MinMaxScaler()        SearchSpace_T=np.atleast_2d(self.SearchSpace[-1,:]).T        scalerT.fit(SearchSpace_T)        self.Xscaler=scaler        self.Tscaler=scalerT        self.scaleSearchSpace=np.array([np.zeros(self.dim), np.ones(self.dim)]).T                self.f = func        self.X_ori= None        self.X = None        self.Y = None               self.Y_ori = None        self.T=None        self.T_original=None        self.Y_cost_original=None        self.time_opt=0         self.max_min_gap=self.SearchSpace[:,1]-self.SearchSpace[:,0]        self.acq_name = acq_name        self.logmarginal=0        self.gp=ProductGaussianProcess(self.scaleSearchSpace,verbose=verbose)        self.Y_curves=[]        self.Y_cost_original=None        self.time_opt=0        self.acq_func = None           self.logmarginal=0        self.markVirtualObs=[]        self.countVirtual=[]        self.linear_regression = linear_model.LinearRegression()        self.condition_number=[]        self.max_n_augmentation=10        self.threshold_cond=15            def init(self, n_init_points=3, seed=1):        np.random.seed(seed)        SearchSpace=np.copy(self.SearchSpace)        SearchSpace[-1,0]=SearchSpace[-1,1]        l = [np.random.uniform(x[0], x[1]) for _ in range(n_init_points) for x in SearchSpace]         temp=np.asarray(l)        temp=temp.T        init_X=list(temp.reshape((n_init_points,-1)))        self.X_original = np.asarray(init_X)        self.T_original=self.X_original[:,-1]        self.T_original=np.reshape(self.T_original,(n_init_points,-1))        self.X_original=self.X_original[:,:-1]        self.X_original=np.reshape(self.X_original,(n_init_points,-1))           y_init_curves, y_init_cost=self.f(init_X)        y_init_cost=np.atleast_2d(np.asarray(y_init_cost))        self.Y_curves+=y_init_curves        y_init=transform_logistic(y_init_curves,self.gp.logistic_hyper['midpoint'],                                  self.gp.logistic_hyper['growth'], self.SearchSpace[-1,1])        y_init=np.reshape(y_init,(n_init_points,1))                self.Y_original = np.asarray(y_init)      self.Y_cost_original=np.reshape(y_init_cost,(-1,1))        self.X = self.Xscaler.transform(np.asarray(init_X)[:,:-1])        self.X=np.reshape(self.X,(n_init_points,-1))        self.T = self.Tscaler.transform(self.T_original)        self.markVirtualObs+=[0]*n_init_points        for ii in range(n_init_points):            self.generating_virtual_observations(self.X[ii,:],                         self.T[ii],[y_init_curves[ii]],y_init_cost[0][ii],IsRandom=False)        self.Y_cost=(self.Y_cost_original-np.min(self.Y_cost_original))/(np.max(self.Y_cost_original)-np.min(self.Y_cost_original))        if np.std(self.Y_original)==0:            self.Y=(self.Y_original-np.mean(self.Y_original))        else:            self.Y=(self.Y_original-np.mean(self.Y_original))/np.std(self.Y_original)       def utility_cost_evaluation(self,x,acq_func,isDebug=False):                def utility_cost_evaluation_single(x,acq_func,isDebug=False):            utility=acq_func.acq_kind(x,gp=self.gp)                        try:                mean_cost=self.linear_regression.predict(np.reshape(x,(1,-1)))                            except:                print(x)                print(\"bug\")                mean_cost=max(0,mean_cost)+0.1            if 'ei' in acq_func.acq_name:                acquisition_function_value= np.log(utility)-np.log(mean_cost)            else:                acquisition_function_value= np.log(1+np.exp(utility))/np.log(1+np.exp(mean_cost))            if isDebug==True:                print(\"acq_func at the selected point \t utility:\",np.round(utility,decimals=4),\"\\t cost:\",mean_cost)                if utility==0:                    print(\"utility =0===============================================================================\")               return acquisition_function_value*(-1)        if len(x)==self.dim:            temp=utility_cost_evaluation_single(x,acq_func,isDebug=isDebug)            if isDebug==True:                return temp            else:                utility=np.mean(temp)        else:            utility=[0]*len(x)            for idx,val in enumerate(x):                temp=utility_cost_evaluation_single(x=val,acq_func=acq_func,isDebug=isDebug)                                                     utility[idx]=np.mean(temp)                utility=np.asarray(utility)    return utility       def acq_utility_cost(self):        acq={}        acq['name']=self.acq_name        acq['dim']=self.scaleSearchSpace.shape[0]        acq['scaleSearchSpace']=self.scaleSearchSpace           if self.acq_name=='ei_mu_max':            x_mu_max,mu_max_val=acq_max_with_name(gp=self.gp,scaleSearchSpace=self.scaleSearchSpace,acq_name='mu',IsReturnY=True)            acq['mu_max']=  mu_max_val        myacq=AcquisitionFunction(acq)                x_min = acq_min_scipy_kwargs(myfunc=self.utility_cost_evaluation,SearchSpace=self.scaleSearchSpace,                        acq_func=myacq, isDebug=False)        if self.verbose==True:            acq_val=self.utility_cost_evaluation(x_min,myacq,isDebug=False)            print(\"selected point from acq func:\",np.round(x_min,decimals=4),\"acq val=log(Utility/Cost)=\",(-1)*np.round(acq_val,decimals=4))            if np.round(acq_val,decimals=4)==0:                print(\"acq value =0\")                return x_min        def select_informative_location_by_uncertainty(self,n_virtual_obs,x_max,t_max):                        SearchSpace=np.copy(self.scaleSearchSpace)        for dd in range(self.dim-1):            SearchSpace[dd,0],SearchSpace[dd,1]=x_max[dd],x_max[dd]            SearchSpace[-1,1]=t_max        temp_X,temp_T=self.X.copy(),self.T.copy()        temp_gp=copy.deepcopy(self.gp )                temp_Y=np.random.random(size=(len(temp_T),1))                temp_gp.fit(temp_X,temp_T,temp_Y,self.Y_curves)        new_batch_T=None        pred_var_value=[0]*n_virtual_obs        for ii in range(n_virtual_obs):            x_max_pred_variance, pred_var_value[ii]=acq_max_with_name(gp=temp_gp,                              scaleSearchSpace=SearchSpace,acq_name='pure_exploration',IsReturnY=True)            log_cond=np.log( temp_gp.compute_condition_number() )            if log_cond>self.threshold_cond or pred_var_value[ii]<(self.gp.noise_delta+1e-3):                break                      if x_max_pred_variance[-1] in temp_T[-ii:]:                break                        temp_X = np.vstack((temp_X, x_max.reshape((1, -1))))            temp_T = np.vstack((temp_T, x_max_pred_variance[-1].reshape((1, -1))))            temp_gp.X,temp_gp.T=temp_X,temp_T            temp_Y=np.random.random(size=(len(temp_T),1))                        temp_gp.fit(temp_X,temp_T,temp_Y,self.Y_curves)            if new_batch_T is None:                new_batch_T=x_max_pred_variance[-1].reshape((1, -1))            else:                new_batch_T= np.vstack((new_batch_T, x_max_pred_variance[-1].reshape((1, -1))))                if new_batch_T is None:            return [],0        else:            output=np.sort(new_batch_T.ravel()).tolist()            return output, len(output)        def generating_virtual_observations(self,x_max,t_max,y_original_curves,y_cost_original,IsRandom=False):                temp_X_new_original=self.Xscaler.inverse_transform(np.reshape(x_max,(-1,self.dim-1)))        max_n_virtual_obs=np.int(t_max*self.max_n_augmentation)        if max_n_virtual_obs==0:            self.countVirtual.append(0)            return                if IsRandom==True:            l = [np.random.uniform(0, t_max) for _ in range(max_n_virtual_obs)]        else:            l,n_virtual_obs=self.select_informative_location_by_uncertainty(max_n_virtual_obs,x_max,t_max)                    self.countVirtual.append(n_virtual_obs)                if self.verbose:            np.set_printoptions(suppress=True)            print(\"Max #augmented points\",max_n_virtual_obs, \"\\t #augmented points \",len(l),                  \"\\t Augmented points: \",np.round(l,decimals=3))                    l_original=[self.SearchSpace[-1,0]+val*self.max_min_gap[-1] for val in l]                               virtual_obs_t_original=np.asarray(l_original).T        virtual_obs_t=np.asarray(l).T                y_virtual_original=[0]*n_virtual_obs        for ii in range(n_virtual_obs):                        idx=np.int(virtual_obs_t_original[ii])                        temp_curve=y_original_curves[0][:idx+1]            self.markVirtualObs.append(1)            y_virtual_original[ii]=transform_logistic([temp_curve],                      self.gp.logistic_hyper['midpoint'],self.gp.logistic_hyper['growth'],self.SearchSpace[-1,1])                       self.X = np.vstack((self.X, x_max.reshape((1, -1))))            self.X_original=np.vstack((self.X_original, temp_X_new_original))                    self.T = np.vstack((self.T, virtual_obs_t[ii].reshape((1, -1))))            temp=np.asarray(virtual_obs_t_original[ii])            self.T_original=np.vstack((self.T_original, temp.reshape((1, -1))))            self.Y_original = np.append(self.Y_original,[y_virtual_original[ii]])            self.Y_curves.append(temp_curve)                        y_cost_estimate=y_cost_original*virtual_obs_t[ii]            self.Y_cost_original = np.append(self.Y_cost_original,[y_cost_estimate])                            def suggest_nextpoint(self):         self.gp=ProductGaussianProcess(self.scaleSearchSpace,self.gp.hyper,self.gp.logistic_hyper)        self.gp.fit(self.X, self.T,self.Y,self.Y_curves)                    self.condition_number.append(self.gp.cond_num)        if self.verbose:            print(\"ln of conditioning number of GP covariance matrix\", np.round(np.log(self.gp.cond_num),decimals=1))        count=len(self.markVirtualObs)-np.sum(self.markVirtualObs)        count=np.int(count)        if  len(self.Y)%(2*self.dim)==0:            hyper=[self.gp.hyper['lengthscale_x'],self.gp.hyper['lengthscale_t'],                     self.gp.logistic_hyper['midpoint'],self.gp.logistic_hyper['growth']]            newlengthscale_x,newlengthscale_t,new_midpoint, new_growth = self.gp.optimize_lengthscale_logistic_hyper(hyper,self.gp.noise_delta)                        self.gp.hyper['lengthscale_x']=newlengthscale_x            self.gp.hyper['lengthscale_t']=self.gp.hyper['lengthscale_t']            self.gp.logistic_hyper['midpoint']=new_midpoint            self.gp.logistic_hyper['growth']=new_growth                      if self.verbose:                print(\"==estimated lengthscale_x={:.4f}   lengthscale_t={:.3f}   Logistic_m0={:.1f}   Logistic_g0={:.1f}\".format(                    newlengthscale_x,newlengthscale_t,new_midpoint,new_growth))                start_opt=time.time()        combine_input=np.hstack((self.X,self.T))        self.linear_regression.fit(combine_input,self.Y_cost)                x_max_temp=self.acq_utility_cost()        x_max=x_max_temp[:-1]        t_max=x_max_temp[-1]               finished_opt=time.time()        elapse_opt=finished_opt-start_opt        self.time_opt=np.hstack((self.time_opt,elapse_opt))                self.markVirtualObs.append(0)        self.X = np.vstack((self.X, x_max.reshape((1, -1))))        self.T = np.vstack((self.T, t_max.reshape((1, -1))))        temp_X_new_original=self.Xscaler.inverse_transform(np.reshape(x_max,(-1,self.dim-1)))        self.X_original=np.vstack((self.X_original, temp_X_new_original))                temp_T_new_original=self.Tscaler.inverse_transform(np.reshape(t_max,(-1,1)))        self.T_original=np.vstack((self.T_original, temp_T_new_original))        x_original_to_test=x_max_temp*self.max_min_gap+self.SearchSpace[:,0]        y_original_curves, y_cost_original= self.f(x_original_to_test)                y_original=transform_logistic(y_original_curves,              self.gp.logistic_hyper['midpoint'],self.gp.logistic_hyper['growth'],self.SearchSpace[-1,1])                if len(y_original_curves)==1:            self.Y_curves.append(y_original_curves[0])        else:            self.Y_curves.append(y_original_curves)                self.Y_original = np.append(self.Y_original,y_original)        self.Y_cost_original = np.append(self.Y_cost_original,y_cost_original)        self.generating_virtual_observations(x_max,t_max,y_original_curves,y_cost_original[0])                if np.std(self.Y_original)==0:            self.Y=(self.Y_original-np.mean(self.Y_original))        else:            self.Y=(self.Y_original-np.mean(self.Y_original))/np.std(self.Y_original)                    self.Y_cost=(self.Y_cost_original-np.min(self.Y_cost_original))/(np.max(self.Y_cost_original)-np.min(self.Y_cost_original))                            np.set_printoptions(suppress=True)        print(\"[original scale] x={} t={:.0f} current y={:.2f}, ybest={:.2f}\".format( np.round(self.X_original[-1],decimals=4),              np.asscalar(self.T_original[-1]),np.asscalar(self.Y_original[-1]), np.asscalar(self.Y_original.max())))import numpy as npfrom bayes_opt.acquisition_functions import unique_rowsfrom sklearn.preprocessing import MinMaxScalerfrom scipy.optimize import minimizefrom sklearn.metrics.pairwise import euclidean_distancesimport scipy.linalg as splafrom bayes_opt.curve_compression import apply_one_transform_logistic, transform_logisticclass ProductGaussianProcess(object):    def __init__ (self,SearchSpace,gp_hyper=None,logistic_hyper=None,verbose=0):        self.noise_delta=5e-4        self.noise_upperbound=1e-2        self.mycov=self.cov_RBF_time        self.SearchSpace=SearchSpace        scaler = MinMaxScaler()        scaler.fit(SearchSpace.T)        self.Xscaler=scaler        self.verbose=verbose        self.dim=SearchSpace.shape[0]                if gp_hyper is None:            self.hyper={}            self.hyper['var']=1            self.hyper['lengthscale_x']=0.02            self.hyper['lengthscale_t']=0.2        else:            self.hyper=gp_hyper                if logistic_hyper is None:            self.logistic_hyper={}            self.logistic_hyper['midpoint']=0.0            self.logistic_hyper['growth']=1.0        else:            self.logistic_hyper=logistic_hyper        self.X=[]        self.T=[]        self.Y=[]        self.Y_curves=None        self.alpha=[]        self.L=[]        self.MaxEpisode=0                return None               def cov_RBF_time(self, x1,t1,x2,t2,lengthscale,lengthscale_t):                Euc_dist=euclidean_distances(x1,x2)        exp_dist_x=np.exp(-np.square(Euc_dist)/lengthscale)                Euc_dist=euclidean_distances(t1,t2)        exp_dist_t=np.exp(-np.square(Euc_dist)/lengthscale_t)                return exp_dist_x*exp_dist_t                        def fit(self,X,T,Y,Y_curves):                temp=np.hstack((X,T))        ur = unique_rows(temp)                T=T[ur]        X=X[ur]        Y=Y[ur]                self.X=X        self.Y=Y        self.T=T        self.Y_curves=[val for idx,val in enumerate(Y_curves) if ur[idx]==True]                for curves in self.Y_curves:            self.MaxEpisode=max(len(curves),self.MaxEpisode)                        Euc_dist_x=euclidean_distances(X,X)            Euc_dist_t=euclidean_distances(T,T)                self.KK_x_x=np.exp(-np.square(Euc_dist_x)/self.hyper['lengthscale_x']                           -np.square(Euc_dist_t)/self.hyper['lengthscale_t'])+np.eye(len(X))*self.noise_delta                  if np.isnan(self.KK_x_x).any():            print(\"nan in KK_x_x\")                self.L=np.linalg.cholesky(self.KK_x_x)        temp=np.linalg.solve(self.L,self.Y)        self.alpha=np.linalg.solve(self.L.T,temp)        self.cond_num=self.compute_condition_number()            def compute_condition_number(self):        cond_num=np.linalg.cond(self.KK_x_x)        return cond_num            def log_marginal_lengthscale_logistic_hyper(self,hyper,noise_delta):                def compute_log_marginal_with_logistic_hyper(lengthscale, lengthscale_t,midpoint,growth,noise_delta):            temp=np.hstack((self.X,self.T))            ur = unique_rows(temp)            myX=self.X[ur]            myT=self.T[ur]                        Y_original=transform_logistic(self.Y_curves,midpoint,growth,self.MaxEpisode)            myY=(Y_original-np.mean(Y_original))/np.std(Y_original)                        myY=myY[ur]                      self.Euc_dist_x=euclidean_distances(myX,myX)            self.Euc_dist_t=euclidean_distances(myT,myT)                KK=np.exp(-np.square(self.Euc_dist_x)/lengthscale-np.square(self.Euc_dist_t)/lengthscale_t)                +np.eye(len(myX))*noise_delta                                    try:                temp_inv=np.linalg.solve(KK,myY)            except:                return -np.inf                        try:                first_term=-0.5*np.dot(myY.T,temp_inv)                                if KK.shape[0]>200:                    idx=np.random.permutation(KK.shape[0])                    idx=idx[:200]                    KK=KK[np.ix_(idx,idx)]                chol  = spla.cholesky(KK, lower=True)                W_logdet=np.sum(np.log(np.diag(chol)))                second_term=-W_logdet            except:                return -np.inf                        logmarginal=first_term+second_term-0.5*len(myY)*np.log(2*3.14)                        if np.isnan(np.asscalar(logmarginal))==True:                print(\"lengthscale_x={:f} lengthscale_t={:f} first term ={:.4f} second  term ={:.4f}\".format(                        lengthscale,lengthscale_t,np.asscalar(first_term),np.asscalar(second_term)))            return np.asscalar(logmarginal)                logmarginal=0        if not isinstance(hyper,list) and len(hyper.shape)==2:            logmarginal=[0]*hyper.shape[0]            growth=hyper[:,3]            midpoint=hyper[:,2]            lengthscale_t=hyper[:,1]            lengthscale_x=hyper[:,0]            for idx in range(hyper.shape[0]):                logmarginal[idx]=compute_log_marginal_with_logistic_hyper(lengthscale_x[idx],                           lengthscale_t[idx],midpoint[idx],growth[idx],noise_delta)        else:            lengthscale_x,lengthscale_t,midpoint,growth=hyper            logmarginal=compute_log_marginal_with_logistic_hyper(lengthscale_x,lengthscale_t,                                                                 midpoint,growth,noise_delta)        return logmarginal        def optimize_lengthscale_SE_logistic_hyper(self,previous_hyper,noise_delta):                SearchSpace_l_min=0.03        SearchSpace_l_max=0.3                SearchSpace_midpoint_min=-2        SearchSpace_midpoint_max=3                SearchSpace_growth_min=0.5        SearchSpace_growth_max=2                mySearchSpace=np.asarray([[SearchSpace_l_min,SearchSpace_l_max],[10*SearchSpace_l_min,2*SearchSpace_l_max],                             [SearchSpace_midpoint_min,SearchSpace_midpoint_max],[SearchSpace_growth_min,SearchSpace_growth_max]])                lengthscale_tries = np.random.uniform(mySearchSpace[:, 0], mySearchSpace[:, 1],size=(20, 4))        self.flagOptimizeHyperFirst=0        logmarginal_tries=self.log_marginal_lengthscale_logistic_hyper(lengthscale_tries,noise_delta)        idx_max=np.argmax(logmarginal_tries)        lengthscale_init_max=lengthscale_tries[idx_max]                myopts ={'maxiter':30*self.dim,'maxfun':30*self.dim}        x_max=[]        max_log_marginal=None                res = minimize(lambda x: -self.log_marginal_lengthscale_logistic_hyper(x,noise_delta),lengthscale_init_max,                       bounds=mySearchSpace,method=\"L-BFGS-B\",options=myopts)        if 'x' not in res:            val=self.log_marginal_lengthscale_logistic_hyper(res,noise_delta)        else:            val=self.log_marginal_lengthscale_logistic_hyper(res.x,noise_delta)          if max_log_marginal is None or val >= max_log_marginal:            if 'x' not in res:                x_max = res            else:                x_max = res.x            max_log_marginal = val        return x_max            def optimize_lengthscale_logistic_hyper(self,prev_hyper,noise_delta):                        newlengthscale,newlengthscale_t,newmidpoint,newgrowth=self.optimize_lengthscale_SE_logistic_hyper(prev_hyper,noise_delta)        self.hyper['lengthscale_x']=newlengthscale        self.hyper['lengthscale_t']=newlengthscale_t                temp=np.hstack((self.X,self.T))        ur = unique_rows(temp)        Y_original=transform_logistic(self.Y_curves,newmidpoint,newgrowth,self.SearchSpace[-1,1])        Y=(Y_original-np.mean(Y_original))/np.std(Y_original)        self.Y=Y                self.fit(self.X[ur],self.T[ur],self.Y[ur],self.Y_curves)                return newlengthscale,newlengthscale_t,newmidpoint,newgrowth            def compute_var(self,X,T,xTest,tTest):                xTest=np.asarray(xTest)        xTest=np.atleast_2d(xTest)                tTest=np.asarray(tTest)        tTest=np.atleast_2d(tTest)        tTest=np.reshape(tTest,(-1,1))                if self.kernel_name=='SE':            myX=X            myT=T                        Euc_dist_x=euclidean_distances(myX,myX)                    Euc_dist_t=euclidean_distances(myT,myT)                    KK=np.exp(-np.square(Euc_dist_x)/self.hyper['lengthscale_x']-np.square(Euc_dist_t)/self.hyper['lengthscale_t'])                +np.eye(len(myX))*self.noise_delta                                 Euc_dist_test_train_x=euclidean_distances(xTest,X)            Euc_dist_test_train_t=euclidean_distances(tTest,T)                        KK_xTest_xTrain=np.exp(-np.square(Euc_dist_test_train_x)/self.hyper['lengthscale_x']-np.square(Euc_dist_test_train_t)/self.hyper['lengthscale_t'])                        try:            temp=np.linalg.solve(KK,KK_xTest_xTrain.T)        except:            temp=np.linalg.lstsq(KK,KK_xTest_xTrain.T, rcond=-1)            temp=temp[0]                var=np.eye(xTest.shape[0])-np.dot(temp.T,KK_xTest_xTrain.T)        var=np.diag(var)        var.flags['WRITEABLE']=True        var[var<1e-100]=0        return var             def predict(self,xTest, eval_MSE=True):                if len(xTest.shape)==1:            xTest=xTest.reshape((-1,self.X.shape[1]+1))                        tTest=xTest[:,-1]        tTest=np.atleast_2d(tTest)        tTest=np.reshape(tTest,(xTest.shape[0],-1))                xTest=xTest[:,:-1]                temp=np.hstack((self.X,self.T))        ur = unique_rows(temp)                X=self.X[ur]        T=self.T[ur]                        Euc_dist_x=euclidean_distances(xTest,xTest)        Euc_dist_t=euclidean_distances(tTest,tTest)        KK_xTest_xTest=np.exp(-np.square(Euc_dist_x)/self.hyper['lengthscale_x']-np.square(Euc_dist_t)/self.hyper['lengthscale_t'])                +np.eye(xTest.shape[0])*self.noise_delta                Euc_dist_test_train_x=euclidean_distances(xTest,X)                Euc_dist_test_train_t=euclidean_distances(tTest,T)                KK_xTest_xTrain=np.exp(-np.square(Euc_dist_test_train_x)/self.hyper['lengthscale_x']-np.square(Euc_dist_test_train_t)/self.hyper['lengthscale_t'])                      mean=np.dot(KK_xTest_xTrain,self.alpha)        v=np.linalg.solve(self.L,KK_xTest_xTrain.T)        var=KK_xTest_xTest-np.dot(v.T,v)                return mean.ravel(),np.diag(var)            def posterior(self,x):        return self.predict(self,x)import numpy as npfrom scipy.stats import normcounter = 0class AcquisitionFunction(object):    def __init__(self, acq):        self.acq=acq        acq_name=acq['name']                if 'mu_max' in acq:            self.mu_max=acq['mu_max']        ListAcq=['bucb','ucb', 'ei','poi','random','ucb_pe',                 'pure_exploration','mu','lcb','ei_mu_max']                IsTrue=[val for idx,val in enumerate(ListAcq) if val in acq_name]        if  IsTrue == []:            err = \"The utility function \"                  \"{} has not been implemented, \"                  \"please choose one of ucb, ei, or poi.\".format(acq_name)            raise NotImplementedError(err)        else:            self.acq_name = acq_name                    self.dim=acq['dim']                if 'scalebounds' not in acq:            self.scalebounds=[0,1]*self.dim                    else:            self.scalebounds=acq['scalebounds']                           def acq_kind(self, x, gp):                y_max=np.max(gp.Y)        if np.any(np.isnan(x)):            return 0               if self.acq_name == 'ucb':            return self._ucb(x, gp)        if self.acq_name == 'lcb':            return self._lcb(x, gp)        if self.acq_name == 'ei':            return self._ei(x, gp, y_max)        if self.acq_name == 'ei_mu_max':            return self._ei(x, gp, self.mu_max)        if self.acq_name == 'poi':            return self._poi(x, gp, y_max)                if self.acq_name == 'pure_exploration':            return self._pure_exploration(x, gp)               if self.acq_name == 'mu':            return self._mu(x, gp)                if self.acq_name == 'ucb_pe':            return self._ucb_pe(x, gp,self.acq['kappa'],self.acq['maxlcb'])                   def utility_plot(self, x, gp, y_max):        if np.any(np.isnan(x)):            return 0        if self.acq_name == 'ei':            return self._ei_plot(x, gp, y_max)           @staticmethod    def _mu(x, gp):        mean, var = gp.predict(x, eval_MSE=True)        mean=np.atleast_2d(mean).T        return mean                        @staticmethod    def _lcb(x, gp):        mean, var = gp.predict(x, eval_MSE=True)        var.flags['WRITEABLE']=True        var[var<1e-10]=0        mean=np.atleast_2d(mean).T        var=np.atleast_2d(var).T        beta_t = 2 * np.log(len(gp.Y));        return mean - np.sqrt(beta_t) * np.sqrt(var)             @staticmethod    def _ucb(x, gp):        mean, var = gp.predict(x, eval_MSE=True)        var.flags['WRITEABLE']=True        var[var<1e-10]=0        mean=np.atleast_2d(mean).T        var=np.atleast_2d(var).T                        beta_t = 2 * np.log(len(gp.Y));          return mean + np.sqrt(beta_t) * np.sqrt(var)            @staticmethod    def _ucb_pe(x, gp, kappa, maxlcb):        mean, var = gp.predict_bucb(x, eval_MSE=True)        var.flags['WRITEABLE']=True        var[var<1e-10]=0        mean=np.atleast_2d(mean).T        var=np.atleast_2d(var).T        value=mean + kappa * np.sqrt(var)        myidx=[idx for idx,val in enumerate(value) if val<maxlcb]        var[myidx]=0        return var               @staticmethod    def _pure_exploration(x, gp):        mean, var = gp.predict(x, eval_MSE=True)        var.flags['WRITEABLE']=True        var[var<1e-10]=0        mean=np.atleast_2d(mean).T        var=np.atleast_2d(var).T        return np.sqrt(var)               @staticmethod    def _ei(x, gp, y_max):        y_max=np.asscalar(y_max)        mean, var = gp.predict(x, eval_MSE=True)        var2 = np.maximum(var, 1e-10 + 0 * var)        z = (mean - y_max)/np.sqrt(var2)        out=(mean - y_max) * norm.cdf(z) + np.sqrt(var2) * norm.pdf(z)        out[var2<1e-10]=0        return out           @staticmethod          def _poi(x, gp,y_max):        mean, var = gp.predict(x, eval_MSE=True)        var = np.maximum(var, 1e-9 + 0 * var)        z = (mean - y_max)/np.sqrt(var)        return norm.cdf(z)           def unique_rows(a):    order = np.lexsort(a.T)    reorder = np.argsort(order)    a = a[order]    diff = np.diff(a, axis=0)    ui = np.ones(len(a), 'bool')    ui[1:] = (diff != 0).any(axis=1)    return ui[reorder]class BColours(object):    BLUE = '\\033[94m'    CYAN = '\\033[36m'    GREEN = '\\033[32m'    MAGENTA = '\\033[35m'    RED = '\\033[31m'    ENDC = '\\033[0m'import numpy as npfrom scipy.optimize import minimizefrom bayes_opt.acquisition_functions import AcquisitionFunctionimport sobol_seq__author__ = 'Vu'def acq_max_with_name(gp,scaleSearchSpace,acq_name=\"ei\",IsReturnY=False,IsMax=True,fstar_scaled=None):    acq={}    acq['name']=acq_name    acq['dim']=scaleSearchSpace.shape[0]    acq['scaleSearchSpace']=scaleSearchSpace       if fstar_scaled:        acq['fstar_scaled']=fstar_scaled       myacq=AcquisitionFunction(acq)    if IsMax:        x_max = acq_max(ac=myacq.acq_kind,gp=gp,bounds=scaleSearchSpace,opt_toolbox='scipy')    else:        x_max = acq_min_scipy(ac=myacq.acq_kind,gp=gp,bounds=scaleSearchSpace)    if IsReturnY==True:        y_max=myacq.acq_kind(x_max,gp=gp)        return x_max,y_max    return x_maxdef acq_max(ac, gp, bounds, opt_toolbox='scipy',seeds=[],IsMax=True):    y_max=np.max(gp.Y)      x_max = acq_max_scipy(ac=ac,gp=gp,y_max=y_max,bounds=bounds)    return x_maxdef generate_sobol_seq(dim,nSobol):    mysobol_seq = sobol_seq.i4_sobol_generate(dim, nSobol)    return mysobol_seq        def acq_min_scipy_kwargs(myfunc, SearchSpace, **kwargs):    dim=SearchSpace.shape[0]    x_max = SearchSpace[:, 0]    min_acq = None    myopts ={'maxiter':10*dim,'maxfun':20*dim}    for i in range(3*dim):        x_tries = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(100*dim, dim))            y_tries=myfunc(x_tries,**kwargs)                idx_min=np.argmin(y_tries)        x_init_min=x_tries[idx_min]        res = minimize(lambda x: myfunc(x.reshape(1, -1), **kwargs),x_init_min.reshape(1, -1),bounds=SearchSpace,                       method=\"L-BFGS-B\",options=myopts)        if 'x' not in res:            val=myfunc(res,**kwargs)        else:            val=myfunc(res.x,**kwargs)         if min_acq is None or val <= min_acq:            if 'x' not in res:                x_max = res            else:                x_max = res.x            min_acq = val    return np.clip(x_max, SearchSpace[:, 0], SearchSpace[:, 1])        def acq_min_scipy(ac, gp, bounds):    dim=bounds.shape[0]    x_max = bounds[:, 0]    min_acq = None    myopts ={'maxiter':10*dim,'maxfun':20*dim}    for i in range(3*dim):        x_tries = np.random.uniform(bounds[:, 0], bounds[:, 1],size=(50*dim, dim))            y_tries=ac(x_tries,gp=gp)                idx_max=np.argmin(y_tries)        x_init_max=x_tries[idx_max]            res = minimize(lambda x: ac(x.reshape(1, -1), gp=gp),x_init_max.reshape(1, -1),bounds=bounds,                       method=\"L-BFGS-B\",options=myopts)          if 'x' not in res:            val=ac(res,gp)        else:            val=ac(res.x,gp)         if min_acq is None or val <= min_acq:            if 'x' not in res:                x_max = res            else:                x_max = res.x            min_acq = val    return np.clip(x_max, bounds[:, 0], bounds[:, 1])        def acq_max_scipy(ac, gp, y_max, bounds):    dim=bounds.shape[0]    x_max = bounds[:, 0]    max_acq = None    myopts ={'maxiter':10*dim,'maxfun':20*dim}    for i in range(1*dim):        x_tries = np.random.uniform(bounds[:, 0], bounds[:, 1],size=(50*dim, dim))            y_tries=ac(x_tries,gp=gp)                idx_max=np.argmax(y_tries)        x_init_max=x_tries[idx_max]            res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp),x_init_max.reshape(1, -1),bounds=bounds,                       method=\"L-BFGS-B\",options=myopts)        if 'x' not in res:            val=ac(res,gp)        else:            val=ac(res.x,gp)         if max_acq is None or val >= max_acq:            if 'x' not in res:                x_max = res            else:                x_max = res.x            max_acq = val    return np.clip(x_max, bounds[:, 0], bounds[:, 1])        def acq_max_with_init(ac, gp, y_max, bounds, init_location=[]):    dim=bounds.shape[0]    x_max = bounds[:, 0]    max_acq = None    myopts ={'maxiter':5*dim,'maxfun':10*dim}    for i in range(2*dim):        x_tries = np.random.uniform(bounds[:, 0], bounds[:, 1],size=(20*dim, dim))                if init_location!=[]:            x_tries=np.vstack((x_tries,init_location))                y_tries=ac(x_tries,gp=gp)                idx_max=np.argmax(y_tries)        x_init_max=x_tries[idx_max]            res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp),x_init_max.reshape(1, -1),bounds=bounds,                       method=\"L-BFGS-B\",options=myopts)        if 'x' not in res:            val=ac(res,gp)        else:            val=ac(res.x,gp)         if max_acq is None or val >= max_acq:            if 'x' not in res:                x_max = res            else:                x_max = res.x            max_acq = val    return np.clip(x_max, bounds[:, 0], bounds[:, 1])import itertoolsimport numpy as npdef apply_one_transform_average(curve, midpoint=3, growth=1,MaxEpisode=1000):            if isinstance(curve, (list,)):        curve=curve[0]         def linear_func(x):        if len(x)==1:            return 1        else:            return [1 for u in x]    my_xrange_scaled=np.linspace(0.01,5, MaxEpisode)    my_logistic_value_scaled=linear_func(my_xrange_scaled)    my_logistic_value_scaled=my_logistic_value_scaled[:len(curve)]    average=np.mean(curve)        return average,my_logistic_value_scaleddef return_logistic_curve(midpoint, growth, MaxEpoch=1000):        def logistic_func(x):        if len(x)==1:            return 1.0/(1+np.exp(-growth*(x-midpoint)))        else:            return [1.0/(1+np.exp(-growth*(u-midpoint))) for u in x]            my_xrange_scaled=np.linspace(-6,6, MaxEpoch)    my_logistic_value_scaled=logistic_func(my_xrange_scaled)        return my_logistic_value_scaleddef apply_one_transform_ln(curve, midpoint=3, growth=1,MaxEpisode=1000):    if isinstance(curve, (list,)):        curve=curve[0]         def ln_func(x):        if len(x)==1:            return 20+np.log(x)        else:            return [np.log(u) for u in x]    my_xrange_scaled=np.linspace(0.01,5, MaxEpisode)    my_logistic_value_scaled=ln_func(my_xrange_scaled)    my_logistic_value_scaled=my_logistic_value_scaled[:len(curve)]    if np.max(curve)<=0 and np.min(curve)<=0:        curve=curve+500        threshold=(midpoint+6-2)*len(curve)/(12)    threshold=np.int(threshold)        prod_func=curve*my_logistic_value_scaled        average=[np.mean(prod_func[threshold:pos]) for pos in range(threshold,len(prod_func))]    if np.isnan(average[-1]):        print('bug [curve]')    return average[-1],my_logistic_value_scaleddef apply_one_transform_logistic(curve, midpoint=-2, growth=1,MaxEpisode=1000,IsReturnCurve=False):    if isinstance(curve, (list,)):        curve=curve[0]            def logistic_func(x):        return 1.0/(1+np.exp(-growth*(x-midpoint)))            my_xrange_scaled=np.linspace(-6,6, int(MaxEpisode))    my_logistic_value_scaled=logistic_func(my_xrange_scaled)    my_logistic_value_scaled=my_logistic_value_scaled[:len(curve)]    if np.max(curve)<=0 and np.min(curve)<=0:        curve=curve+500        threshold=(midpoint+6-2)*len(curve)/(12)    threshold=np.int(threshold)        prod_func=curve*my_logistic_value_scaled        average=[np.mean(prod_func[threshold:pos+1]) for pos in range(threshold,len(prod_func))]    if IsReturnCurve==True:        return average[-1],my_logistic_value_scaled    else:        return average[-1]def transform_logistic_marginal(curves,MaxEpisode=1000):    def transform_one_logistic_marginal(curves,MaxEpisode):            midpoint_list=[-3,-2,-1,0,1]        growth_list=[0.1,1,2,3]                temp_Y_value=[0]*(len(midpoint_list)*len(growth_list))        for idx, (val1, val2) in enumerate(itertools.product(midpoint_list,growth_list)):            temp_Y_value[idx]=apply_one_transform_logistic(curves,val1, val2,MaxEpisode)                        temp_Y_value=np.asarray(temp_Y_value)                Y=np.mean(temp_Y_value,axis=0)        return Y    if len(curves)==1:        output=transform_one_logistic_marginal(curves[0],MaxEpisode)    else:        output=[0]*len(curves)        for idx, curve in enumerate(curves):            output[idx]=transform_one_logistic_marginal(curve,MaxEpisode)    return outputdef transform_logistic(curves, midpoint=0, growth=1,MaxEpisode=1000):    if len(curves)==1:        output=apply_one_transform_logistic(curves[0], midpoint, growth,MaxEpisode)    else:        output=[0]*len(curves)        for idx, curve in enumerate(curves):            output[idx]=apply_one_transform_logistic(curve, midpoint, growth,MaxEpisode)    return output",
    "Experiment Result": "The BOIL algorithm uses a Product Gaussian Process (GP) with a product kernel. Initial GP kernel hyperparameters are: `lengthscale_x = 0.02` and `lengthscale_t = 0.2`. The GP noise parameter `noise_delta` is set to `5e-4`, with an upper bound `noise_upperbound = 1e-2`. The utility score is compressed using a Sigmoid (Logistic) preference function, initialized with `midpoint = 0.0` and `growth = 1.0`. The `MaxEpisode` for utility calculation is dynamically set based on observed curves.\n\nThe initial phase of BOIL uses `n_init_points = 3` randomly sampled points. Hyperparameters for the GP (both lengthscales) and the Logistic preference function (midpoint, growth) are optimized together by maximizing the GP's log marginal likelihood every `2 * dim` iterations, where `dim` is the dimensionality of the search space. The optimization search bounds for these parameters are:\n- `lengthscale_x`: [0.03, 0.3]\n- `lengthscale_t`: [0.03, 0.6] (10*SearchSpace_l_min, 2*SearchSpace_l_max implicitly meaning 10*0.03 and 2*0.3)\n- `midpoint`: [-2, 3]\n- `growth`: [0.5, 2]\n\nFor selecting the next hyperparameter and iteration count, a modified Expected Improvement (`acq_name = \"ei_mu_max\"`) criterion is used, normalized by the predicted training cost. The training cost is modeled using a `sklearn.linear_model.LinearRegression()` model, fitted on the observed hyperparameter-iteration pairs and their corresponding costs.\n\nSelective data augmentation is employed to improve sample efficiency and prevent GP covariance matrix ill-conditioning. A maximum of `max_n_augmentation = 10` virtual points can be added per real observation. These points are strategically sampled at locations of maximum GP predictive uncertainty. The augmentation process is dynamically controlled by a condition number threshold, `threshold_cond = 15`. If the log of the GP covariance matrix's condition number exceeds this threshold, or if predictive uncertainty is too low, augmentation for that observation stops."
}
Output:
{'open_problems': 'Current PEFT techniques that work in spectral space rely on a *fixed* set of r singular directions per layer. This static choice is sub-optimal because (i) different inputs/tasks activate different directions, (ii) all layers receive the same parameter budget irrespective of their importance, and (iii) capacity can only be increased by storing more per-layer parameters. A mechanism that *dynamically* selects additional spectral directions on a per-example basis, while keeping the number of trainable parameters constant and layer-agnostic, is missing.', 'method': "Dynamic Conditional Spectral Gates (DynaCSG).\n1. Pre-processing: for every linear weight W we store the top r_b (e.g. r_b=8) singular triplet U_b,S_b,V_b obtained once offline.\n2. Shared hyper-network H_θ: a 2-layer MLP (≈64k parameters, shared by all layers) that maps a compact context vector c (CLS embedding after layer ℓ) to a gate vector g_ℓ∈R^{r_b}.  θ is the *only* trainable parameter set.\n3. Sparse stochastic gating: g~Bernoulli(σ((H_θ(c)-τ)/τ_g)), implemented with a Gumbel–Sigmoid straight-through estimator and an L0 penalty λ·||g||_0. Expected active gates per layer is thus learned but kept small (≈2).\n4. Spectral modulation per forward pass:\n   Ŝ_b = S_b·(1+α·g), \u2003Ŵ = (U_b * Ŝ_b) @ V_b.\n   No extra per-layer tensors are stored; the FLOP overhead is negligible because g is very sparse.\n5. Training objective: task loss + λ·L0. At inference the stochastic gate is replaced by its deterministic mean mask.\n\nPython prototype:\n```\nclass DynCSGLayer(nn.Module):\n    def __init__(self, orig_lin, r=8, h_dim=128):\n        super().__init__()\n        W=orig_lin.weight.data; U,S,V=torch.linalg.svd(W, full_matrices=False)\n        self.register_buffer('U',U[:,:r]); self.register_buffer('S',S[:r]); self.register_buffer('V',V[:r])\n        self.hyper=nn.Sequential(nn.Linear(h_dim,64),nn.ReLU(),nn.Linear(64,r))\n        self.tau=1.0; self.alpha=0.1; self.l0_lambda=1e-4\n    def forward(self,x,ctx):\n        logits=self.hyper(ctx)\n        gate=torch.sigmoid((logits+self._gumbel_like(logits))/self.tau)\n        S_hat=self.S*(1+self.alpha*gate)\n        W_hat=(self.U*S_hat.unsqueeze(0))@self.V\n        return F.linear(x,W_hat)\n    def l0_reg(self):\n        return self.l0_lambda*gate.mean()\n```\nThe same `hyper` object is reused by all wrapped linear layers.", 'experimental_setup': 'Backbone: DeBERTa-v3-base.\nDatasets: GLUE (in-domain) + HANS & ANLI (out-of-domain robustness).\nBaselines: Full FT, LoRA-8, SpectralAdapterR-8, AdaLoRA (budget-matched).\nProposed: DynaCSG with r_b=8, shared-hypernet (≈0.03% trainable params).\nTraining: 5 epochs, AdamW 2e-4, λ=1e-4 for L0.\nInference: deterministic mask, measure average activated gates and latency.', 'primary_metric': '(1) Average GLUE score; (2) HANS accuracy; (3) Activated-gate count ⟨k⟩ per layer (efficiency proxy).', 'experimental_code': 'github.com/anon/dynacsg – 200 lines (torch >=1.12).', 'expected_result': 'DynaCSG improves GLUE by +1.8 points over SpectralAdapterR and +1.0 over AdaLoRA while keeping ⟨k⟩≈2 (same parameter cost) and adds <1% latency. Robustness gains: +3–4% on HANS & ANLI due to input-adaptive capacity.', 'expected_conclusion': 'Input-conditioned, sparsity-controlled spectral gating eliminates the rigidity of fixed-rank PEFT without inflating per-layer parameters. A single tiny hyper-network is sufficient to supply context-specific subspaces across the whole model, yielding better accuracy–efficiency trade-offs and improved out-of-domain robustness. The idea opens a path toward task- and example-adaptive PEFT modules for on-device and federated scenarios.'}
